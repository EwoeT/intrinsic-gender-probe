{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Dict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# debias embeddings for Sent-debias\n",
    "\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "with open('../../../../liang_sent_debias-master/debias-BERT/experiments/4_bert_large_saved_embs/num7993_a_pretrained.pkl', 'rb') as f:\n",
    "    all_embeddings_a = pickle.load(f)\n",
    "\n",
    "with open('../../../../liang_sent_debias-master/debias-BERT/experiments/4_bert_large_saved_embs/num7993_b_pretrained.pkl', 'rb') as f:\n",
    "    all_embeddings_b = pickle.load(f)\n",
    "    \n",
    "    \n",
    "means = (all_embeddings_a + all_embeddings_b) / 2.0\n",
    "all_embeddings_a -= means\n",
    "all_embeddings_b -= means\n",
    "all_embeddings = np.concatenate([all_embeddings_a, all_embeddings_b], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def doPCA(matrix, num_components=10):\n",
    "\tpca = PCA(n_components=num_components, svd_solver=\"auto\")\n",
    "\tpca.fit(matrix) # Produce different results each time...\n",
    "\treturn pca\n",
    "\n",
    "\n",
    "def drop_bias(u, v):\n",
    "    return u - torch.ger(torch.matmul(u, v), v) / v.dot(v)\n",
    "\n",
    "\n",
    "def get_gender_dir(k):\n",
    "    gender_dir = doPCA(all_embeddings).components_[:k]\n",
    "    # if (not keepdims):\n",
    "    gender_dir = np.mean(gender_dir, axis=0)\n",
    "    logger.info(\"gender direction={} {} {}\".format(gender_dir.shape,\n",
    "            type(gender_dir), gender_dir[:10]))\n",
    "    gender_dir = torch.from_numpy(gender_dir)\n",
    "    return gender_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dir = get_gender_dir(1)\n",
    "\n",
    "def sent_deb_fill_mask_raw(sentence, tokenizer, model):\n",
    "    input_seq = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(input_seq, return_dict=True, output_hidden_states=True).hidden_states[0]\n",
    "#         print(embeddings.shape)\n",
    "        for t in range(embeddings.shape[1]):\n",
    "            embeddings[:, t] = drop_bias(embeddings[:, t], gender_dir)\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=-1)\n",
    "#         print(embeddings.shape)\n",
    "        token_logits = decoder(embeddings)\n",
    "    mask_token_index = torch.where(input_seq == tokenizer.mask_token_id)[1]\n",
    "    results = []\n",
    "    for i in torch.where(input_seq == tokenizer.mask_token_id)[1]:\n",
    "        logits = token_logits[0, i.item(), :].squeeze()\n",
    "        prob = logits.softmax(dim=0)\n",
    "        results.append((prob, logits))\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def fill_mask_raw(sentence, tokenizer, model):\n",
    "    input_seq = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        token_logits = model(input_seq, return_dict=True).logits\n",
    "    mask_token_index = torch.where(input_seq == tokenizer.mask_token_id)[1]\n",
    "    results = []\n",
    "    for i in torch.where(input_seq == tokenizer.mask_token_id)[1]:\n",
    "        logits = token_logits[0, i.item(), :].squeeze()\n",
    "        prob = logits.softmax(dim=0)\n",
    "        results.append((prob, logits))\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_mask_fill_logits(\n",
    "    sentence,\n",
    "    gendered_tokens,\n",
    "    tokenizer,\n",
    "    model_ind,\n",
    "    use_last_mask=False,\n",
    "    apply_softmax=False,\n",
    "):\n",
    "    outcome = {}\n",
    "    model = models[model_ind]\n",
    "    if model_ind == 2:\n",
    "        prob, values = sent_deb_fill_mask_raw(sentence, tokenizer, model)[1 if use_last_mask else 0]\n",
    "    else:\n",
    "        prob, values = fill_mask_raw(sentence, tokenizer, model)[1 if use_last_mask else 0]\n",
    "    for token in gendered_tokens:\n",
    "        outcome[token] = (\n",
    "            prob[tokenizer.convert_tokens_to_ids(token)].item()\n",
    "            if apply_softmax\n",
    "            else values[tokenizer.convert_tokens_to_ids(token)].item()\n",
    "        )\n",
    "    return outcome\n",
    "\n",
    "\n",
    "def bias_score(\n",
    "    sentence: str,\n",
    "    gender_words: Iterable[str],\n",
    "    word: str,\n",
    "    tokenizer,\n",
    "    model_ind,\n",
    "    gender_comes_first=True,\n",
    ") -> Dict[str, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a sentence of the form \"GGG is XXX\"\n",
    "    XXX is a placeholder for the target word\n",
    "    GGG is a placeholder for the gendered words (the subject)\n",
    "    We will predict the bias when filling in the gendered words and\n",
    "    filling in the target word.\n",
    "\n",
    "    gender_comes_first: whether GGG comes before XXX (TODO: better way of handling this?)\n",
    "    \"\"\"\n",
    "    # probability of filling [MASK] with \"he\" vs. \"she\" when target is \"programmer\"\n",
    "    mw, fw = gender_words\n",
    "    subject_fill_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", word).replace(\"GGG\", tokenizer.mask_token),\n",
    "        gender_words,\n",
    "        tokenizer,\n",
    "        model_ind,\n",
    "        use_last_mask=not gender_comes_first,\n",
    "        apply_softmax=True,\n",
    "    )\n",
    "    subject_fill_bias = subject_fill_logits[mw] - subject_fill_logits[fw]\n",
    "\n",
    "    # male words are simply more likely than female words\n",
    "    # correct for this by masking the target word and measuring the prior probabilities\n",
    "    subject_fill_prior_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", tokenizer.mask_token).replace(\n",
    "            \"GGG\", tokenizer.mask_token\n",
    "        ),\n",
    "        gender_words,\n",
    "        tokenizer,\n",
    "        model_ind,\n",
    "        use_last_mask=gender_comes_first,\n",
    "        apply_softmax=True,\n",
    "    )\n",
    "    subject_fill_bias_prior_correction = (\n",
    "        subject_fill_prior_logits[mw] - subject_fill_prior_logits[fw]\n",
    "    )\n",
    "\n",
    "    # probability of filling \"programmer\" into [MASK] when subject is male/female\n",
    "    mw_fill_prob = get_mask_fill_logits(\n",
    "        sentence.replace(\"GGG\", mw).replace(\"XXX\", tokenizer.mask_token),\n",
    "        [word],\n",
    "        tokenizer,\n",
    "        model_ind,\n",
    "        apply_softmax=True,\n",
    "    )[word]\n",
    "    fw_fill_prob = get_mask_fill_logits(\n",
    "        sentence.replace(\"GGG\", fw).replace(\"XXX\", tokenizer.mask_token),\n",
    "        [word],\n",
    "        tokenizer,\n",
    "        model_ind,\n",
    "        apply_softmax=True,\n",
    "    )[word]\n",
    "    # We don't need to correct for the prior probability here since the probability\n",
    "    # should already be conditioned on the presence of the word in question\n",
    "    tgt_fill_bias = np.log(mw_fill_prob / fw_fill_prob)\n",
    "    return {\n",
    "        \"gender_fill_bias\": subject_fill_bias,\n",
    "        \"gender_fill_prior_correction\": subject_fill_bias_prior_correction,\n",
    "        \"gender_fill_bias_prior_corrected\": np.log(\n",
    "            subject_fill_logits[mw] / subject_fill_prior_logits[mw]\n",
    "        )\n",
    "        - np.log(subject_fill_logits[fw] / subject_fill_prior_logits[fw]),\n",
    "        \"target_fill_bias\": tgt_fill_bias,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# # model1\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "# import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# model1 default pretrained model\n",
    "import torch\n",
    "# tokenizer2 = AlbertTokenizer.from_pretrained('bert-large-uncased')\n",
    "# # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# # linear classification layer on top. \n",
    "model1 = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 Context-debias\n",
    "import torch\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model2 = BertForMaskedLM.from_pretrained('bert-large-uncased', state_dict=torch.load(\"../../../../kaneko_debiased_bert/context-debias-main/debiased_models/42/bert_large/checkpoint-best/pytorch_model.bin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model3 Sent-debias\n",
    "import torch\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model3 = BertForMaskedLM.from_pretrained(\"bert-large-uncased\")\n",
    "decoder = BertForMaskedLM.from_pretrained(\"bert-large-uncased\").cls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model4 CDA\n",
    "import torch\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model4 = BertForMaskedLM.from_pretrained(\"bert-large-uncased\", state_dict=torch.load(\"../../../../CDA/counterfactual-data-substitution-master/zari-bert-cda/pytorch_model.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4]\n",
    "tokenizers = [tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aerobics',\n",
       " 'beauty',\n",
       " 'blonde',\n",
       " 'cheerleader',\n",
       " 'cheerleading',\n",
       " 'cooking',\n",
       " 'flirt',\n",
       " 'flower',\n",
       " 'gossip',\n",
       " 'housekeeper',\n",
       " 'housekeepers',\n",
       " 'jewelry',\n",
       " 'nanny',\n",
       " 'nurse',\n",
       " 'nurses',\n",
       " 'pink',\n",
       " 'pretty',\n",
       " 'receptionist',\n",
       " 'sewing',\n",
       " 'softball',\n",
       " 'submissive',\n",
       " 'makeup',\n",
       " 'therapist',\n",
       " 'maid',\n",
       " 'chairperson',\n",
       " 'tycoon',\n",
       " 'warrior',\n",
       " 'trucker',\n",
       " 'strong',\n",
       " 'terrorist',\n",
       " 'soldier',\n",
       " 'sniper',\n",
       " 'baseball',\n",
       " 'sergeant',\n",
       " 'bodyguard',\n",
       " 'boss',\n",
       " 'boxer',\n",
       " 'captain',\n",
       " 'carpenter',\n",
       " 'chancellor',\n",
       " 'colonel',\n",
       " 'commander',\n",
       " 'conductor',\n",
       " 'diplomat',\n",
       " 'drummer',\n",
       " 'engineer',\n",
       " 'financier',\n",
       " 'gambler',\n",
       " 'gangster',\n",
       " 'geek',\n",
       " 'guitarist',\n",
       " 'industrialist',\n",
       " 'marshal',\n",
       " 'mechanic',\n",
       " 'philosopher',\n",
       " 'physicist',\n",
       " 'scientist',\n",
       " 'rapper',\n",
       " 'mechanic',\n",
       " 'carpenter',\n",
       " 'clergy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# female_stereotype_list\n",
    "female_stereotype = open(\"female_stereotype.txt\", \"r\") \n",
    "data = female_stereotype.read()\n",
    "female_stereotype_list = data.split(\"\\n\")\n",
    "# print(female_stereotype_list)\n",
    "female_stereotype.close()\n",
    "\n",
    "\n",
    "# male_stereotype_liste\n",
    "male_stereotype = open(\"male_stereotype.txt\", \"r\")\n",
    "data = male_stereotype.read()\n",
    "male_stereotype_list = data.split(\"\\n\")\n",
    "# print(male_stereotype_list)\n",
    "male_stereotype.close()\n",
    "\n",
    "female_list = list(female_stereotype_list)\n",
    "female_list\n",
    "\n",
    "male_list = list(male_stereotype_list)\n",
    "male_list\n",
    "\n",
    "all_jobs = female_list + male_list\n",
    "all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = [\"female\", \"woman\", \"girl\", \"lady\", \"sister\", \"daughter\", \"mother\", \"aunt\", \"grandmother\"]\n",
    "YY = [\"male\", \"man\", \"boy\", \"guy\", \"brother\", \"son\", \"father\", \"uncle\", \"grandfather\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerobics\n",
      "beauty\n",
      "blonde\n",
      "cheerleader\n",
      "cheerleading\n",
      "cooking\n",
      "flirt\n",
      "flower\n",
      "gossip\n",
      "housekeeper\n",
      "housekeepers\n",
      "jewelry\n",
      "nanny\n",
      "nurse\n",
      "nurses\n",
      "pink\n",
      "pretty\n",
      "receptionist\n",
      "sewing\n",
      "softball\n",
      "submissive\n",
      "makeup\n",
      "therapist\n",
      "maid\n",
      "chairperson\n",
      "tycoon\n",
      "warrior\n",
      "trucker\n",
      "strong\n",
      "terrorist\n",
      "soldier\n",
      "sniper\n",
      "baseball\n",
      "sergeant\n",
      "bodyguard\n",
      "boss\n",
      "boxer\n",
      "captain\n",
      "carpenter\n",
      "chancellor\n",
      "colonel\n",
      "commander\n",
      "conductor\n",
      "diplomat\n",
      "drummer\n",
      "engineer\n",
      "financier\n",
      "gambler\n",
      "gangster\n",
      "geek\n",
      "guitarist\n",
      "industrialist\n",
      "marshal\n",
      "mechanic\n",
      "philosopher\n",
      "physicist\n",
      "scientist\n",
      "rapper\n",
      "mechanic\n",
      "carpenter\n",
      "clergy\n",
      "1.3266292479044877\n",
      "aerobics\n",
      "beauty\n",
      "blonde\n",
      "cheerleader\n",
      "cheerleading\n",
      "cooking\n",
      "flirt\n",
      "flower\n",
      "gossip\n",
      "housekeeper\n",
      "housekeepers\n",
      "jewelry\n",
      "nanny\n",
      "nurse\n",
      "nurses\n",
      "pink\n",
      "pretty\n",
      "receptionist\n",
      "sewing\n",
      "softball\n",
      "submissive\n",
      "makeup\n",
      "therapist\n",
      "maid\n",
      "chairperson\n",
      "tycoon\n",
      "warrior\n",
      "trucker\n",
      "strong\n",
      "terrorist\n",
      "soldier\n",
      "sniper\n",
      "baseball\n",
      "sergeant\n",
      "bodyguard\n",
      "boss\n",
      "boxer\n",
      "captain\n",
      "carpenter\n",
      "chancellor\n",
      "colonel\n",
      "commander\n",
      "conductor\n",
      "diplomat\n",
      "drummer\n",
      "engineer\n",
      "financier\n",
      "gambler\n",
      "gangster\n",
      "geek\n",
      "guitarist\n",
      "industrialist\n",
      "marshal\n",
      "mechanic\n",
      "philosopher\n",
      "physicist\n",
      "scientist\n",
      "rapper\n",
      "mechanic\n",
      "carpenter\n",
      "clergy\n",
      "1.6107385417909847\n",
      "aerobics\n",
      "beauty\n",
      "blonde\n",
      "cheerleader\n",
      "cheerleading\n",
      "cooking\n",
      "flirt\n",
      "flower\n",
      "gossip\n",
      "housekeeper\n",
      "housekeepers\n",
      "jewelry\n",
      "nanny\n",
      "nurse\n",
      "nurses\n",
      "pink\n",
      "pretty\n",
      "receptionist\n",
      "sewing\n",
      "softball\n",
      "submissive\n",
      "makeup\n",
      "therapist\n",
      "maid\n",
      "chairperson\n",
      "tycoon\n",
      "warrior\n",
      "trucker\n",
      "strong\n",
      "terrorist\n",
      "soldier\n",
      "sniper\n",
      "baseball\n",
      "sergeant\n",
      "bodyguard\n",
      "boss\n",
      "boxer\n",
      "captain\n",
      "carpenter\n",
      "chancellor\n",
      "colonel\n",
      "commander\n",
      "conductor\n",
      "diplomat\n",
      "drummer\n",
      "engineer\n",
      "financier\n",
      "gambler\n",
      "gangster\n",
      "geek\n",
      "guitarist\n",
      "industrialist\n",
      "marshal\n",
      "mechanic\n",
      "philosopher\n",
      "physicist\n",
      "scientist\n",
      "rapper\n",
      "mechanic\n",
      "carpenter\n",
      "clergy\n",
      "0.225483627796646\n",
      "aerobics\n",
      "beauty\n",
      "blonde\n",
      "cheerleader\n",
      "cheerleading\n",
      "cooking\n",
      "flirt\n",
      "flower\n",
      "gossip\n",
      "housekeeper\n",
      "housekeepers\n",
      "jewelry\n",
      "nanny\n",
      "nurse\n",
      "nurses\n",
      "pink\n",
      "pretty\n",
      "receptionist\n",
      "sewing\n",
      "softball\n",
      "submissive\n",
      "makeup\n",
      "therapist\n",
      "maid\n",
      "chairperson\n",
      "tycoon\n",
      "warrior\n",
      "trucker\n",
      "strong\n",
      "terrorist\n",
      "soldier\n",
      "sniper\n",
      "baseball\n",
      "sergeant\n",
      "bodyguard\n",
      "boss\n",
      "boxer\n",
      "captain\n",
      "carpenter\n",
      "chancellor\n",
      "colonel\n",
      "commander\n",
      "conductor\n",
      "diplomat\n",
      "drummer\n",
      "engineer\n",
      "financier\n",
      "gambler\n",
      "gangster\n",
      "geek\n",
      "guitarist\n",
      "industrialist\n",
      "marshal\n",
      "mechanic\n",
      "philosopher\n",
      "physicist\n",
      "scientist\n",
      "rapper\n",
      "mechanic\n",
      "carpenter\n",
      "clergy\n",
      "0.40590138772210144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3266292479044877,\n",
       " 1: 1.6107385417909847,\n",
       " 2: 0.225483627796646,\n",
       " 3: 0.40590138772210144}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_score_dict = {}\n",
    "for model_ind in range(len(models)):\n",
    "    gender_fill_bias_prior_corrected_score_list = []\n",
    "    for job in all_jobs:\n",
    "        print(job)\n",
    "        for k, i in enumerate(XX):\n",
    "    #         print([XX[k], YY[k]])\n",
    "            lpbs_values = bias_score(\n",
    "            \"the GGG is the XXX\",\n",
    "            [XX[k], YY[k]],\n",
    "            job,\n",
    "            tokenizer,\n",
    "            model_ind,\n",
    "            gender_comes_first=True,\n",
    "        )\n",
    "    #         print(lpbs_values[\"gender_fill_bias_prior_corrected\"]) \n",
    "            gender_fill_bias_prior_corrected_score_list.append(abs(lpbs_values[\"gender_fill_bias_prior_corrected\"]))\n",
    "\n",
    "\n",
    "    # compute average bias score over all jobs and words\n",
    "    average_gender_fill_bias_prior_corrected_score = sum(gender_fill_bias_prior_corrected_score_list)/len(gender_fill_bias_prior_corrected_score_list)\n",
    "    all_models_score_dict[model_ind] = (average_gender_fill_bias_prior_corrected_score)\n",
    "    print(average_gender_fill_bias_prior_corrected_score)\n",
    "all_models_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.3266292479044877,\n",
       " 1: 1.6107385417909847,\n",
       " 2: 0.225483627796646,\n",
       " 3: 0.40590138772210144}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
