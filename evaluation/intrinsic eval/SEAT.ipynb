{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# female_stereotype_list\n",
    "female_stereotype = open(\"female_stereotype.txt\", \"r\") \n",
    "data = female_stereotype.read()\n",
    "female_stereotype_list = data.split(\"\\n\")\n",
    "female_stereotype.close()\n",
    "\n",
    "\n",
    "# male_stereotype_liste\n",
    "male_stereotype = open(\"male_stereotype.txt\", \"r\")\n",
    "data = male_stereotype.read()\n",
    "male_stereotype_list = data.split(\"\\n\")\n",
    "male_stereotype.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# # model1 Pretrained model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# model1\n",
    "import torch\n",
    "# # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# # linear classification layer on top. \n",
    "model1 = BertModel.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model2 Context-debias\n",
    "import torch\n",
    "# tokenizer2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model2 = BertModel.from_pretrained('bert-large-uncased', state_dict=torch.load(\"../../../../kaneko_debiased_bert/context-debias-main/debiased_models/42/bert_large/checkpoint-best/pytorch_model.bin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model3 Sent-debias\n",
    "import torch\n",
    "# tokenizer2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model3 = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model4 CDA\n",
    "import torch\n",
    "# tokenizer2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model4 = BertModel.from_pretrained(\"bert-large-uncased\", state_dict=torch.load(\"../../../../CDA/counterfactual-data-substitution-master/zari-bert-cda/pytorch_model.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4]\n",
    "tokenizers = [tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_list = list(female_stereotype_list)\n",
    "male_list = list(male_stereotype_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gendered_word_list\n",
    "# gendered_word_list = [[\"she\", \"he\"],[\"female\", \"male\"], [\"woman\", \"man\"], [\"girl\", \"boy\"], [\"sister\", \"brother\"], [\"daughter\", \"son\"], [\"mother\", \"father\"]]\n",
    "XX = [\"female\", \"woman\", \"girl\", \"sister\", \"daughter\", \"mother\", \"aunt\", \"grandmother\"]\n",
    "YY = [\"male\", \"man\", \"boy\", \"brother\", \"son\", \"father\", \"uncle\", \"grandfather\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\"this is the _.\", \"that is the _.\", \"there is the _.\", \"here is the _.\", \"the _ is here.\", \"the _ is there.\", \"it is the _.\",\"the _ is a [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [\"temp1\", \"temp2\", \"temp3\", \"temp4\",\"temp5\", \"temp6\", \"temp7\", \"temp8\", \"temp9\", \"temp10\", \"temp11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(sentence, word):\n",
    "    toks = tokenizer(sentence).input_ids\n",
    "    wordpieces = tokenizer(word).input_ids\n",
    "#     print(toks)\n",
    "    word = wordpieces[1] # use first wordpiece\n",
    "    for i, t in enumerate(toks):\n",
    "        if t == word:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debias embeddings\n",
    "\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_gender_pair_embeddings():\n",
    "    with open('../../../../liang_sent_debias-master/debias-BERT/experiments/4_bert_large_saved_embs/num7993_a_pretrained.pkl', 'rb') as f:\n",
    "        all_embeddings_a = pickle.load(f)\n",
    "\n",
    "    with open('../../../../liang_sent_debias-master/debias-BERT/experiments/4_bert_large_saved_embs/num7993_b_pretrained.pkl', 'rb') as f:\n",
    "        all_embeddings_b = pickle.load(f)\n",
    "\n",
    "\n",
    "    means = (all_embeddings_a + all_embeddings_b) / 2.0\n",
    "    all_embeddings_a -= means\n",
    "    all_embeddings_b -= means\n",
    "    all_embeddings = np.concatenate([all_embeddings_a, all_embeddings_b], axis=0)\n",
    "    return all_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_embeddings = load_gender_pair_embeddings()\n",
    "\n",
    "\n",
    "def doPCA(matrix, num_components=10):\n",
    "\tpca = PCA(n_components=num_components, svd_solver=\"auto\")\n",
    "\tpca.fit(matrix) # Produce different results each time...\n",
    "\treturn pca\n",
    "\n",
    "\n",
    "def drop_bias(u, v):\n",
    "    return u - torch.ger(torch.matmul(u, v), v) / v.dot(v)\n",
    "\n",
    "\n",
    "def get_gender_dir(k):\n",
    "    gender_dir = doPCA(all_embeddings).components_[:k]\n",
    "    # if (not keepdims):\n",
    "    gender_dir = np.mean(gender_dir, axis=0)\n",
    "    logger.info(\"gender direction={} {} {}\".format(gender_dir.shape,\n",
    "            type(gender_dir), gender_dir[:10]))\n",
    "    gender_dir = torch.from_numpy(gender_dir)\n",
    "    return gender_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SWP first embedding\n",
    "def sentence_embedding(template, word, model_ind):\n",
    "    sentence = template.replace(\"_\", word)\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = models[model_ind](**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    token_embeddings = last_hidden_states\n",
    "    input_mask_expanded = inputs.attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    start = get_index(sentence, word)\n",
    "    embeddings = token_embeddings[0][start]\n",
    "    return embeddings.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# SWP first embedding\n",
    "def model3_sentence_embedding(template, word, model_ind):\n",
    "    model = models[model_ind]\n",
    "    sentence = template.replace(\"_\", word)\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    token_embeddings = last_hidden_states\n",
    "    for t in range(token_embeddings.shape[1]):\n",
    "        token_embeddings[:, t] = drop_bias(token_embeddings[:, t], gender_dir)\n",
    "        token_embeddings = torch.nn.functional.normalize(token_embeddings, p=2, dim=-1)\n",
    "    input_mask_expanded = inputs.attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    start = get_index(sentence, word)\n",
    "    embeddings = token_embeddings[0][start]\n",
    "    return embeddings.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(x, y):\n",
    "    return np.dot(x, y) / math.sqrt(np.dot(x, x) * np.dot(y, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_cossim_lookup(XY, AB):\n",
    "    \"\"\"\n",
    "    XY: mapping from target string to target vector (either in X or Y)\n",
    "    AB: mapping from attribute string to attribute vectore (either in A or B)\n",
    "    Returns an array of size (len(XY), len(AB)) containing cosine similarities\n",
    "    between items in XY and items in AB.\n",
    "    \"\"\"\n",
    "\n",
    "    cossims = np.zeros((len(XY), len(AB)))\n",
    "    for xy in XY:\n",
    "        for ab in AB:\n",
    "            cossims[xy, ab] = cossim(XY[xy], AB[ab])\n",
    "    return cossims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keys_to_ints(X, Y):\n",
    "    return (\n",
    "        dict((i, v) for (i, (k, v)) in enumerate(X.items())),\n",
    "        dict((i + len(X), v) for (i, (k, v)) in enumerate(Y.items())),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def s_XAB(A, s_wAB_memo):\n",
    "    return s_wAB_memo[A].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_wAB(X, Y, cossims):\n",
    "    \"\"\"\n",
    "    Return vector of s(w, A, B) across w, where\n",
    "        s(w, A, B) = mean_{a in A} cos(w, a) - mean_{b in B} cos(w, b).\n",
    "    \"\"\"\n",
    "    return cossims[X, :].mean(axis=0) - cossims[Y, :].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_XAB_df(A, B, s_wAB_memo):\n",
    "    df1 = pd.DataFrame(s_wAB_memo[A])\n",
    "    df2 = pd.DataFrame(s_wAB_memo[B])\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_XYAB(A, B, s_wAB_memo):\n",
    "    r\"\"\"\n",
    "    Given indices of target concept X and precomputed s_wAB values,\n",
    "    the WEAT test statistic for p-value computation.\n",
    "    \"\"\"\n",
    "    return s_XAB(A, s_wAB_memo) - s_XAB(B, s_wAB_memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WEAT_test(X, Y, A, B, n_samples, cossims):\n",
    "    ''' Compute the p-val for the permutation test, which is defined as\n",
    "        the probability that a random even partition X_i, Y_i of X u Y\n",
    "        satisfies P[s(X_i, Y_i, A, B) > s(X, Y, A, B)]\n",
    "    '''\n",
    "    X = np.array(list(X), dtype=np.int)\n",
    "    Y = np.array(list(Y), dtype=np.int)\n",
    "    A = np.array(list(A), dtype=np.int)\n",
    "    B = np.array(list(B), dtype=np.int)\n",
    "\n",
    "    assert len(X) == len(Y)\n",
    "    size = len(X)\n",
    "    s_wAB_memo = s_wAB(X, Y, cossims=cossims)\n",
    "    XY = np.concatenate((X, Y))\n",
    "\n",
    "\n",
    "    s = s_XYAB(A, B, s_wAB_memo)\n",
    "    return s\n",
    "\n",
    "\n",
    "def convert_keys_to_ints(X, Y):\n",
    "    return (\n",
    "        dict((i, v) for (i, (k, v)) in enumerate(X.items())),\n",
    "        dict((i + len(X), v) for (i, (k, v)) in enumerate(Y.items())),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effect_size(df1, df2, k=0):\n",
    "    diff = (df1[k].mean() - df2[k].mean())\n",
    "    std_ = pd.concat([df1, df2], axis=0)[k].std() + 1e-8\n",
    "    return diff / std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.6239635580176857\n",
      "1\n",
      "0.3652346837031964\n",
      "2\n",
      "1.6242898579344123\n",
      "3\n",
      "1.340075283883311\n",
      "0\n",
      "1.6071278176986008\n",
      "1\n",
      "0.31627028386638095\n",
      "2\n",
      "1.608358418028016\n",
      "3\n",
      "1.5089758469212187\n",
      "0\n",
      "1.5217741410325767\n",
      "1\n",
      "0.05824415570862318\n",
      "2\n",
      "1.5218751527597913\n",
      "3\n",
      "1.3201387818889876\n",
      "0\n",
      "1.4770595779850684\n",
      "1\n",
      "0.5257678541030162\n",
      "2\n",
      "1.4775274962839435\n",
      "3\n",
      "1.3914654641989752\n",
      "0\n",
      "1.570224662780473\n",
      "1\n",
      "0.3905907087468089\n",
      "2\n",
      "1.570996816935041\n",
      "3\n",
      "0.4497110054647657\n",
      "0\n",
      "1.6475621836149925\n",
      "1\n",
      "-0.05282674089465071\n",
      "2\n",
      "1.6479510380072386\n",
      "3\n",
      "0.4897858485806677\n",
      "0\n",
      "1.532952782910619\n",
      "1\n",
      "0.3105679679696524\n",
      "2\n",
      "1.5334169033812621\n",
      "3\n",
      "1.2228405926748434\n",
      "0\n",
      "1.6177424708230268\n",
      "1\n",
      "-0.147007102125903\n",
      "2\n",
      "1.6172852952823416\n",
      "3\n",
      "0.7817368119372631\n"
     ]
    }
   ],
   "source": [
    "gender_dir = get_gender_dir(1)\n",
    "\n",
    "template_score_dict = {}\n",
    "for ind, template in enumerate(templates):\n",
    "    score_dict = {}\n",
    "    attribute_template = template\n",
    "    target_template = template\n",
    "    for model_ind in range(len(models)):\n",
    "        print(model_ind)\n",
    "        if model_ind == 2:\n",
    "            X = {\"x\" + str(j): sentence_embedding(attribute_template, j, model_ind) for j in XX}\n",
    "            Y = {\"y\" + str(j): sentence_embedding(attribute_template, j, model_ind) for j in YY}\n",
    "            (X, Y) = convert_keys_to_ints(X, Y)\n",
    "            XY = X.copy()\n",
    "            XY.update(Y)\n",
    "            X = np.array(list(X), dtype=np.int)\n",
    "            Y = np.array(list(Y), dtype=np.int)\n",
    "            AA = female_list\n",
    "            BB = male_list\n",
    "\n",
    "            A = {\"a\" + str(j): model3_sentence_embedding(target_template, j, model_ind) for j in AA}\n",
    "            B = {\"b\" + str(j): model3_sentence_embedding(target_template, j, model_ind) for j in BB}\n",
    "\n",
    "            (A, B) = convert_keys_to_ints(A, B)\n",
    "\n",
    "\n",
    "            AB = A.copy()\n",
    "            AB.update(B)\n",
    "\n",
    "            cossims = construct_cossim_lookup(XY, AB)\n",
    "            A = np.array(list(A), dtype=np.int)\n",
    "            B = np.array(list(B), dtype=np.int)\n",
    "\n",
    "\n",
    "            s_wAB_memo = s_wAB(X, Y, cossims=cossims)\n",
    "            df1,df2 = s_XAB_df(A, B, s_wAB_memo)\n",
    "            effect_size = get_effect_size(df1, df2)\n",
    "            score_dict[model_ind] = effect_size\n",
    "            print(score_dict[model_ind])\n",
    "        else:\n",
    "            X = {\"x\" + str(j): sentence_embedding(attribute_template, j, model_ind) for j in XX}\n",
    "            Y = {\"y\" + str(j): sentence_embedding(attribute_template, j, model_ind) for j in YY}\n",
    "            (X, Y) = convert_keys_to_ints(X, Y)\n",
    "            XY = X.copy()\n",
    "            XY.update(Y)\n",
    "            X = np.array(list(X), dtype=np.int)\n",
    "            Y = np.array(list(Y), dtype=np.int)\n",
    "            AA = female_list\n",
    "            BB = male_list\n",
    "\n",
    "            A = {\"a\" + str(j): sentence_embedding(target_template, j, model_ind) for j in AA}\n",
    "            B = {\"b\" + str(j): sentence_embedding(target_template, j, model_ind) for j in BB}\n",
    "\n",
    "            (A, B) = convert_keys_to_ints(A, B)\n",
    "\n",
    "\n",
    "            AB = A.copy()\n",
    "            AB.update(B)\n",
    "\n",
    "            cossims = construct_cossim_lookup(XY, AB)\n",
    "            A = np.array(list(A), dtype=np.int)\n",
    "            B = np.array(list(B), dtype=np.int)\n",
    "\n",
    "\n",
    "            s_wAB_memo = s_wAB(X, Y, cossims=cossims)\n",
    "            df1,df2 = s_XAB_df(A, B, s_wAB_memo)\n",
    "            effect_size = get_effect_size(df1, df2)\n",
    "            score_dict[model_ind] = effect_size\n",
    "            print(score_dict[model_ind])\n",
    "    template_score_dict[temps[ind]] = score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(template_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp1</th>\n",
       "      <th>temp2</th>\n",
       "      <th>temp3</th>\n",
       "      <th>temp4</th>\n",
       "      <th>temp5</th>\n",
       "      <th>temp6</th>\n",
       "      <th>temp7</th>\n",
       "      <th>temp8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.623964</td>\n",
       "      <td>1.607128</td>\n",
       "      <td>1.521774</td>\n",
       "      <td>1.477060</td>\n",
       "      <td>1.570225</td>\n",
       "      <td>1.647562</td>\n",
       "      <td>1.532953</td>\n",
       "      <td>1.617742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365235</td>\n",
       "      <td>0.316270</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.525768</td>\n",
       "      <td>0.390591</td>\n",
       "      <td>-0.052827</td>\n",
       "      <td>0.310568</td>\n",
       "      <td>-0.147007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.624290</td>\n",
       "      <td>1.608358</td>\n",
       "      <td>1.521875</td>\n",
       "      <td>1.477527</td>\n",
       "      <td>1.570997</td>\n",
       "      <td>1.647951</td>\n",
       "      <td>1.533417</td>\n",
       "      <td>1.617285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.340075</td>\n",
       "      <td>1.508976</td>\n",
       "      <td>1.320139</td>\n",
       "      <td>1.391465</td>\n",
       "      <td>0.449711</td>\n",
       "      <td>0.489786</td>\n",
       "      <td>1.222841</td>\n",
       "      <td>0.781737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      temp1     temp2     temp3     temp4     temp5     temp6     temp7  \\\n",
       "0  1.623964  1.607128  1.521774  1.477060  1.570225  1.647562  1.532953   \n",
       "1  0.365235  0.316270  0.058244  0.525768  0.390591 -0.052827  0.310568   \n",
       "2  1.624290  1.608358  1.521875  1.477527  1.570997  1.647951  1.533417   \n",
       "3  1.340075  1.508976  1.320139  1.391465  0.449711  0.489786  1.222841   \n",
       "\n",
       "      temp8  \n",
       "0  1.617742  \n",
       "1 -0.147007  \n",
       "2  1.617285  \n",
       "3  0.781737  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
