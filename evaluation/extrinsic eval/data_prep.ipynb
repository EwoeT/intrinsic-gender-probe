{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM3-32GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "# random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print('No GPU available, using the CPU instead.')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################### Load dataset ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['countrywoman', 'sororal', 'witches', 'maidservant', 'mothers', 'diva', 'actress', 'spinster', 'mama', 'duchesses', 'barwoman', 'countrywomen', 'dowry', 'hostesses', 'airwomen', 'menopause', 'clitoris', 'princess', 'governesses', 'abbess', 'women', 'widow', 'ladies', 'sorceresses', 'madam', 'brides', 'baroness', 'housewives', 'godesses', 'niece', 'widows', 'lady', 'sister', 'brides', 'nun', 'adultresses', 'obstetrics', 'bellgirls', 'her', 'marchioness', 'princesses', 'empresses', 'mare', 'chairwoman', 'convent', 'priestesses', 'girlhood', 'ladies', 'queen', 'gals', 'mommies', 'maid', 'female_ejaculation', 'spokeswoman', 'seamstress', 'cowgirls', 'chick', 'spinsters', 'hair_salon', 'empress', 'mommy', 'feminism', 'gals', 'enchantress', 'gal', 'motherhood', 'estrogen', 'camerawomen', 'godmother', 'strongwoman', 'goddess', 'matriarch', 'aunt', 'chairwomen', \"ma'am\", 'sisterhood', 'hostess', 'estradiol', 'wife', 'mom', 'stewardess', 'females', 'viagra', 'spokeswomen', 'ma', 'belle', 'minx', 'maiden', 'witch', 'miss', 'nieces', 'mothered', 'cow', 'belles', 'councilwomen', 'landladies', 'granddaughter', 'fiancees', 'stepmothers', 'horsewomen', 'grandmothers', 'adultress', 'schoolgirl', 'hen', 'granddaughters', 'bachelorette', 'camerawoman', 'moms', 'her', 'mistress', 'lass', 'policewoman', 'nun', 'actresses', 'saleswomen', 'girlfriend', 'councilwoman', 'lady', 'stateswoman', 'maternal', 'lass', 'landlady', 'sistren', 'ladies', 'wenches', 'sorority', 'bellgirl', 'duchess', 'ballerina', 'chicks', 'fiancee', 'fillies', 'wives', 'suitress', 'maternity', 'she', 'businesswoman', 'masseuses', 'heroine', 'doe', 'busgirls', 'girlfriends', 'queens', 'sisters', 'mistresses', 'stepmother', 'brides', 'daughter', 'minxes', 'cowgirl', 'lady', 'daughters', 'mezzo', 'saleswoman', 'mistress', 'hostess', 'nuns', 'maids', 'mrs.', 'headmistresses', 'lasses', 'congresswoman', 'airwoman', 'housewife', 'priestess', 'barwomen', 'barnoesses', 'abbesses', 'handywoman', 'toque', 'sororities', 'stewardesses', 'filly', 'czarina', 'stepdaughters', 'herself', 'girls', 'lionesses', 'lady', 'vagina', 'hers', 'masseuse', 'cows', 'aunts', 'wench', 'toques', 'wife', 'lioness', 'sorceress', 'effeminate', 'mother', 'lesbians', 'female', 'waitresses', 'ovum', 'skene_gland', 'stepdaughter', 'womb', 'businesswomen', 'heiress', 'waitress', 'headmistress', 'woman', 'governess', 'godess', 'bride', 'grandma', 'bride', 'gal', 'lesbian', 'ladies', 'girl', 'grandmother', 'mare', 'maternity', 'hens', 'uterus', 'nuns', 'maidservants', \"seamstress'\", 'busgirl', 'heroines', 'countryman', 'fraternal', 'wizards', 'manservant', 'fathers', 'divo', 'actor', 'bachelor', 'papa', 'dukes', 'barman', 'countrymen', 'brideprice', 'hosts', 'airmen', 'andropause', 'penis', 'prince', 'governors', 'abbot', 'men', 'widower', 'gentlemen', 'sorcerers', 'sir', 'bridegrooms', 'baron', 'househusbands', 'gods', 'nephew', 'widowers', 'lord', 'brother', 'grooms', 'priest', 'adultors', 'andrology', 'bellboys', 'his', 'marquis', 'princes', 'emperors', 'stallion', 'chairman', 'monastery', 'priests', 'boyhood', 'fellas', 'king', 'dudes', 'daddies', 'manservant', 'semen', 'spokesman', 'tailor', 'cowboys', 'dude', 'bachelors', 'barbershop', 'emperor', 'daddy', 'masculism', 'guys', 'enchanter', 'guy', 'fatherhood', 'androgen', 'cameramen', 'godfather', 'strongman', 'god', 'patriarch', 'uncle', 'chairmen', 'sir', 'brotherhood', 'host', 'testosterone', 'husband', 'dad', 'steward', 'males', 'cialis', 'spokesmen', 'pa', 'beau', 'stud', 'bachelor', 'wizard', 'sir', 'nephews', 'fathered', 'bull', 'beaus', 'councilmen', 'landlords', 'grandson', 'fiances', 'stepfathers', 'horsemen', 'grandfathers', 'adultor', 'schoolboy', 'rooster', 'grandsons', 'bachelor', 'cameraman', 'dads', 'him', 'master', 'lad', 'policeman', 'monk', 'actors', 'salesmen', 'boyfriend', 'councilman', 'fella', 'statesman', 'paternal', 'chap', 'landlord', 'brethren', 'lords', 'blokes', 'fraternity', 'bellboy', 'duke', 'ballet_dancer', 'dudes', 'fiance', 'colts', 'husbands', 'suitor', 'paternity', 'he', 'businessman', 'masseurs', 'hero', 'deer', 'busboys', 'boyfriends', 'kings', 'brothers', 'masters', 'stepfather', 'grooms', 'son', 'studs', 'cowboy', 'mentleman', 'sons', 'baritone', 'salesman', 'paramour', 'male_host', 'monks', 'menservants', 'mr.', 'headmasters', 'lads', 'congressman', 'airman', 'househusband', 'priest', 'barmen', 'barons', 'abbots', 'handyman', 'beard', 'fraternities', 'stewards', 'colt', 'czar', 'stepsons', 'himself', 'boys', 'lions', 'gentleman', 'penis', 'his', 'masseur', 'bulls', 'uncles', 'bloke', 'beards', 'hubby', 'lion', 'sorcerer', 'macho', 'father', 'gays', 'male', 'waiters', 'sperm', 'prostate', 'stepson', 'prostatic_utricle', 'businessmen', 'heir', 'waiter', 'headmaster', 'man', 'governor', 'god', 'bridegroom', 'grandpa', 'groom', 'dude', 'gay', 'gents', 'boy', 'grandfather', 'gelding', 'paternity', 'roosters', 'prostatic_utricle', 'priests', 'manservants', 'stailor', 'busboy', 'heros', '']\n"
     ]
    }
   ],
   "source": [
    "all_attribute = open(\"attrribute_names_lists/all_attributes.txt\", \"r\") \n",
    "data = all_attribute.read()\n",
    "all_attribute_list = data.split(\"\\n\")\n",
    "print((all_attribute_list))\n",
    "all_attribute.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale', 'Abra', 'Acacia', 'Ada', 'Adah', 'Adaline', 'Adara', 'Addie', 'Addis', 'Adel', 'Adela', 'Adelaide', 'Adele', 'Adelice', 'Adelina', 'Adelind', 'Adeline', 'Adella', 'Adelle', 'Adena', 'Adey', 'Adi', 'Adiana', 'Adina', 'Adora', 'Adore', 'Adoree', 'Adorne', 'Adrea', 'Adria', 'Adriaens', 'Adrian', 'Adriana', 'Adriane', 'Adrianna', 'Adrianne', 'Adrien', 'Adriena', 'Adrienne', 'Aeriel', 'Aeriela', 'Aeriell', 'Ag', 'Agace', 'Agata', 'Agatha', 'Agathe', 'Aggi', 'Aggie', 'Aggy', 'Agna', 'Agnella', 'Agnes', 'Agnese', 'Agnesse', 'Agneta', 'Agnola', 'Agretha', 'Aida', 'Aidan', 'Aigneis', 'Aila', 'Aile', 'Ailee', 'Aileen', 'Ailene', 'Ailey', 'Aili', 'Ailina', 'Ailyn', 'Aime', 'Aimee', 'Aimil', 'Aina', 'Aindrea', 'Ainslee', 'Ainsley', 'Ainslie', 'Ajay', 'Alaine', 'Alameda', 'Alana', 'Alanah', 'Alane', 'Alanna', 'Alayne', 'Alberta', 'Albertina', 'Albertine', 'Albina', 'Alecia', 'Aleda', 'Aleece', 'Aleecia', 'Aleen', 'Alejandra', 'Alejandrina', 'Alena', 'Alene', 'Alessandra', 'Aleta', 'Alethea', 'Alex', 'Alexa', 'Alexandra', 'Alexandrina', 'Alexi', 'Alexia', 'Alexina', 'Alexine', 'Alexis', 'Alfie', 'Alfreda', 'Ali', 'Alia', 'Alica', 'Alice', 'Alicea', 'Alicia', 'Alida', 'Alidia', 'Alina', 'Aline', 'Alis', 'Alisa', 'Alisha', 'Alison', 'Alissa', 'Alisun', 'Alix', 'Aliza', 'Alla', 'Alleen', 'Allegra', 'Allene', 'Alli', 'Allianora', 'Allie', 'Allina', 'Allis', 'Allison', 'Allissa', 'Allsun', 'Ally', 'Allyce', 'Allyn', 'Allys', 'Allyson', 'Alma', 'Almeda', 'Almeria', 'Almeta', 'Almira', 'Almire', 'Aloise', 'Aloisia', 'Aloysia', 'Alpa', 'Alta', 'Althea', 'Alvera', 'Alvina', 'Alvinia', 'Alvira', 'Alyce', 'Alyda', 'Alys', 'Alysa', 'Alyse', 'Alysia', 'Alyson', 'Alyss', 'Alyssa', 'Amabel', 'Amabelle', 'Amalea', 'Amalee', 'Amaleta', 'Amalia', 'Amalie', 'Amalita', 'Amalle', 'Amanda', 'Amandi', 'Amandie', 'Amandy', 'Amara', 'Amargo', 'Amata', 'Amber', 'Amberly', 'Ambrosia', 'Ambur', 'Ame', 'Amelia', 'Amelie', 'Amelina', 'Ameline', 'Amelita', 'Ami', 'Amie', 'Amity', 'Ammamaria', 'Amy', 'Ana', 'Anabel', 'Anabella', 'Anabelle', 'Anais', 'Analiese', 'Analise', 'Anallese', 'Anallise', 'Anastasia', 'Anastasie', 'Anastassia', 'Anatola', 'Andee', 'Andi', 'Andie', 'Andra', 'Andrea', 'Andreana', 'Andree', 'Andrei', 'Andria', 'Andriana', 'Andriette', 'Andromache', 'Andromeda', 'Andy', 'Anestassia', 'Anet', 'Anett', 'Anetta', 'Anette', 'Ange', 'Angel', 'Angela', 'Angele', 'Angelia', 'Angelica', 'Angelika', 'Angelina', 'Angeline', 'Angelique', 'Angelita', 'Angelle', 'Angie', 'Angil', 'Angy', 'Ania', 'Anica', 'Anissa', 'Anita', 'Anitra', 'Anja', 'Anjanette', 'Anjela', 'Ann', 'Ann-Mari', 'Ann-Marie', 'Anna', 'Anna-Diana', 'Anna-Diane', 'Anna-Maria', 'Annabal', 'Annabel', 'Annabela', 'Annabell', 'Annabella', 'Annabelle', 'Annadiana', 'Annadiane', 'Annalee', 'Annalena', 'Annaliese', 'Annalisa', 'Annalise', 'Annalyse', 'Annamari', 'Annamaria', 'Annamarie', 'Anne', 'Anne-Corinne', 'Anne-Mar', 'Anne-Marie', 'Annecorinne', 'Anneliese', 'Annelise', 'Annemarie', 'Annetta', 'Annette', 'Anni', 'Annice', 'Annie', 'Annissa', 'Annmaria', 'Annmarie', 'Annnora', 'Annora', 'Anny', 'Anselma', 'Ansley', 'Anstice', 'Anthe', 'Anthea', 'Anthia', 'Antoinette', 'Antonella', 'Antonetta', 'Antonia', 'Antonie', 'Antonietta', 'Antonina', 'Anya', 'Aphrodite', 'Appolonia', 'April', 'Aprilette', 'Ara', 'Arabel', 'Arabela', 'Arabele', 'Arabella', 'Arabelle', 'Arda', 'Ardath', 'Ardeen', 'Ardelia', 'Ardelis', 'Ardella', 'Ardelle', 'Arden', 'Ardene', 'Ardenia', 'Ardine', 'Ardis', 'Ardith', 'Ardra', 'Ardyce', 'Ardys', 'Ardyth', 'Aretha', 'Ariadne', 'Ariana', 'Arianne', 'Aridatha', 'Ariel', 'Ariela', 'Ariella', 'Arielle', 'Arlana', 'Arlee', 'Arleen', 'Arlen', 'Arlena', 'Arlene', 'Arleta', 'Arlette', 'Arleyne', 'Arlie', 'Arliene', 'Arlina', 'Arlinda', 'Arline', 'Arly', 'Arlyn', 'Arlyne', 'Aryn', 'Ashely', 'Ashlee', 'Ashleigh', 'Ashlen', 'Ashley', 'Ashli', 'Ashlie', 'Ashly', 'Asia', 'Astra', 'Astrid', 'Astrix', 'Atalanta', 'Athena', 'Athene', 'Atlanta', 'Atlante', 'Auberta', 'Aubine', 'Aubree', 'Aubrette', 'Aubrey', 'Aubrie', 'Aubry', 'Audi', 'Audie', 'Audra', 'Audre', 'Audrey', 'Audrie', 'Audry', 'Audrye', 'Audy', 'Augusta', 'Auguste', 'Augustina', 'Augustine', 'Aura', 'Aurea', 'Aurel', 'Aurelea', 'Aurelia', 'Aurelie', 'Auria', 'Aurie', 'Aurilia', 'Aurlie', 'Auroora', 'Aurora', 'Aurore', 'Austin', 'Austina', 'Austine', 'Ava', 'Aveline', 'Averil', 'Averyl', 'Avie', 'Avis', 'Aviva', 'Avivah', 'Avril', 'Avrit', 'Ayn', 'Bab', 'Babara', 'Babette', 'Babita', 'Babs', 'Bambi', 'Bambie', 'Bamby', 'Barb', 'Barbabra', 'Barbara', 'Barbara-Anne', 'Barbaraanne', 'Barbe', 'Barbee', 'Barbette', 'Barbey', 'Barbi', 'Barbie', 'Barbra', 'Barby', 'Bari', 'Barrie', 'Barry', 'Basia', 'Bathsheba', 'Batsheva', 'Bea', 'Beatrice', 'Beatrisa', 'Beatrix', 'Beatriz', 'Beau', 'Bebe', 'Becca', 'Becka', 'Becki', 'Beckie', 'Becky', 'Bee', 'Beilul', 'Beitris', 'Bekki', 'Bel', 'Belia', 'Belicia', 'Belinda', 'Belita', 'Bell', 'Bella', 'Bellamy', 'Bellanca', 'Belle', 'Bellina', 'Belva', 'Belvia', 'Bendite', 'Benedetta', 'Benedicta', 'Benedikta', 'Benetta', 'Benita', 'Benni', 'Bennie', 'Benny', 'Benoite', 'Berenice', 'Beret', 'Berget', 'Berna', 'Bernadene', 'Bernadette', 'Bernadina', 'Bernadine', 'Bernardina', 'Bernardine', 'Bernelle', 'Bernete', 'Bernetta', 'Bernette', 'Berni', 'Bernice', 'Bernie', 'Bernita', 'Berny', 'Berri', 'Berrie', 'Berry', 'Bert', 'Berta', 'Berte', 'Bertha', 'Berthe', 'Berti', 'Bertie', 'Bertina', 'Bertine', 'Berty', 'Beryl', 'Beryle', 'Bess', 'Bessie', 'Bessy', 'Beth', 'Bethanne', 'Bethany', 'Bethena', 'Bethina', 'Betsey', 'Betsy', 'Betta', 'Bette', 'Bette-Ann', 'Betteann', 'Betteanne', 'Betti', 'Bettie', 'Bettina', 'Bettine', 'Betty', 'Bettye', 'Beulah', 'Bev', 'Beverie', 'Beverlee', 'Beverlie', 'Beverly', 'Bevvy', 'Bianca', 'Bianka', 'Biddy', 'Bidget', 'Bill', 'Billi', 'Billie', 'Billy', 'Binni', 'Binnie', 'Binny', 'Bird', 'Birdie', 'Birgit', 'Birgitta', 'Blair', 'Blaire', 'Blake', 'Blakelee', 'Blakeley', 'Blanca', 'Blanch', 'Blancha', 'Blanche', 'Blinni', 'Blinnie', 'Blinny', 'Bliss', 'Blisse', 'Blithe', 'Blondell', 'Blondelle', 'Blondie', 'Blondy', 'Blythe', 'Bo', 'Bobbette', 'Bobbi', 'Bobbie', 'Bobby', 'Bobette', 'Bobina', 'Bobine', 'Bobinette', 'Bonita', 'Bonnee', 'Bonni', 'Bonnie', 'Bonny', 'Brana', 'Brandais', 'Brande', 'Brandea', 'Brandi', 'Brandice', 'Brandie', 'Brandise', 'Brandy', 'Brea', 'Breanne', 'Brear', 'Bree', 'Breena', 'Bren', 'Brena', 'Brenda', 'Brenn', 'Brenna', 'Brett', 'Bria', 'Briana', 'Brianna', 'Brianne', 'Bride', 'Bridget', 'Bridgett', 'Bridgette', 'Bridie', 'Brier', 'Brietta', 'Brigid', 'Brigida', 'Brigit', 'Brigitta', 'Brigitte', 'Brina', 'Briney', 'Briny', 'Brit', 'Brita', 'Britaney', 'Britani', 'Briteny', 'Britney', 'Britni', 'Britt', 'Britta', 'Brittan', 'Brittany', 'Britte', 'Brittney', 'Brook', 'Brooke', 'Brooks', 'Brunella', 'Brunhilda', 'Brunhilde', 'Bryana', 'Bryn', 'Bryna', 'Brynn', 'Brynna', 'Brynne', 'Buffy', 'Bunni', 'Bunnie', 'Bunny', 'Burta', 'Cabrina', 'Cacilia', 'Cacilie', 'Caitlin', 'Caitrin', 'Cal', 'Calida', 'Calla', 'Calley', 'Calli', 'Callida', 'Callie', 'Cally', 'Calypso', 'Cam', 'Camala', 'Camel', 'Camella', 'Camellia', 'Cameo', 'Cami', 'Camila', 'Camile', 'Camilla', 'Camille', 'Cammi', 'Cammie', 'Cammy', 'Canada', 'Candace', 'Candi', 'Candice', 'Candida', 'Candide', 'Candie', 'Candis', 'Candra', 'Candy', 'Cappella', 'Caprice', 'Cara', 'Caralie', 'Caren', 'Carena', 'Caresa', 'Caressa', 'Caresse', 'Carey', 'Cari', 'Caria', 'Carie', 'Caril', 'Carilyn', 'Carin', 'Carina', 'Carine', 'Cariotta', 'Carissa', 'Carita', 'Caritta', 'Carla', 'Carlee', 'Carleen', 'Carlen', 'Carlena', 'Carlene', 'Carley', 'Carli', 'Carlie', 'Carlin', 'Carlina', 'Carline', 'Carlisle', 'Carlita', 'Carlota', 'Carlotta', 'Carly', 'Carlye', 'Carlyn', 'Carlynn', 'Carlynne', 'Carma', 'Carmel', 'Carmela', 'Carmelia', 'Carmelina', 'Carmelita', 'Carmella', 'Carmelle', 'Carmen', 'Carmina', 'Carmine', 'Carmita', 'Carmon', 'Caro', 'Carol', 'Carol-Jean', 'Carola', 'Carolan', 'Carolann', 'Carole', 'Carolee', 'Caroleen', 'Carolie', 'Carolin', 'Carolina', 'Caroline', 'Caroljean', 'Carolyn', 'Carolyne', 'Carolynn', 'Caron', 'Carree', 'Carri', 'Carrie', 'Carrissa', 'Carrol', 'Carroll', 'Carry', 'Cary', 'Caryl', 'Caryn', 'Casandra', 'Casey', 'Casi', 'Casia', 'Casie', 'Cass', 'Cassandra', 'Cassandre', 'Cassandry', 'Cassaundra', 'Cassey', 'Cassi', 'Cassie', 'Cassondra', 'Cassy', 'Cat', 'Catarina', 'Cate', 'Caterina', 'Catha', 'Catharina', 'Catharine', 'Cathe', 'Cathee', 'Catherin', 'Catherina', 'Catherine', 'Cathi', 'Cathie', 'Cathleen', 'Cathlene', 'Cathrin', 'Cathrine', 'Cathryn', 'Cathy', 'Cathyleen', 'Cati', 'Catie', 'Catina', 'Catlaina', 'Catlee', 'Catlin', 'Catrina', 'Catriona', 'Caty', 'Cayla', 'Cecelia', 'Cecil', 'Cecile', 'Ceciley', 'Cecilia', 'Cecilla', 'Cecily', 'Ceil', 'Cele', 'Celene', 'Celesta', 'Celeste', 'Celestia', 'Celestina', 'Celestine', 'Celestyn', 'Celestyna', 'Celia', 'Celie', 'Celina', 'Celinda', 'Celine', 'Celinka', 'Celisse', 'Celle', 'Cesya', 'Chad', 'Chanda', 'Chandal', 'Chandra', 'Channa', 'Chantal', 'Chantalle', 'Charil', 'Charin', 'Charis', 'Charissa', 'Charisse', 'Charita', 'Charity', 'Charla', 'Charlean', 'Charleen', 'Charlena', 'Charlene', 'Charline', 'Charlot', 'Charlott', 'Charlotta', 'Charlotte', 'Charmain', 'Charmaine', 'Charmane', 'Charmian', 'Charmine', 'Charmion', 'Charo', 'Charyl', 'Chastity', 'Chelsae', 'Chelsea', 'Chelsey', 'Chelsie', 'Chelsy', 'Cher', 'Chere', 'Cherey', 'Cheri', 'Cherianne', 'Cherice', 'Cherida', 'Cherie', 'Cherilyn', 'Cherilynn', 'Cherin', 'Cherise', 'Cherish', 'Cherlyn', 'Cherri', 'Cherrita', 'Cherry', 'Chery', 'Cherye', 'Cheryl', 'Cheslie', 'Chiarra', 'Chickie', 'Chicky', 'Chiquita', 'Chloe', 'Chloette', 'Chloris', 'Chris', 'Chriss', 'Chrissa', 'Chrissie', 'Chrissy', 'Christa', 'Christabel', 'Christabella', 'Christabelle', 'Christal', 'Christalle', 'Christan', 'Christean', 'Christel', 'Christen', 'Christi', 'Christian', 'Christiana', 'Christiane', 'Christie', 'Christin', 'Christina', 'Christine', 'Christy', 'Christyna', 'Chrysa', 'Chrysler', 'Chrystal', 'Chryste', 'Chrystel', 'Ciara', 'Cicely', 'Cicily', 'Ciel', 'Cilka', 'Cinda', 'Cindee', 'Cindelyn', 'Cinderella', 'Cindi', 'Cindie', 'Cindra', 'Cindy', 'Cinnamon', 'Cissie', 'Cissy', 'Clair', 'Claire', 'Clara', 'Clarabelle', 'Clare', 'Claresta', 'Clareta', 'Claretta', 'Clarette', 'Clarey', 'Clari', 'Claribel', 'Clarice', 'Clarie', 'Clarinda', 'Clarine', 'Clarisa', 'Clarissa', 'Clarisse', 'Clarita', 'Clary', 'Claude', 'Claudelle', 'Claudetta', 'Claudette', 'Claudia', 'Claudie', 'Claudina', 'Claudine', 'Clea', 'Clem', 'Clemence', 'Clementia', 'Clementina', 'Clementine', 'Clemmie', 'Clemmy', 'Cleo', 'Cleopatra', 'Clerissa', 'Cleva', 'Clio', 'Clo', 'Cloe', 'Cloris', 'Clotilda', 'Clovis', 'Codee', 'Codi', 'Codie', 'Cody', 'Coleen', 'Colene', 'Coletta', 'Colette', 'Colleen', 'Collete', 'Collette', 'Collie', 'Colline', 'Colly', 'Con', 'Concettina', 'Conchita', 'Concordia', 'Conney', 'Conni', 'Connie', 'Conny', 'Consolata', 'Constance', 'Constancia', 'Constancy', 'Constanta', 'Constantia', 'Constantina', 'Constantine', 'Consuela', 'Consuelo', 'Cookie', 'Cora', 'Corabel', 'Corabella', 'Corabelle', 'Coral', 'Coralie', 'Coraline', 'Coralyn', 'Cordelia', 'Cordelie', 'Cordey', 'Cordie', 'Cordula', 'Cordy', 'Coreen', 'Corella', 'Corena', 'Corenda', 'Corene', 'Coretta', 'Corette', 'Corey', 'Cori', 'Corie', 'Corilla', 'Corina', 'Corine', 'Corinna', 'Corinne', 'Coriss', 'Corissa', 'Corliss', 'Corly', 'Cornela', 'Cornelia', 'Cornelle', 'Cornie', 'Corny', 'Correna', 'Correy', 'Corri', 'Corrianne', 'Corrie', 'Corrina', 'Corrine', 'Corrinne', 'Corry', 'Cortney', 'Cory', 'Cosetta', 'Cosette', 'Courtenay', 'Courtney', 'Cresa', 'Cris', 'Crissie', 'Crissy', 'Crista', 'Cristabel', 'Cristal', 'Cristen', 'Cristi', 'Cristie', 'Cristin', 'Cristina', 'Cristine', 'Cristionna', 'Cristy', 'Crysta', 'Crystal', 'Crystie', 'Cyb', 'Cybal', 'Cybel', 'Cybelle', 'Cybil', 'Cybill', 'Cyndi', 'Cyndy', 'Cynthea', 'Cynthia', 'Cynthie', 'Cynthy', 'Dacey', 'Dacia', 'Dacie', 'Dacy', 'Dael', 'Daffi', 'Daffie', 'Daffy', 'Dafna', 'Dagmar', 'Dahlia', 'Daile', 'Daisey', 'Daisi', 'Daisie', 'Daisy', 'Dale', 'Dalenna', 'Dalia', 'Dalila', 'Dallas', 'Daloris', 'Damara', 'Damaris', 'Damita', 'Dana', 'Danell', 'Danella', 'Danelle', 'Danette', 'Dani', 'Dania', 'Danica', 'Danice', 'Daniel', 'Daniela', 'Daniele', 'Daniella', 'Danielle', 'Danika', 'Danila', 'Danit', 'Danita', 'Danna', 'Danni', 'Dannie', 'Danny', 'Dannye', 'Danya', 'Danyelle', 'Danyette', 'Daphene', 'Daphna', 'Daphne', 'Dara', 'Darb', 'Darbie', 'Darby', 'Darcee', 'Darcey', 'Darci', 'Darcie', 'Darcy', 'Darda', 'Dareen', 'Darell', 'Darelle', 'Dari', 'Daria', 'Darice', 'Darla', 'Darleen', 'Darlene', 'Darline', 'Darryl', 'Darsey', 'Darsie', 'Darya', 'Daryl', 'Daryn', 'Dasha', 'Dasi', 'Dasie', 'Dasya', 'Datha', 'Daune', 'Daveen', 'Daveta', 'Davida', 'Davina', 'Davine', 'Davita', 'Dawn', 'Dawna', 'Dayle', 'Dayna', 'Dea', 'Deana', 'Deane', 'Deanna', 'Deanne', 'Deb', 'Debbi', 'Debbie', 'Debbra', 'Debby', 'Debee', 'Debera', 'Debi', 'Debor', 'Debora', 'Deborah', 'Debra', 'Dede', 'Dedie', 'Dedra', 'Dee', 'Dee Dee', 'Deeann', 'Deeanne', 'Deedee', 'Deena', 'Deerdre', 'Dehlia', 'Deidre', 'Deina', 'Deirdre', 'Del', 'Dela', 'Delaney', 'Delcina', 'Delcine', 'Delia', 'Delila', 'Delilah', 'Delinda', 'Dell', 'Della', 'Delly', 'Delora', 'Delores', 'Deloria', 'Deloris', 'Delphina', 'Delphine', 'Delphinia', 'Demeter', 'Demetra', 'Demetria', 'Demetris', 'Dena', 'Deni', 'Denice', 'Denise', 'Denna', 'Denni', 'Dennie', 'Denny', 'Deny', 'Denys', 'Denyse', 'Deonne', 'Desaree', 'Desdemona', 'Desirae', 'Desiree', 'Desiri', 'Deva', 'Devan', 'Devi', 'Devin', 'Devina', 'Devinne', 'Devon', 'Devondra', 'Devonna', 'Devonne', 'Devora', 'Dew', 'Di', 'Diahann', 'Diamond', 'Dian', 'Diana', 'Diandra', 'Diane', 'Diane-Marie', 'Dianemarie', 'Diann', 'Dianna', 'Dianne', 'Diannne', 'Didi', 'Dido', 'Diena', 'Dierdre', 'Dina', 'Dinah', 'Dinnie', 'Dinny', 'Dion', 'Dione', 'Dionis', 'Dionne', 'Dita', 'Dix', 'Dixie', 'Dode', 'Dodi', 'Dodie', 'Dody', 'Doe', 'Doll', 'Dolley', 'Dolli', 'Dollie', 'Dolly', 'Dolora', 'Dolores', 'Dolorita', 'Doloritas', 'Dominica', 'Dominique', 'Dona', 'Donella', 'Donelle', 'Donetta', 'Donia', 'Donica', 'Donielle', 'Donna', 'Donnajean', 'Donnamarie', 'Donni', 'Donnie', 'Donny', 'Dora', 'Doralia', 'Doralin', 'Doralyn', 'Doralynn', 'Doralynne', 'Dorcas', 'Dore', 'Doreen', 'Dorelia', 'Dorella', 'Dorelle', 'Dorena', 'Dorene', 'Doretta', 'Dorette', 'Dorey', 'Dori', 'Doria', 'Dorian', 'Dorice', 'Dorie', 'Dorine', 'Doris', 'Dorisa', 'Dorise', 'Dorit', 'Dorita', 'Doro', 'Dorolice', 'Dorolisa', 'Dorotea', 'Doroteya', 'Dorothea', 'Dorothee', 'Dorothy', 'Dorree', 'Dorri', 'Dorrie', 'Dorris', 'Dorry', 'Dorthea', 'Dorthy', 'Dory', 'Dosi', 'Dot', 'Doti', 'Dotti', 'Dottie', 'Dotty', 'Dove', 'Drea', 'Drew', 'Dulce', 'Dulcea', 'Dulci', 'Dulcia', 'Dulciana', 'Dulcie', 'Dulcine', 'Dulcinea', 'Dulcy', 'Dulsea', 'Dusty', 'Dyan', 'Dyana', 'Dyane', 'Dyann', 'Dyanna', 'Dyanne', 'Dyna', 'Dynah', \"E'Lane\", 'Eada', 'Eadie', 'Eadith', 'Ealasaid', 'Eartha', 'Easter', 'Eba', 'Ebba', 'Ebonee', 'Ebony', 'Eda', 'Eddi', 'Eddie', 'Eddy', 'Ede', 'Edee', 'Edeline', 'Eden', 'Edi', 'Edie', 'Edin', 'Edita', 'Edith', 'Editha', 'Edithe', 'Ediva', 'Edna', 'Edwina', 'Edy', 'Edyth', 'Edythe', 'Effie', 'Eileen', 'Eilis', 'Eimile', 'Eirena', 'Ekaterina', 'Elaina', 'Elaine', 'Elana', 'Elane', 'Elayne', 'Elberta', 'Elbertina', 'Elbertine', 'Eleanor', 'Eleanora', 'Eleanore', 'Electra', 'Elena', 'Elene', 'Eleni', 'Elenore', 'Eleonora', 'Eleonore', 'Elfie', 'Elfreda', 'Elfrida', 'Elfrieda', 'Elga', 'Elianora', 'Elianore', 'Elicia', 'Elie', 'Elinor', 'Elinore', 'Elisa', 'Elisabet', 'Elisabeth', 'Elisabetta', 'Elise', 'Elisha', 'Elissa', 'Elita', 'Eliza', 'Elizabet', 'Elizabeth', 'Elka', 'Elke', 'Ella', 'Elladine', 'Elle', 'Ellen', 'Ellene', 'Ellette', 'Elli', 'Ellie', 'Ellissa', 'Elly', 'Ellyn', 'Ellynn', 'Elmira', 'Elna', 'Elnora', 'Elnore', 'Eloisa', 'Eloise', 'Elonore', 'Elora', 'Elsa', 'Elsbeth', 'Else', 'Elsey', 'Elsi', 'Elsie', 'Elsinore', 'Elspeth', 'Elsy', 'Elva', 'Elvera', 'Elvina', 'Elvira', 'Elwina', 'Elwira', 'Elyn', 'Elyse', 'Elysee', 'Elysha', 'Elysia', 'Elyssa', 'Em', 'Ema', 'Emalee', 'Emalia', 'Emanuela', 'Emelda', 'Emelia', 'Emelina', 'Emeline', 'Emelita', 'Emelyne', 'Emera', 'Emilee', 'Emili', 'Emilia', 'Emilie', 'Emiline', 'Emily', 'Emlyn', 'Emlynn', 'Emlynne', 'Emma', 'Emmalee', 'Emmaline', 'Emmalyn', 'Emmalynn', 'Emmalynne', 'Emmeline', 'Emmey', 'Emmi', 'Emmie', 'Emmy', 'Emmye', 'Emogene', 'Emyle', 'Emylee', 'Endora', 'Engracia', 'Enid', 'Enrica', 'Enrichetta', 'Enrika', 'Enriqueta', 'Enya', 'Eolanda', 'Eolande', 'Eran', 'Erda', 'Erena', 'Erica', 'Ericha', 'Ericka', 'Erika', 'Erin', 'Erina', 'Erinn', 'Erinna', 'Erma', 'Ermengarde', 'Ermentrude', 'Ermina', 'Erminia', 'Erminie', 'Erna', 'Ernaline', 'Ernesta', 'Ernestine', 'Ertha', 'Eryn', 'Esma', 'Esmaria', 'Esme', 'Esmeralda', 'Esmerelda', 'Essa', 'Essie', 'Essy', 'Esta', 'Estel', 'Estele', 'Estell', 'Estella', 'Estelle', 'Ester', 'Esther', 'Estrella', 'Estrellita', 'Ethel', 'Ethelda', 'Ethelin', 'Ethelind', 'Etheline', 'Ethelyn', 'Ethyl', 'Etta', 'Etti', 'Ettie', 'Etty', 'Eudora', 'Eugenia', 'Eugenie', 'Eugine', 'Eula', 'Eulalie', 'Eunice', 'Euphemia', 'Eustacia', 'Eva', 'Evaleen', 'Evangelia', 'Evangelin', 'Evangelina', 'Evangeline', 'Evania', 'Evanne', 'Eve', 'Eveleen', 'Evelina', 'Eveline', 'Evelyn', 'Evette', 'Evey', 'Evie', 'Evita', 'Evonne', 'Evvie', 'Evvy', 'Evy', 'Eyde', 'Eydie', 'Fabrianne', 'Fabrice', 'Fae', 'Faina', 'Faith', 'Fallon', 'Fan', 'Fanchette', 'Fanchon', 'Fancie', 'Fancy', 'Fanechka', 'Fania', 'Fanni', 'Fannie', 'Fanny', 'Fanya', 'Fara', 'Farah', 'Farand', 'Farica', 'Farra', 'Farrah', 'Farrand', 'Fatima', 'Faun', 'Faunie', 'Faustina', 'Faustine', 'Fawn', 'Fawna', 'Fawne', 'Fawnia', 'Fay', 'Faydra', 'Faye', 'Fayette', 'Fayina', 'Fayre', 'Fayth', 'Faythe', 'Federica', 'Fedora', 'Felecia', 'Felicdad', 'Felice', 'Felicia', 'Felicity', 'Felicle', 'Felipa', 'Felisha', 'Felita', 'Feliza', 'Fenelia', 'Feodora', 'Ferdinanda', 'Ferdinande', 'Fern', 'Fernanda', 'Fernande', 'Fernandina', 'Ferne', 'Fey', 'Fiann', 'Fianna', 'Fidela', 'Fidelia', 'Fidelity', 'Fifi', 'Fifine', 'Filia', 'Filide', 'Filippa', 'Fina', 'Fiona', 'Fionna', 'Fionnula', 'Fiorenze', 'Fleur', 'Fleurette', 'Flo', 'Flor', 'Flora', 'Florance', 'Flore', 'Florella', 'Florence', 'Florencia', 'Florentia', 'Florenza', 'Florette', 'Flori', 'Floria', 'Florice', 'Florida', 'Florie', 'Florina', 'Florinda', 'Floris', 'Florri', 'Florrie', 'Florry', 'Flory', 'Flossi', 'Flossie', 'Flossy', 'Flower', 'Fortuna', 'Fortune', 'Fran', 'France', 'Francene', 'Frances', 'Francesca', 'Francesmary', 'Francine', 'Francis', 'Francisca', 'Franciska', 'Francoise', 'Francyne', 'Frank', 'Frankie', 'Franky', 'Franni', 'Frannie', 'Franny', 'Frayda', 'Fred', 'Freda', 'Freddi', 'Freddie', 'Freddy', 'Fredelia', 'Frederica', 'Fredericka', 'Fredi', 'Fredia', 'Fredra', 'Fredrika', 'Freida', 'Frieda', 'Friederike', 'Fulvia', 'Gabbey', 'Gabbi', 'Gabbie', 'Gabey', 'Gabi', 'Gabie', 'Gabriel', 'Gabriela', 'Gabriell', 'Gabriella', 'Gabrielle', 'Gabriellia', 'Gabrila', 'Gaby', 'Gae', 'Gael', 'Gail', 'Gale', 'Gale ', 'Galina', 'Garland', 'Garnet', 'Garnette', 'Gates', 'Gavra', 'Gavrielle', 'Gay', 'Gayla', 'Gayle', 'Gayleen', 'Gaylene', 'Gaynor', 'Gelya', 'Gen', 'Gena', 'Gene', 'Geneva', 'Genevieve', 'Genevra', 'Genia', 'Genna', 'Genni', 'Gennie', 'Gennifer', 'Genny', 'Genovera', 'Genvieve', 'George', 'Georgeanna', 'Georgeanne', 'Georgena', 'Georgeta', 'Georgetta', 'Georgette', 'Georgia', 'Georgiamay', 'Georgiana', 'Georgianna', 'Georgianne', 'Georgie', 'Georgina', 'Georgine', 'Gera', 'Geralda', 'Geraldina', 'Geraldine', 'Gerda', 'Gerhardine', 'Geri', 'Gerianna', 'Gerianne', 'Gerladina', 'Germain', 'Germaine', 'Germana', 'Gerri', 'Gerrie', 'Gerrilee', 'Gerry', 'Gert', 'Gerta', 'Gerti', 'Gertie', 'Gertrud', 'Gertruda', 'Gertrude', 'Gertrudis', 'Gerty', 'Giacinta', 'Giana', 'Gianina', 'Gianna', 'Gigi', 'Gilberta', 'Gilberte', 'Gilbertina', 'Gilbertine', 'Gilda', 'Gill', 'Gillan', 'Gilli', 'Gillian', 'Gillie', 'Gilligan', 'Gilly', 'Gina', 'Ginelle', 'Ginevra', 'Ginger', 'Ginni', 'Ginnie', 'Ginnifer', 'Ginny', 'Giorgia', 'Giovanna', 'Gipsy', 'Giralda', 'Gisela', 'Gisele', 'Gisella', 'Giselle', 'Gizela', 'Glad', 'Gladi', 'Gladis', 'Gladys', 'Gleda', 'Glen', 'Glenda', 'Glenine', 'Glenn', 'Glenna', 'Glennie', 'Glennis', 'Glori', 'Gloria', 'Gloriana', 'Gloriane', 'Glorianna', 'Glory', 'Glyn', 'Glynda', 'Glynis', 'Glynnis', 'Godiva', 'Golda', 'Goldarina', 'Goldi', 'Goldia', 'Goldie', 'Goldina', 'Goldy', 'Grace', 'Gracia', 'Gracie', 'Grata', 'Gratia', 'Gratiana', 'Gray', 'Grayce', 'Grazia', 'Gredel', 'Greer', 'Greta', 'Gretal', 'Gretchen', 'Grete', 'Gretel', 'Grethel', 'Gretna', 'Gretta', 'Grier', 'Griselda', 'Grissel', 'Guendolen', 'Guenevere', 'Guenna', 'Guglielma', 'Gui', 'Guillema', 'Guillemette', 'Guinevere', 'Guinna', 'Gunilla', 'Gunvor', 'Gus', 'Gusella', 'Gussi', 'Gussie', 'Gussy', 'Gusta', 'Gusti', 'Gustie', 'Gusty', 'Gwen', 'Gwendolen', 'Gwendolin', 'Gwendolyn', 'Gweneth', 'Gwenette', 'Gwenn', 'Gwenneth', 'Gwenni', 'Gwennie', 'Gwenny', 'Gwenora', 'Gwenore', 'Gwyn', 'Gwyneth', 'Gwynne', 'Gypsy', 'Hadria', 'Hailee', 'Haily', 'Haleigh', 'Halette', 'Haley', 'Hali', 'Halie', 'Halimeda', 'Halley', 'Halli', 'Hallie', 'Hally', 'Hana', 'Hanna', 'Hannah', 'Hanni', 'Hannibal', 'Hannie', 'Hannis', 'Hanny', 'Happy', 'Harlene', 'Harley', 'Harli', 'Harlie', 'Harmonia', 'Harmonie', 'Harmony', 'Harri', 'Harrie', 'Harriet', 'Harriett', 'Harrietta', 'Harriette', 'Harriot', 'Harriott', 'Hatti', 'Hattie', 'Hatty', 'Havivah', 'Hayley', 'Hazel', 'Heath', 'Heather', 'Heda', 'Hedda', 'Heddi', 'Heddie', 'Hedi', 'Hedvig', 'Hedwig', 'Hedy', 'Heida', 'Heide', 'Heidi', 'Heidie', 'Helaina', 'Helaine', 'Helen', 'Helen-Elizabeth', 'Helena', 'Helene', 'Helga', 'Helge', 'Helise', 'Hellene', 'Helli', 'Heloise', 'Helsa', 'Helyn', 'Hendrika', 'Henka', 'Henrie', 'Henrieta', 'Henrietta', 'Henriette', 'Henryetta', 'Hephzibah', 'Hermia', 'Hermina', 'Hermine', 'Herminia', 'Hermione', 'Herta', 'Hertha', 'Hester', 'Hesther', 'Hestia', 'Hetti', 'Hettie', 'Hetty', 'Hilarie', 'Hilary', 'Hilda', 'Hildagard', 'Hildagarde', 'Hilde', 'Hildegaard', 'Hildegarde', 'Hildy', 'Hillary', 'Hilliary', 'Hinda', 'Holley', 'Holli', 'Hollie', 'Holly', 'Holly-Anne', 'Hollyanne', 'Honey', 'Honor', 'Honoria', 'Hope', 'Horatia', 'Hortense', 'Hortensia', 'Hulda', 'Hyacinth', 'Hyacintha', 'Hyacinthe', 'Hyacinthia', 'Hyacinthie', 'Hynda', 'Ianthe', 'Ibbie', 'Ibby', 'Ida', 'Idalia', 'Idalina', 'Idaline', 'Idell', 'Idelle', 'Idette', 'Ike', 'Ikey', 'Ilana', 'Ileana', 'Ileane', 'Ilene', 'Ilise', 'Ilka', 'Illa', 'Ilona', 'Ilsa', 'Ilse', 'Ilysa', 'Ilyse', 'Ilyssa', 'Imelda', 'Imogen', 'Imogene', 'Imojean', 'Ina', 'Inci', 'Indira', 'Ines', 'Inesita', 'Inessa', 'Inez', 'Inga', 'Ingaberg', 'Ingaborg', 'Inge', 'Ingeberg', 'Ingeborg', 'Inger', 'Ingrid', 'Ingunna', 'Inna', 'Ioana', 'Iolande', 'Iolanthe', 'Iona', 'Iormina', 'Ira', 'Irena', 'Irene', 'Irina', 'Iris', 'Irita', 'Irma', 'Isa', 'Isabeau', 'Isabel', 'Isabelita', 'Isabella', 'Isabelle', 'Isador', 'Isadora', 'Isadore', 'Isahella', 'Iseabal', 'Isidora', 'Isis', 'Isobel', 'Issi', 'Issie', 'Issy', 'Ivett', 'Ivette', 'Ivie', 'Ivonne', 'Ivory', 'Ivy', 'Izabel', 'Izzi', 'Jacenta', 'Jacinda', 'Jacinta', 'Jacintha', 'Jacinthe', 'Jackelyn', 'Jacki', 'Jackie', 'Jacklin', 'Jacklyn', 'Jackquelin', 'Jackqueline', 'Jacky', 'Jaclin', 'Jaclyn', 'Jacquelin', 'Jacqueline', 'Jacquelyn', 'Jacquelynn', 'Jacquenetta', 'Jacquenette', 'Jacquetta', 'Jacquette', 'Jacqui', 'Jacquie', 'Jacynth', 'Jada', 'Jade', 'Jaime', 'Jaimie', 'Jaine', 'Jaleh', 'Jami', 'Jamie', 'Jamima', 'Jammie', 'Jan', 'Jana', 'Janaya', 'Janaye', 'Jandy', 'Jane', 'Janean', 'Janeczka', 'Janeen', 'Janel', 'Janela', 'Janella', 'Janelle', 'Janene', 'Janenna', 'Janessa', 'Janet', 'Janeta', 'Janetta', 'Janette', 'Janeva', 'Janey', 'Jania', 'Janice', 'Janie', 'Janifer', 'Janina', 'Janine', 'Janis', 'Janith', 'Janka', 'Janna', 'Jannel', 'Jannelle', 'Janot', 'Jany', 'Jaquelin', 'Jaquelyn', 'Jaquenetta', 'Jaquenette', 'Jaquith', 'Jasmin', 'Jasmina', 'Jasmine', 'Jayme', 'Jaymee', 'Jayne', 'Jaynell', 'Jazmin', 'Jean', 'Jeana', 'Jeane', 'Jeanelle', 'Jeanette', 'Jeanie', 'Jeanine', 'Jeanna', 'Jeanne', 'Jeannette', 'Jeannie', 'Jeannine', 'Jehanna', 'Jelene', 'Jemie', 'Jemima', 'Jemimah', 'Jemmie', 'Jemmy', 'Jen', 'Jena', 'Jenda', 'Jenelle', 'Jenette', 'Jeni', 'Jenica', 'Jeniece', 'Jenifer', 'Jeniffer', 'Jenilee', 'Jenine', 'Jenn', 'Jenna', 'Jennee', 'Jennette', 'Jenni', 'Jennica', 'Jennie', 'Jennifer', 'Jennilee', 'Jennine', 'Jenny', 'Jeraldine', 'Jeralee', 'Jere', 'Jeri', 'Jermaine', 'Jerrie', 'Jerrilee', 'Jerrilyn', 'Jerrine', 'Jerry', 'Jerrylee', 'Jess', 'Jessa', 'Jessalin', 'Jessalyn', 'Jessamine', 'Jessamyn', 'Jesse', 'Jesselyn', 'Jessi', 'Jessica', 'Jessie', 'Jessika', 'Jessy', 'Jewel', 'Jewell', 'Jewelle', 'Jill', 'Jillana', 'Jillane', 'Jillayne', 'Jilleen', 'Jillene', 'Jilli', 'Jillian', 'Jillie', 'Jilly', 'Jinny', 'Jo', 'Jo Ann', 'Jo-Ann', 'Jo-Anne', 'JoAnn', 'JoAnne', 'Joan', 'Joana', 'Joane', 'Joanie', 'Joann', 'Joanna', 'Joanne', 'Joannes', 'Jobey', 'Jobi', 'Jobie', 'Jobina', 'Joby', 'Jobye', 'Jobyna', 'Jocelin', 'Joceline', 'Jocelyn', 'Jocelyne', 'Jodee', 'Jodi', 'Jodie', 'Jody', 'Joela', 'Joelie', 'Joell', 'Joella', 'Joelle', 'Joellen', 'Joelly', 'Joellyn', 'Joelynn', 'Joete', 'Joey', 'Johanna', 'Johannah', 'Johnette', 'Johnna', 'Joice', 'Jojo', 'Jolee', 'Joleen', 'Jolene', 'Joletta', 'Joli', 'Jolie', 'Joline', 'Joly', 'Jolyn', 'Jolynn', 'Jonell', 'Joni', 'Jonie', 'Jonis', 'Jordain', 'Jordan', 'Jordana', 'Jordanna', 'Jorey', 'Jori', 'Jorie', 'Jorrie', 'Jorry', 'Joscelin', 'Josee', 'Josefa', 'Josefina', 'Joselyn', 'Josepha', 'Josephina', 'Josephine', 'Josey', 'Josi', 'Josie', 'Joslyn', 'Josselyn', 'Josy', 'Jourdan', 'Joy', 'Joya', 'Joyan', 'Joyann', 'Joyce', 'Joycelin', 'Joye', 'Joyous', 'Juana', 'Juanita', 'Jude', 'Judi', 'Judie', 'Judith', 'Juditha', 'Judy', 'Judye', 'Julee', 'Juli', 'Julia', 'Juliana', 'Juliane', 'Juliann', 'Julianna', 'Julianne', 'Julie', 'Julienne', 'Juliet', 'Julieta', 'Julietta', 'Juliette', 'Julina', 'Juline', 'Julissa', 'Julita', 'June', 'Junette', 'Junia', 'Junie', 'Junina', 'Justin', 'Justina', 'Justine', 'Jyoti', 'Kacey', 'Kacie', 'Kacy', 'Kai', 'Kaia', 'Kaila', 'Kaile', 'Kailey', 'Kaitlin', 'Kaitlyn', 'Kaitlynn', 'Kaja', 'Kakalina', 'Kala', 'Kaleena', 'Kali', 'Kalie', 'Kalila', 'Kalina', 'Kalinda', 'Kalindi', 'Kalli', 'Kally', 'Kameko', 'Kamila', 'Kamilah', 'Kamillah', 'Kandace', 'Kandy', 'Kania', 'Kanya', 'Kara', 'Kara-Lynn', 'Karalee', 'Karalynn', 'Kare', 'Karee', 'Karel', 'Karen', 'Karena', 'Kari', 'Karia', 'Karie', 'Karil', 'Karilynn', 'Karin', 'Karina', 'Karine', 'Kariotta', 'Karisa', 'Karissa', 'Karita', 'Karla', 'Karlee', 'Karleen', 'Karlen', 'Karlene', 'Karlie', 'Karlotta', 'Karlotte', 'Karly', 'Karlyn', 'Karmen', 'Karna', 'Karol', 'Karola', 'Karole', 'Karolina', 'Karoline', 'Karoly', 'Karon', 'Karrah', 'Karrie', 'Karry', 'Kary', 'Karyl', 'Karylin', 'Karyn', 'Kasey', 'Kass', 'Kassandra', 'Kassey', 'Kassi', 'Kassia', 'Kassie', 'Kaster', 'Kat', 'Kata', 'Katalin', 'Kate', 'Katee', 'Katerina', 'Katerine', 'Katey', 'Kath', 'Katha', 'Katharina', 'Katharine', 'Katharyn', 'Kathe', 'Katheleen', 'Katherina', 'Katherine', 'Katheryn', 'Kathi', 'Kathie', 'Kathleen', 'Kathlene', 'Kathlin', 'Kathrine', 'Kathryn', 'Kathryne', 'Kathy', 'Kathye', 'Kati', 'Katie', 'Katina', 'Katine', 'Katinka', 'Katleen', 'Katlin', 'Katrina', 'Katrine', 'Katrinka', 'Katti', 'Kattie', 'Katuscha', 'Katusha', 'Katy', 'Katya', 'Kay', 'Kaycee', 'Kaye', 'Kayla', 'Kayle', 'Kaylee', 'Kayley', 'Kaylil', 'Kaylyn', 'Kee', 'Keeley', 'Keelia', 'Keely', 'Kelcey', 'Kelci', 'Kelcie', 'Kelcy', 'Kelila', 'Kellen', 'Kelley', 'Kelli', 'Kellia', 'Kellie', 'Kellina', 'Kellsie', 'Kelly', 'Kellyann', 'Kelsey', 'Kelsi', 'Kelsy', 'Kendra', 'Kendre', 'Kenna', 'Keren', 'Keri', 'Keriann', 'Kerianne', 'Kerri', 'Kerrie', 'Kerrill', 'Kerrin', 'Kerry', 'Kerstin', 'Kesley', 'Keslie', 'Kessia', 'Kessiah', 'Ketti', 'Kettie', 'Ketty', 'Kevina', 'Kevyn', 'Ki', 'Kia', 'Kiah', 'Kial', 'Kiele', 'Kiersten', 'Kikelia', 'Kiley', 'Kim', 'Kimberlee', 'Kimberley', 'Kimberli', 'Kimberly', 'Kimberlyn', 'Kimbra', 'Kimmi', 'Kimmie', 'Kimmy', 'Kinna', 'Kip', 'Kipp', 'Kippie', 'Kippy', 'Kira', 'Kirbee', 'Kirbie', 'Kirby', 'Kiri', 'Kirsten', 'Kirsteni', 'Kirsti', 'Kirstie', 'Kirstin', 'Kirstyn', 'Kissee', 'Kissiah', 'Kissie', 'Kit', 'Kitti', 'Kittie', 'Kitty', 'Kizzee', 'Kizzie', 'Klara', 'Klarika', 'Klarrisa', 'Konstance', 'Konstanze', 'Koo', 'Kora', 'Koral', 'Koralle', 'Kordula', 'Kore', 'Korella', 'Koren', 'Koressa', 'Kori', 'Korie', 'Korney', 'Korrie', 'Korry', 'Kourtney', 'Kris', 'Krissie', 'Krissy', 'Krista', 'Kristal', 'Kristan', 'Kriste', 'Kristel', 'Kristen', 'Kristi', 'Kristien', 'Kristin', 'Kristina', 'Kristine', 'Kristy', 'Kristyn', 'Krysta', 'Krystal', 'Krystalle', 'Krystle', 'Krystyna', 'Kyla', 'Kyle', 'Kylen', 'Kylie', 'Kylila', 'Kylynn', 'Kym', 'Kynthia', 'Kyrstin', 'La', 'Lacee', 'Lacey', 'Lacie', 'Lacy', 'Ladonna', 'Laetitia', 'Laila', 'Laina', 'Lainey', 'Lamb', 'Lana', 'Lane', 'Lanette', 'Laney', 'Lani', 'Lanie', 'Lanita', 'Lanna', 'Lanni', 'Lanny', 'Lara', 'Laraine', 'Lari', 'Larina', 'Larine', 'Larisa', 'Larissa', 'Lark', 'Laryssa', 'Latashia', 'Latia', 'Latisha', 'Latrena', 'Latrina', 'Laura', 'Lauraine', 'Laural', 'Lauralee', 'Laure', 'Lauree', 'Laureen', 'Laurel', 'Laurella', 'Lauren', 'Laurena', 'Laurene', 'Lauretta', 'Laurette', 'Lauri', 'Laurianne', 'Laurice', 'Laurie', 'Lauryn', 'Lavena', 'Laverna', 'Laverne', 'Lavina', 'Lavinia', 'Lavinie', 'Layla', 'Layne', 'Layney', 'Lea', 'Leah', 'Leandra', 'Leann', 'Leanna', 'Leanne', 'Leanor', 'Leanora', 'Lebbie', 'Leda', 'Lee', 'LeeAnn', 'Leeann', 'Leeanne', 'Leela', 'Leelah', 'Leena', 'Leesa', 'Leese', 'Legra', 'Leia', 'Leiah', 'Leigh', 'Leigha', 'Leila', 'Leilah', 'Leisha', 'Lela', 'Lelah', 'Leland', 'Lelia', 'Lena', 'Lenee', 'Lenette', 'Lenka', 'Lenna', 'Lenora', 'Lenore', 'Leodora', 'Leoine', 'Leola', 'Leoline', 'Leona', 'Leonanie', 'Leone', 'Leonelle', 'Leonie', 'Leonora', 'Leonore', 'Leontine', 'Leontyne', 'Leora', 'Leorah', 'Leshia', 'Lesley', 'Lesli', 'Leslie', 'Lesly', 'Lesya', 'Leta', 'Lethia', 'Leticia', 'Letisha', 'Letitia', 'Letta', 'Letti', 'Lettie', 'Letty', 'Leyla', 'Lezlie', 'Lia', 'Lian', 'Liana', 'Liane', 'Lianna', 'Lianne', 'Lib', 'Libbey', 'Libbi', 'Libbie', 'Libby', 'Licha', 'Lida', 'Lidia', 'Lil', 'Lila', 'Lilah', 'Lilas', 'Lilia', 'Lilian', 'Liliane', 'Lilias', 'Lilith', 'Lilla', 'Lilli', 'Lillian', 'Lillis', 'Lilllie', 'Lilly', 'Lily', 'Lilyan', 'Lin', 'Lina', 'Lind', 'Linda', 'Lindi', 'Lindie', 'Lindsay', 'Lindsey', 'Lindsy', 'Lindy', 'Linea', 'Linell', 'Linet', 'Linette', 'Linn', 'Linnea', 'Linnell', 'Linnet', 'Linnie', 'Linzy', 'Liora', 'Liorah', 'Lira', 'Lisa', 'Lisabeth', 'Lisandra', 'Lisbeth', 'Lise', 'Lisetta', 'Lisette', 'Lisha', 'Lishe', 'Lissa', 'Lissi', 'Lissie', 'Lissy', 'Lita', 'Liuka', 'Livia', 'Liz', 'Liza', 'Lizabeth', 'Lizbeth', 'Lizette', 'Lizzie', 'Lizzy', 'Loella', 'Lois', 'Loise', 'Lola', 'Lolande', 'Loleta', 'Lolita', 'Lolly', 'Lona', 'Lonee', 'Loni', 'Lonna', 'Lonni', 'Lonnie', 'Lora', 'Lorain', 'Loraine', 'Loralee', 'Loralie', 'Loralyn', 'Loree', 'Loreen', 'Lorelei', 'Lorelle', 'Loren', 'Lorena', 'Lorene', 'Lorenza', 'Loretta', 'Lorettalorna', 'Lorette', 'Lori', 'Loria', 'Lorianna', 'Lorianne', 'Lorie', 'Lorilee', 'Lorilyn', 'Lorinda', 'Lorine', 'Lorita', 'Lorna', 'Lorne', 'Lorraine', 'Lorrayne', 'Lorri', 'Lorrie', 'Lorrin', 'Lorry', 'Lory', 'Lotta', 'Lotte', 'Lotti', 'Lottie', 'Lotty', 'Lou', 'Louella', 'Louisa', 'Louise', 'Louisette', 'Love', 'Luana', 'Luanna', 'Luce', 'Luci', 'Lucia', 'Luciana', 'Lucie', 'Lucienne', 'Lucila', 'Lucilia', 'Lucille', 'Lucina', 'Lucinda', 'Lucine', 'Lucita', 'Lucky', 'Lucretia', 'Lucy', 'Luella', 'Luelle', 'Luisa', 'Luise', 'Lula', 'Lulita', 'Lulu', 'Luna', 'Lura', 'Lurette', 'Lurleen', 'Lurlene', 'Lurline', 'Lusa', 'Lust', 'Lyda', 'Lydia', 'Lydie', 'Lyn', 'Lynda', 'Lynde', 'Lyndel', 'Lyndell', 'Lyndsay', 'Lyndsey', 'Lyndsie', 'Lyndy', 'Lynea', 'Lynelle', 'Lynett', 'Lynette', 'Lynn', 'Lynna', 'Lynne', 'Lynnea', 'Lynnell', 'Lynnelle', 'Lynnet', 'Lynnett', 'Lynnette', 'Lynsey', 'Lysandra', 'Lyssa', 'Mab', 'Mabel', 'Mabelle', 'Mable', 'Mada', 'Madalena', 'Madalyn', 'Maddalena', 'Maddi', 'Maddie', 'Maddy', 'Madel', 'Madelaine', 'Madeleine', 'Madelena', 'Madelene', 'Madelin', 'Madelina', 'Madeline', 'Madella', 'Madelle', 'Madelon', 'Madelyn', 'Madge', 'Madlen', 'Madlin', 'Madona', 'Madonna', 'Mady', 'Mae', 'Maegan', 'Mag', 'Magda', 'Magdaia', 'Magdalen', 'Magdalena', 'Magdalene', 'Maggee', 'Maggi', 'Maggie', 'Maggy', 'Magna', 'Mahala', 'Mahalia', 'Maia', 'Maible', 'Maiga', 'Mair', 'Maire', 'Mairead', 'Maisey', 'Maisie', 'Mala', 'Malanie', 'Malcah', 'Malena', 'Malia', 'Malina', 'Malinda', 'Malinde', 'Malissa', 'Malissia', 'Malka', 'Malkah', 'Mallissa', 'Mallorie', 'Mallory', 'Malorie', 'Malory', 'Malva', 'Malvina', 'Malynda', 'Mame', 'Mamie', 'Manda', 'Mandi', 'Mandie', 'Mandy', 'Manon', 'Manya', 'Mara', 'Marabel', 'Marcela', 'Marcelia', 'Marcella', 'Marcelle', 'Marcellina', 'Marcelline', 'Marchelle', 'Marci', 'Marcia', 'Marcie', 'Marcile', 'Marcille', 'Marcy', 'Mareah', 'Maren', 'Marena', 'Maressa', 'Marga', 'Margalit', 'Margalo', 'Margaret', 'Margareta', 'Margarete', 'Margaretha', 'Margarethe', 'Margaretta', 'Margarette', 'Margarita', 'Margaux', 'Marge', 'Margeaux', 'Margery', 'Marget', 'Margette', 'Margi', 'Margie', 'Margit', 'Marglerite', 'Margo', 'Margot', 'Margret', 'Marguerite', 'Margurite', 'Margy', 'Mari', 'Maria', 'Mariam', 'Marian', 'Mariana', 'Mariann', 'Marianna', 'Marianne', 'Maribel', 'Maribelle', 'Maribeth', 'Marice', 'Maridel', 'Marie', 'Marie-Ann', 'Marie-Jeanne', 'Marieann', 'Mariejeanne', 'Mariel', 'Mariele', 'Marielle', 'Mariellen', 'Marietta', 'Mariette', 'Marigold', 'Marijo', 'Marika', 'Marilee', 'Marilin', 'Marillin', 'Marilyn', 'Marin', 'Marina', 'Marinna', 'Marion', 'Mariquilla', 'Maris', 'Marisa', 'Mariska', 'Marissa', 'Marit', 'Marita', 'Maritsa', 'Mariya', 'Marj', 'Marja', 'Marje', 'Marji', 'Marjie', 'Marjorie', 'Marjory', 'Marjy', 'Marketa', 'Marla', 'Marlane', 'Marleah', 'Marlee', 'Marleen', 'Marlena', 'Marlene', 'Marley', 'Marlie', 'Marline', 'Marlo', 'Marlyn', 'Marna', 'Marne', 'Marney', 'Marni', 'Marnia', 'Marnie', 'Marquita', 'Marrilee', 'Marris', 'Marrissa', 'Marry', 'Marsha', 'Marsiella', 'Marta', 'Martelle', 'Martguerita', 'Martha', 'Marthe', 'Marthena', 'Marti', 'Martica', 'Martie', 'Martina', 'Martita', 'Marty', 'Martynne', 'Mary', 'Marya', 'Maryangelyn', 'Maryann', 'Maryanna', 'Maryanne', 'Marybelle', 'Marybeth', 'Maryellen', 'Maryjane', 'Maryjo', 'Maryl', 'Marylee', 'Marylin', 'Marylinda', 'Marylou', 'Marylynne', 'Maryrose', 'Marys', 'Marysa', 'Masha', 'Matelda', 'Mathilda', 'Mathilde', 'Matilda', 'Matilde', 'Matti', 'Mattie', 'Matty', 'Maud', 'Maude', 'Maudie', 'Maura', 'Maure', 'Maureen', 'Maureene', 'Maurene', 'Maurine', 'Maurise', 'Maurita', 'Mavis', 'Mavra', 'Max', 'Maxi', 'Maxie', 'Maxine', 'Maxy', 'May', 'Maya', 'Maybelle', 'Mayda', 'Maye', 'Mead', 'Meade', 'Meagan', 'Meaghan', 'Meara', 'Mechelle', 'Meg', 'Megan', 'Megen', 'Meggan', 'Meggi', 'Meggie', 'Meggy', 'Meghan', 'Meghann', 'Mehetabel', 'Mei', 'Meira', 'Mel', 'Mela', 'Melamie', 'Melania', 'Melanie', 'Melantha', 'Melany', 'Melba', 'Melesa', 'Melessa', 'Melicent', 'Melina', 'Melinda', 'Melinde', 'Melisa', 'Melisande', 'Melisandra', 'Melisenda', 'Melisent', 'Melissa', 'Melisse', 'Melita', 'Melitta', 'Mella', 'Melli', 'Mellicent', 'Mellie', 'Mellisa', 'Mellisent', 'Mellissa', 'Melloney', 'Melly', 'Melodee', 'Melodie', 'Melody', 'Melonie', 'Melony', 'Melosa', 'Melva', 'Mercedes', 'Merci', 'Mercie', 'Mercy', 'Meredith', 'Meredithe', 'Meridel', 'Meridith', 'Meriel', 'Merilee', 'Merilyn', 'Meris', 'Merissa', 'Merl', 'Merla', 'Merle', 'Merlina', 'Merline', 'Merna', 'Merola', 'Merralee', 'Merridie', 'Merrie', 'Merrielle', 'Merrile', 'Merrilee', 'Merrili', 'Merrill', 'Merrily', 'Merry', 'Mersey', 'Meryl', 'Meta', 'Mia', 'Micaela', 'Michaela', 'Michaelina', 'Michaeline', 'Michaella', 'Michal', 'Michel', 'Michele', 'Michelina', 'Micheline', 'Michell', 'Michelle', 'Micki', 'Mickie', 'Micky', 'Midge', 'Mignon', 'Mignonne', 'Miguela', 'Miguelita', 'Mildred', 'Mildrid', 'Milena', 'Milicent', 'Milissent', 'Milka', 'Milli', 'Millicent', 'Millie', 'Millisent', 'Milly', 'Milzie', 'Mimi', 'Min', 'Mina', 'Minda', 'Mindy', 'Minerva', 'Minetta', 'Minette', 'Minna', 'Minni', 'Minnie', 'Minny', 'Minta', 'Miquela', 'Mira', 'Mirabel', 'Mirabella', 'Mirabelle', 'Miran', 'Miranda', 'Mireielle', 'Mireille', 'Mirella', 'Mirelle', 'Miriam', 'Mirilla', 'Mirna', 'Misha', 'Missie', 'Missy', 'Misti', 'Misty', 'Mitra', 'Mitzi', 'Mmarianne', 'Modesta', 'Modestia', 'Modestine', 'Modesty', 'Moina', 'Moira', 'Moll', 'Mollee', 'Molli', 'Mollie', 'Molly', 'Mommy', 'Mona', 'Monah', 'Monica', 'Monika', 'Monique', 'Mora', 'Moreen', 'Morena', 'Morgan', 'Morgana', 'Morganica', 'Morganne', 'Morgen', 'Moria', 'Morissa', 'Morlee', 'Morna', 'Moselle', 'Moya', 'Moyna', 'Moyra', 'Mozelle', 'Muffin', 'Mufi', 'Mufinella', 'Muire', 'Mureil', 'Murial', 'Muriel', 'Murielle', 'Myna', 'Myra', 'Myrah', 'Myranda', 'Myriam', 'Myrilla', 'Myrle', 'Myrlene', 'Myrna', 'Myrta', 'Myrtia', 'Myrtice', 'Myrtie', 'Myrtle', 'Nada', 'Nadean', 'Nadeen', 'Nadia', 'Nadine', 'Nadiya', 'Nady', 'Nadya', 'Nalani', 'Nan', 'Nana', 'Nananne', 'Nance', 'Nancee', 'Nancey', 'Nanci', 'Nancie', 'Nancy', 'Nanete', 'Nanette', 'Nani', 'Nanice', 'Nanine', 'Nannette', 'Nanni', 'Nannie', 'Nanny', 'Nanon', 'Naoma', 'Naomi', 'Nara', 'Nari', 'Nariko', 'Nat', 'Nata', 'Natala', 'Natalee', 'Natalia', 'Natalie', 'Natalina', 'Nataline', 'Natalya', 'Natasha', 'Natassia', 'Nathalia', 'Nathalie', 'Natka', 'Natty', 'Neala', 'Neda', 'Nedda', 'Nedi', 'Neely', 'Neila', 'Neile', 'Neilla', 'Neille', 'Nela', 'Nelia', 'Nelie', 'Nell', 'Nelle', 'Nelli', 'Nellie', 'Nelly', 'Nena', 'Nerissa', 'Nerita', 'Nert', 'Nerta', 'Nerte', 'Nerti', 'Nertie', 'Nerty', 'Nessa', 'Nessi', 'Nessie', 'Nessy', 'Nesta', 'Netta', 'Netti', 'Nettie', 'Nettle', 'Netty', 'Nevsa', 'Neysa', 'Nichol', 'Nichole', 'Nicholle', 'Nicki', 'Nickie', 'Nicky', 'Nicol', 'Nicola', 'Nicole', 'Nicolea', 'Nicolette', 'Nicoli', 'Nicolina', 'Nicoline', 'Nicolle', 'Nidia', 'Nike', 'Niki', 'Nikki', 'Nikkie', 'Nikoletta', 'Nikolia', 'Nil', 'Nina', 'Ninetta', 'Ninette', 'Ninnetta', 'Ninnette', 'Ninon', 'Nisa', 'Nissa', 'Nisse', 'Nissie', 'Nissy', 'Nita', 'Nitin', 'Nixie', 'Noami', 'Noel', 'Noelani', 'Noell', 'Noella', 'Noelle', 'Noellyn', 'Noelyn', 'Noemi', 'Nola', 'Nolana', 'Nolie', 'Nollie', 'Nomi', 'Nona', 'Nonah', 'Noni', 'Nonie', 'Nonna', 'Nonnah', 'Nora', 'Norah', 'Norean', 'Noreen', 'Norene', 'Norina', 'Norine', 'Norma', 'Norri', 'Norrie', 'Norry', 'Nova', 'Novelia', 'Nydia', 'Nyssa', 'Octavia', 'Odele', 'Odelia', 'Odelinda', 'Odella', 'Odelle', 'Odessa', 'Odetta', 'Odette', 'Odilia', 'Odille', 'Ofelia', 'Ofella', 'Ofilia', 'Ola', 'Olenka', 'Olga', 'Olia', 'Olimpia', 'Olive', 'Olivette', 'Olivia', 'Olivie', 'Oliy', 'Ollie', 'Olly', 'Olva', 'Olwen', 'Olympe', 'Olympia', 'Olympie', 'Ondrea', 'Oneida', 'Onida', 'Onlea', 'Oona', 'Opal', 'Opalina', 'Opaline', 'Ophelia', 'Ophelie', 'Oprah', 'Ora', 'Oralee', 'Oralia', 'Oralie', 'Oralla', 'Oralle', 'Orel', 'Orelee', 'Orelia', 'Orelie', 'Orella', 'Orelle', 'Oreste', 'Oriana', 'Orly', 'Orsa', 'Orsola', 'Ortensia', 'Otha', 'Othelia', 'Othella', 'Othilia', 'Othilie', 'Ottilie', 'Pacifica', 'Page', 'Paige', 'Paloma', 'Pam', 'Pamela', 'Pamelina', 'Pamella', 'Pammi', 'Pammie', 'Pammy', 'Pandora', 'Pansie', 'Pansy', 'Paola', 'Paolina', 'Parwane', 'Pat', 'Patience', 'Patrica', 'Patrice', 'Patricia', 'Patrizia', 'Patsy', 'Patti', 'Pattie', 'Patty', 'Paula', 'Paula-Grace', 'Paule', 'Pauletta', 'Paulette', 'Pauli', 'Paulie', 'Paulina', 'Pauline', 'Paulita', 'Pauly', 'Pavia', 'Pavla', 'Pearl', 'Pearla', 'Pearle', 'Pearline', 'Peg', 'Pegeen', 'Peggi', 'Peggie', 'Peggy', 'Pen', 'Penelopa', 'Penelope', 'Penni', 'Pennie', 'Penny', 'Pepi', 'Pepita', 'Peri', 'Peria', 'Perl', 'Perla', 'Perle', 'Perri', 'Perrine', 'Perry', 'Persis', 'Pet', 'Peta', 'Petra', 'Petrina', 'Petronella', 'Petronia', 'Petronilla', 'Petronille', 'Petunia', 'Phaedra', 'Phaidra', 'Phebe', 'Phedra', 'Phelia', 'Phil', 'Philipa', 'Philippa', 'Philippe', 'Philippine', 'Philis', 'Phillida', 'Phillie', 'Phillis', 'Philly', 'Philomena', 'Phoebe', 'Phylis', 'Phyllida', 'Phyllis', 'Phyllys', 'Phylys', 'Pia', 'Pier', 'Pierette', 'Pierrette', 'Pietra', 'Piper', 'Pippa', 'Pippy', 'Polly', 'Pollyanna', 'Pooh', 'Poppy', 'Portia', 'Pris', 'Prisca', 'Priscella', 'Priscilla', 'Prissie', 'Pru', 'Prudence', 'Prudi', 'Prudy', 'Prue', 'Prunella', 'Queada', 'Queenie', 'Quentin', 'Querida', 'Quinn', 'Quinta', 'Quintana', 'Quintilla', 'Quintina', 'Rachael', 'Rachel', 'Rachele', 'Rachelle', 'Rae', 'Raf', 'Rafa', 'Rafaela', 'Rafaelia', 'Rafaelita', 'Ragnhild', 'Rahal', 'Rahel', 'Raina', 'Raine', 'Rakel', 'Ralina', 'Ramona', 'Ramonda', 'Rana', 'Randa', 'Randee', 'Randene', 'Randi', 'Randie', 'Randy', 'Ranee', 'Rani', 'Rania', 'Ranice', 'Ranique', 'Ranna', 'Raphaela', 'Raquel', 'Raquela', 'Rasia', 'Rasla', 'Raven', 'Ray', 'Raychel', 'Raye', 'Rayna', 'Raynell', 'Rayshell', 'Rea', 'Reba', 'Rebbecca', 'Rebe', 'Rebeca', 'Rebecca', 'Rebecka', 'Rebeka', 'Rebekah', 'Rebekkah', 'Ree', 'Reeba', 'Reena', 'Reeta', 'Reeva', 'Regan', 'Reggi', 'Reggie', 'Regina', 'Regine', 'Reiko', 'Reina', 'Reine', 'Remy', 'Rena', 'Renae', 'Renata', 'Renate', 'Rene', 'Renee', 'Renel', 'Renell', 'Renelle', 'Renie', 'Rennie', 'Reta', 'Retha', 'Revkah', 'Rey', 'Reyna', 'Rhea', 'Rheba', 'Rheta', 'Rhetta', 'Rhiamon', 'Rhianna', 'Rhianon', 'Rhoda', 'Rhodia', 'Rhodie', 'Rhody', 'Rhona', 'Rhonda', 'Riane', 'Riannon', 'Rianon', 'Rica', 'Ricca', 'Rici', 'Ricki', 'Rickie', 'Ricky', 'Riki', 'Rikki', 'Rina', 'Risa', 'Rissa', 'Rita', 'Riva', 'Rivalee', 'Rivi', 'Rivkah', 'Rivy', 'Roana', 'Roanna', 'Roanne', 'Robbi', 'Robbie', 'Robbin', 'Robby', 'Robbyn', 'Robena', 'Robenia', 'Roberta', 'Robin', 'Robina', 'Robinet', 'Robinett', 'Robinetta', 'Robinette', 'Robinia', 'Roby', 'Robyn', 'Roch', 'Rochell', 'Rochella', 'Rochelle', 'Rochette', 'Roda', 'Rodi', 'Rodie', 'Rodina', 'Romola', 'Romona', 'Romonda', 'Romy', 'Rona', 'Ronalda', 'Ronda', 'Ronica', 'Ronna', 'Ronni', 'Ronnica', 'Ronnie', 'Ronny', 'Roobbie', 'Rora', 'Rori', 'Rorie', 'Rory', 'Ros', 'Rosa', 'Rosabel', 'Rosabella', 'Rosabelle', 'Rosaleen', 'Rosalia', 'Rosalie', 'Rosalind', 'Rosalinda', 'Rosalinde', 'Rosaline', 'Rosalyn', 'Rosalynd', 'Rosamond', 'Rosamund', 'Rosana', 'Rosanna', 'Rosanne', 'Rosario', 'Rose', 'Roseann', 'Roseanna', 'Roseanne', 'Roselia', 'Roselin', 'Roseline', 'Rosella', 'Roselle', 'Roselyn', 'Rosemaria', 'Rosemarie', 'Rosemary', 'Rosemonde', 'Rosene', 'Rosetta', 'Rosette', 'Roshelle', 'Rosie', 'Rosina', 'Rosita', 'Roslyn', 'Rosmunda', 'Rosy', 'Row', 'Rowe', 'Rowena', 'Roxana', 'Roxane', 'Roxanna', 'Roxanne', 'Roxi', 'Roxie', 'Roxine', 'Roxy', 'Roz', 'Rozalie', 'Rozalin', 'Rozamond', 'Rozanna', 'Rozanne', 'Roze', 'Rozele', 'Rozella', 'Rozelle', 'Rozina', 'Rubetta', 'Rubi', 'Rubia', 'Rubie', 'Rubina', 'Ruby', 'Ruella', 'Ruperta', 'Ruth', 'Ruthann', 'Ruthanne', 'Ruthe', 'Ruthi', 'Ruthie', 'Ruthy', 'Ryann', 'Rycca', 'Saba', 'Sabina', 'Sabine', 'Sabra', 'Sabrina', 'Sacha', 'Sada', 'Sadella', 'Sadie', 'Sal', 'Sallee', 'Salli', 'Sallie', 'Sally', 'Sallyann', 'Sallyanne', 'Salome', 'Sam', 'Samantha', 'Samara', 'Samaria', 'Sammy', 'Samuela', 'Samuella', 'Sande', 'Sandi', 'Sandie', 'Sandra', 'Sandy', 'Sandye', 'Sapphira', 'Sapphire', 'Sara', 'Sara-Ann', 'Saraann', 'Sarah', 'Sarajane', 'Saree', 'Sarena', 'Sarene', 'Sarette', 'Sari', 'Sarina', 'Sarine', 'Sarita', 'Sascha', 'Sasha', 'Sashenka', 'Saudra', 'Saundra', 'Savina', 'Sayre', 'Scarlet', 'Scarlett', 'Scotty', 'Sean', 'Seana', 'Secunda', 'Seka', 'Sela', 'Selena', 'Selene', 'Selestina', 'Selia', 'Selie', 'Selina', 'Selinda', 'Seline', 'Sella', 'Selle', 'Selma', 'Sena', 'Sephira', 'Serena', 'Serene', 'Shaina', 'Shaine', 'Shalna', 'Shalne', 'Shamit', 'Shana', 'Shanda', 'Shandee', 'Shandie', 'Shandra', 'Shandy', 'Shane', 'Shani', 'Shanie', 'Shanna', 'Shannah', 'Shannen', 'Shannon', 'Shanon', 'Shanta', 'Shantee', 'Shara', 'Sharai', 'Shari', 'Sharia', 'Sharie', 'Sharity', 'Sharl', 'Sharla', 'Sharleen', 'Sharlene', 'Sharline', 'Sharna', 'Sharon', 'Sharona', 'Sharra', 'Sharron', 'Sharyl', 'Shaun', 'Shauna', 'Shawn', 'Shawna', 'Shawnee', 'Shay', 'Shayla', 'Shaylah', 'Shaylyn', 'Shaylynn', 'Shayna', 'Shayne', 'Shea', 'Sheba', 'Sheela', 'Sheelagh', 'Sheelah', 'Sheena', 'Sheeree', 'Sheila', 'Sheila-Kathryn', 'Sheilah', 'Sheilakathryn', 'Shel', 'Shela', 'Shelagh', 'Shelba', 'Shelbi', 'Shelby', 'Shelia', 'Shell', 'Shelley', 'Shelli', 'Shellie', 'Shelly', 'Shena', 'Sher', 'Sheree', 'Sheri', 'Sherie', 'Sheril', 'Sherill', 'Sherilyn', 'Sherline', 'Sherri', 'Sherrie', 'Sherry', 'Sherye', 'Sheryl', 'Shilpa', 'Shina', 'Shir', 'Shira', 'Shirah', 'Shirl', 'Shirlee', 'Shirleen', 'Shirlene', 'Shirley', 'Shirline', 'Shoshana', 'Shoshanna', 'Shoshie', 'Siana', 'Sianna', 'Sib', 'Sibbie', 'Sibby', 'Sibeal', 'Sibel', 'Sibella', 'Sibelle', 'Sibilla', 'Sibley', 'Sibyl', 'Sibylla', 'Sibylle', 'Sidoney', 'Sidonia', 'Sidonnie', 'Sigrid', 'Sile', 'Sileas', 'Silva', 'Silvana', 'Silvia', 'Silvie', 'Simona', 'Simone', 'Simonette', 'Simonne', 'Sindee', 'Sinead', 'Siobhan', 'Sioux', 'Siouxie', 'Sisely', 'Sisile', 'Sissie', 'Sissy', 'Sofia', 'Sofie', 'Solange', 'Sondra', 'Sonia', 'Sonja', 'Sonni', 'Sonnie', 'Sonnnie', 'Sonny', 'Sonya', 'Sophey', 'Sophi', 'Sophia', 'Sophie', 'Sophronia', 'Sorcha', 'Sosanna', 'Stace', 'Stacee', 'Stacey', 'Staci', 'Stacia', 'Stacie', 'Stacy', 'Stafani', 'Star', 'Starla', 'Starlene', 'Starlin', 'Starr', 'Stefa', 'Stefania', 'Stefanie', 'Steffane', 'Steffi', 'Steffie', 'Stella', 'Stepha', 'Stephana', 'Stephani', 'Stephanie', 'Stephannie', 'Stephenie', 'Stephi', 'Stephie', 'Stephine', 'Stesha', 'Stevana', 'Stevena', 'Stoddard', 'Storey', 'Storm', 'Stormi', 'Stormie', 'Stormy', 'Sue', 'Sue-elle', 'Suellen', 'Sukey', 'Suki', 'Sula', 'Sunny', 'Sunshine', 'Susan', 'Susana', 'Susanetta', 'Susann', 'Susanna', 'Susannah', 'Susanne', 'Susette', 'Susi', 'Susie', 'Sussi', 'Susy', 'Suzan', 'Suzann', 'Suzanna', 'Suzanne', 'Suzetta', 'Suzette', 'Suzi', 'Suzie', 'Suzy', 'Suzzy', 'Sybil', 'Sybila', 'Sybilla', 'Sybille', 'Sybyl', 'Sydel', 'Sydelle', 'Sydney', 'Sylvia', 'Sylvie', 'Tabatha', 'Tabbatha', 'Tabbi', 'Tabbie', 'Tabbitha', 'Tabby', 'Tabina', 'Tabitha', 'Taffy', 'Talia', 'Tallia', 'Tallie', 'Tally', 'Talya', 'Talyah', 'Tamar', 'Tamara', 'Tamarah', 'Tamarra', 'Tamera', 'Tami', 'Tamiko', 'Tamma', 'Tammara', 'Tammi', 'Tammie', 'Tammy', 'Tamra', 'Tana', 'Tandi', 'Tandie', 'Tandy', 'Tani', 'Tania', 'Tansy', 'Tanya', 'Tara', 'Tarah', 'Tarra', 'Tarrah', 'Taryn', 'Tasha', 'Tasia', 'Tate', 'Tatiana', 'Tatiania', 'Tatum', 'Tawnya', 'Tawsha', 'Teane', 'Ted', 'Tedda', 'Teddi', 'Teddie', 'Teddy', 'Tedi', 'Tedra', 'Teena', 'Tella', 'Teodora', 'Tera', 'Teresa', 'TeresaAnne', 'Terese', 'Teresina', 'Teresita', 'Teressa', 'Teri', 'Teriann', 'Terina', 'Terra', 'Terri', 'Terri-Jo', 'Terrianne', 'Terrie', 'Terry', 'Terrye', 'Tersina', 'Teryl', 'Terza', 'Tess', 'Tessa', 'Tessi', 'Tessie', 'Tessy', 'Thalia', 'Thea', 'Theada', 'Theadora', 'Theda', 'Thekla', 'Thelma', 'Theo', 'Theodora', 'Theodosia', 'Theresa', 'Theresa-Marie', 'Therese', 'Theresina', 'Theresita', 'Theressa', 'Therine', 'Thia', 'Thomasa', 'Thomasin', 'Thomasina', 'Thomasine', 'Tia', 'Tiana', 'Tiena', 'Tierney', 'Tiertza', 'Tiff', 'Tiffani', 'Tiffanie', 'Tiffany', 'Tiffi', 'Tiffie', 'Tiffy', 'Tilda', 'Tildi', 'Tildie', 'Tildy', 'Tillie', 'Tilly', 'Tim', 'Timi', 'Timmi', 'Timmie', 'Timmy', 'Timothea', 'Tina', 'Tine', 'Tiphani', 'Tiphanie', 'Tiphany', 'Tish', 'Tisha', 'Tobe', 'Tobey', 'Tobi', 'Tobie', 'Toby', 'Tobye', 'Toinette', 'Toma', 'Tomasina', 'Tomasine', 'Tomi', 'Tomiko', 'Tommi', 'Tommie', 'Tommy', 'Toni', 'Tonia', 'Tonie', 'Tony', 'Tonya', 'Tootsie', 'Torey', 'Tori', 'Torie', 'Torrie', 'Tory', 'Tova', 'Tove', 'Trace', 'Tracee', 'Tracey', 'Traci', 'Tracie', 'Tracy', 'Trenna', 'Tresa', 'Trescha', 'Tressa', 'Tricia', 'Trina', 'Trish', 'Trisha', 'Trista', 'Trix', 'Trixi', 'Trixie', 'Trixy', 'Truda', 'Trude', 'Trudey', 'Trudi', 'Trudie', 'Trudy', 'Trula', 'Tuesday', 'Twila', 'Twyla', 'Tybi', 'Tybie', 'Tyne', 'Ula', 'Ulla', 'Ulrica', 'Ulrika', 'Ulrike', 'Umeko', 'Una', 'Ursa', 'Ursala', 'Ursola', 'Ursula', 'Ursulina', 'Ursuline', 'Uta', 'Val', 'Valaree', 'Valaria', 'Vale', 'Valeda', 'Valencia', 'Valene', 'Valenka', 'Valentia', 'Valentina', 'Valentine', 'Valera', 'Valeria', 'Valerie', 'Valery', 'Valerye', 'Valida', 'Valina', 'Valli', 'Vallie', 'Vally', 'Valma', 'Valry', 'Van', 'Vanda', 'Vanessa', 'Vania', 'Vanna', 'Vanni', 'Vannie', 'Vanny', 'Vanya', 'Veda', 'Velma', 'Velvet', 'Vena', 'Venita', 'Ventura', 'Venus', 'Vera', 'Veradis', 'Vere', 'Verena', 'Verene', 'Veriee', 'Verile', 'Verina', 'Verine', 'Verla', 'Verna', 'Vernice', 'Veronica', 'Veronika', 'Veronike', 'Veronique', 'Vi', 'Vicki', 'Vickie', 'Vicky', 'Victoria', 'Vida', 'Viki', 'Vikki', 'Vikkie', 'Vikky', 'Vilhelmina', 'Vilma', 'Vin', 'Vina', 'Vinita', 'Vinni', 'Vinnie', 'Vinny', 'Viola', 'Violante', 'Viole', 'Violet', 'Violetta', 'Violette', 'Virgie', 'Virgina', 'Virginia', 'Virginie', 'Vita', 'Vitia', 'Vitoria', 'Vittoria', 'Viv', 'Viva', 'Vivi', 'Vivia', 'Vivian', 'Viviana', 'Vivianna', 'Vivianne', 'Vivie', 'Vivien', 'Viviene', 'Vivienne', 'Viviyan', 'Vivyan', 'Vivyanne', 'Vonni', 'Vonnie', 'Vonny', 'Wallie', 'Wallis', 'Wally', 'Waly', 'Wanda', 'Wandie', 'Wandis', 'Waneta', 'Wenda', 'Wendeline', 'Wendi', 'Wendie', 'Wendy', 'Wenona', 'Wenonah', 'Whitney', 'Wileen', 'Wilhelmina', 'Wilhelmine', 'Wilie', 'Willa', 'Willabella', 'Willamina', 'Willetta', 'Willette', 'Willi', 'Willie', 'Willow', 'Willy', 'Willyt', 'Wilma', 'Wilmette', 'Wilona', 'Wilone', 'Wilow', 'Windy', 'Wini', 'Winifred', 'Winna', 'Winnah', 'Winne', 'Winni', 'Winnie', 'Winnifred', 'Winny', 'Winona', 'Winonah', 'Wren', 'Wrennie', 'Wylma', 'Wynn', 'Wynne', 'Wynnie', 'Wynny', 'Xaviera', 'Xena', 'Xenia', 'Xylia', 'Xylina', 'Yalonda', 'Yehudit', 'Yelena', 'Yetta', 'Yettie', 'Yetty', 'Yevette', 'Yoko', 'Yolanda', 'Yolande', 'Yolane', 'Yolanthe', 'Yonina', 'Yoshi', 'Yoshiko', 'Yovonnda', 'Yvette', 'Yvonne', 'Zabrina', 'Zahara', 'Zandra', 'Zaneta', 'Zara', 'Zarah', 'Zaria', 'Zarla', 'Zea', 'Zelda', 'Zelma', 'Zena', 'Zenia', 'Zia', 'Zilvia', 'Zita', 'Zitella', 'Zoe', 'Zola', 'Zonda', 'Zondra', 'Zonnya', 'Zora', 'Zorah', 'Zorana', 'Zorina', 'Zorine', 'Zsa Zsa', 'Zsazsa', 'Zulema', 'Zuzana', 'Mikako', 'Kaari', 'Gita', 'Geeta', '']\n"
     ]
    }
   ],
   "source": [
    "# female_names_list\n",
    "all_attribute = open(\"attrribute_names_lists/female_names.txt\", \"r\") \n",
    "data = all_attribute.read()\n",
    "female_names_list = data.split(\"\\n\")\n",
    "print((female_names_list))\n",
    "all_attribute.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim', 'Abdullah', 'Abe', 'Abel', 'Abelard', 'Abner', 'Abraham', 'Abram', 'Ace', 'Adair', 'Adam', 'Adams', 'Addie', 'Adger', 'Aditya', 'Adlai', 'Adnan', 'Adolf', 'Adolfo', 'Adolph', 'Adolphe', 'Adolpho', 'Adolphus', 'Adrian', 'Adrick', 'Adrien', 'Agamemnon', 'Aguinaldo', 'Aguste', 'Agustin', 'Aharon', 'Ahmad', 'Ahmed', 'Ahmet', 'Ajai', 'Ajay', 'Al', 'Alaa', 'Alain', 'Alan', 'Alasdair', 'Alastair', 'Albatros', 'Albert', 'Alberto', 'Albrecht', 'Alden', 'Aldis', 'Aldo', 'Aldric', 'Aldrich', 'Aldus', 'Aldwin', 'Alec', 'Aleck', 'Alejandro', 'Aleks', 'Aleksandrs', 'Alessandro', 'Alex', 'Alexander', 'Alexei', 'Alexis', 'Alf', 'Alfie', 'Alfonse', 'Alfonso', 'Alfonzo', 'Alford', 'Alfred', 'Alfredo', 'Algernon', 'Ali', 'Alic', 'Alister', 'Alix', 'Allah', 'Allan', 'Allen', 'Alley', 'Allie', 'Allin', 'Allyn', 'Alonso', 'Alonzo', 'Aloysius', 'Alphonse', 'Alphonso', 'Alston', 'Alton', 'Alvin', 'Alwin', 'Amadeus', 'Ambros', 'Ambrose', 'Ambrosi', 'Ambrosio', 'Ambrosius', 'Amery', 'Amory', 'Amos', 'Anatol', 'Anatole', 'Anatollo', 'Anatoly', 'Anders', 'Andie', 'Andonis', 'Andre', 'Andrea', 'Andreas', 'Andrej', 'Andres', 'Andrew', 'Andrey', 'Andri', 'Andros', 'Andrus', 'Andrzej', 'Andy', 'Angel', 'Angelico', 'Angelo', 'Angie', 'Angus', 'Ansel', 'Ansell', 'Anselm', 'Anson', 'Anthony', 'Antin', 'Antoine', 'Anton', 'Antone', 'Antoni', 'Antonin', 'Antonino', 'Antonio', 'Antonius', 'Antony', 'Anurag', 'Apollo', 'Apostolos', 'Aram', 'Archibald', 'Archibold', 'Archie', 'Archon', 'Archy', 'Arel', 'Ari', 'Arie', 'Ariel', 'Aristotle', 'Arlo', 'Armand', 'Armando', 'Armond', 'Armstrong', 'Arne', 'Arnie', 'Arnold', 'Arnoldo', 'Aron', 'Arron', 'Art', 'Arther', 'Arthur', 'Artie', 'Artur', 'Arturo', 'Arvie', 'Arvin', 'Arvind', 'Arvy', 'Ash', 'Ashby', 'Ashish', 'Ashley', 'Ashton', 'Aub', 'Aube', 'Aubert', 'Aubrey', 'Augie', 'August', 'Augustin', 'Augustine', 'Augusto', 'Augustus', 'Austen', 'Austin', 'Ave', 'Averell', 'Averil', 'Averill', 'Avery', 'Avi', 'Avraham', 'Avram', 'Avrom', 'Axel', 'Aylmer', 'Aziz', 'Bailey', 'Bailie', 'Baillie', 'Baily', 'Baird', 'Baldwin', 'Bancroft', 'Barbabas', 'Barclay', 'Bard', 'Barde', 'Barn', 'Barnabas', 'Barnabe', 'Barnaby', 'Barnard', 'Barnebas', 'Barnett', 'Barney', 'Barnie', 'Barny', 'Baron', 'Barr', 'Barret', 'Barrett', 'Barri', 'Barrie', 'Barris', 'Barron', 'Barry', 'Bart', 'Bartel', 'Barth', 'Barthel', 'Bartholemy', 'Bartholomeo', 'Bartholomeus', 'Bartholomew', 'Bartie', 'Bartlet', 'Bartlett', 'Bartolemo', 'Bartolomei', 'Bartolomeo', 'Barton', 'Barty', 'Bary', 'Basil', 'Batholomew', 'Baxter', 'Bay', 'Bayard', 'Beale', 'Bealle', 'Bear', 'Bearnard', 'Beau', 'Beaufort', 'Beauregard', 'Beck', 'Bela', 'Ben', 'Benedict', 'Bengt', 'Benito', 'Benjamen', 'Benjamin', 'Benji', 'Benjie', 'Benjy', 'Benn', 'Bennet', 'Bennett', 'Bennie', 'Benny', 'Benson', 'Bentley', 'Benton', 'Beowulf', 'Berchtold', 'Berk', 'Berke', 'Berkeley', 'Berkie', 'Berkley', 'Bernard', 'Bernardo', 'Bernd', 'Bernhard', 'Bernie', 'Bert', 'Bertie', 'Bertram', 'Bertrand', 'Bharat', 'Biff', 'Bill', 'Billie', 'Billy', 'Bing', 'Binky', 'Bishop', 'Bjorn', 'Bjorne', 'Blaine', 'Blair', 'Blake', 'Blare', 'Blayne', 'Bo', 'Bob', 'Bobbie', 'Bobby', 'Bogart', 'Bogdan', 'Boniface', 'Boris', 'Boyce', 'Boyd', 'Brad', 'Braden', 'Bradford', 'Bradley', 'Bradly', 'Brady', 'Brandon', 'Brandy', 'Brant', 'Brendan', 'Brent', 'Bret', 'Brett', 'Brewer', 'Brewster', 'Brian', 'Brice', 'Briggs', 'Brinkley', 'Britt', 'Brock', 'Broddie', 'Broddy', 'Broderic', 'Broderick', 'Brodie', 'Brody', 'Bronson', 'Brook', 'Brooke', 'Brooks', 'Bruce', 'Bruno', 'Bryan', 'Bryant', 'Bryce', 'Bryn', 'Bryon', 'Bubba', 'Buck', 'Bucky', 'Bud', 'Buddy', 'Burgess', 'Burke', 'Burl', 'Burnaby', 'Burt', 'Burton', 'Buster', 'Butch', 'Butler', 'Byram', 'Byron', 'Caesar', 'Cain', 'Cal', 'Caldwell', 'Caleb', 'Calhoun', 'Calvin', 'Cam', 'Cameron', 'Cammy', 'Carey', 'Carl', 'Carleigh', 'Carlie', 'Carlin', 'Carlo', 'Carlos', 'Carlton', 'Carlyle', 'Carmine', 'Carroll', 'Carson', 'Carsten', 'Carter', 'Cary', 'Caryl', 'Case', 'Casey', 'Caspar', 'Casper', 'Cass', 'Cat', 'Cecil', 'Cesar', 'Chad', 'Chadd', 'Chaddie', 'Chaddy', 'Chadwick', 'Chaim', 'Chalmers', 'Chan', 'Chance', 'Chancey', 'Chanderjit', 'Chandler', 'Chane', 'Chariot', 'Charles', 'Charleton', 'Charley', 'Charlie', 'Charlton', 'Chas', 'Chase', 'Chaunce', 'Chauncey', 'Che', 'Chelton', 'Chen', 'Chester', 'Cheston', 'Chet', 'Chev', 'Chevalier', 'Chevy', 'Chip', 'Chris', 'Chrissy', 'Christ', 'Christian', 'Christiano', 'Christie', 'Christof', 'Christofer', 'Christoph', 'Christophe', 'Christopher', 'Christorpher', 'Christos', 'Christy', 'Chrisy', 'Chuck', 'Churchill', 'Clair', 'Claire', 'Clancy', 'Clarance', 'Clare', 'Clarence', 'Clark', 'Clarke', 'Claude', 'Claudio', 'Claudius', 'Claus', 'Clay', 'Clayborn', 'Clayborne', 'Claybourne', 'Clayton', 'Cleland', 'Clem', 'Clemens', 'Clement', 'Clemente', 'Clemmie', 'Cletus', 'Cleveland', 'Cliff', 'Clifford', 'Clifton', 'Clint', 'Clinten', 'Clinton', 'Clive', 'Clyde', 'Cob', 'Cobb', 'Cobbie', 'Cobby', 'Cody', 'Colbert', 'Cole', 'Coleman', 'Colin', 'Collin', 'Collins', 'Conan', 'Connie', 'Connolly', 'Connor', 'Conrad', 'Conroy', 'Constantin', 'Constantine', 'Constantinos', 'Conway', 'Cooper', 'Corbin', 'Corby', 'Corey', 'Corky', 'Cornelius', 'Cornellis', 'Corrie', 'Cortese', 'Corwin', 'Cory', 'Cosmo', 'Costa', 'Courtney', 'Craig', 'Crawford', 'Creighton', 'Cris', 'Cristopher', 'Curt', 'Curtice', 'Curtis', 'Cy', 'Cyril', 'Cyrill', 'Cyrille', 'Cyrillus', 'Cyrus', 'Dabney', 'Daffy', 'Dale', 'Dallas', 'Dalton', 'Damian', 'Damien', 'Damon', 'Dan', 'Dana', 'Dane', 'Dani', 'Danie', 'Daniel', 'Dannie', 'Danny', 'Dante', 'Darby', 'Darcy', 'Daren', 'Darian', 'Darien', 'Darin', 'Dario', 'Darius', 'Darrel', 'Darrell', 'Darren', 'Darrick', 'Darrin', 'Darryl', 'Darth', 'Darwin', 'Daryl', 'Daryle', 'Dave', 'Davey', 'David', 'Davidde', 'Davide', 'Davidson', 'Davie', 'Davin', 'Davis', 'Davon', 'Davoud', 'Davy', 'Dawson', 'Dean', 'Deane', 'Del', 'Delbert', 'Dell', 'Delmar', 'Demetre', 'Demetri', 'Demetris', 'Demetrius', 'Demosthenis', 'Denis', 'Dennie', 'Dennis', 'Denny', 'Derby', 'Derek', 'Derick', 'Derk', 'Derrek', 'Derrick', 'Derrin', 'Derrol', 'Derron', 'Deryl', 'Desmond', 'Desmund', 'Devin', 'Devon', 'Dewey', 'Dewitt', 'Dexter', 'Dick', 'Dickey', 'Dickie', 'Diego', 'Dieter', 'Dietrich', 'Dillon', 'Dimitri', 'Dimitrios', 'Dimitris', 'Dimitrou', 'Dimitry', 'Dino', 'Dion', 'Dionis', 'Dionysus', 'Dirk', 'Dmitri', 'Dom', 'Domenic', 'Domenico', 'Dominic', 'Dominick', 'Dominique', 'Don', 'Donal', 'Donald', 'Donn', 'Donnie', 'Donny', 'Donovan', 'Dorian', 'Dory', 'Doug', 'Douggie', 'Dougie', 'Douglas', 'Douglass', 'Douglis', 'Dov', 'Doyle', 'Drake', 'Drew', 'Dru', 'Dryke', 'Duane', 'Dudley', 'Duffie', 'Duffy', 'Dugan', 'Duke', 'Dunc', 'Duncan', 'Dunstan', 'Durand', 'Durant', 'Durante', 'Durward', 'Dustin', 'Dwain', 'Dwaine', 'Dwane', 'Dwayne', 'Dwight', 'Dylan', 'Dyson', 'Earl', 'Earle', 'Easton', 'Eben', 'Ebeneser', 'Ebenezer', 'Eberhard', 'Ed', 'Eddie', 'Eddy', 'Edgar', 'Edgardo', 'Edie', 'Edmond', 'Edmund', 'Edouard', 'Edsel', 'Eduard', 'Eduardo', 'Edward', 'Edwin', 'Efram', 'Egbert', 'Ehud', 'Elbert', 'Elden', 'Eldon', 'Eli', 'Elias', 'Elihu', 'Elijah', 'Eliot', 'Eliott', 'Elisha', 'Elliot', 'Elliott', 'Ellis', 'Ellsworth', 'Ellwood', 'Elmer', 'Elmore', 'Elnar', 'Elric', 'Elroy', 'Elton', 'Elvin', 'Elvis', 'Elwin', 'Elwood', 'Elwyn', 'Ely', 'Emanuel', 'Emerson', 'Emery', 'Emil', 'Emile', 'Emilio', 'Emmanuel', 'Emmery', 'Emmet', 'Emmett', 'Emmit', 'Emmott', 'Emmy', 'Emory', 'Ender', 'Engelbart', 'Engelbert', 'Englebart', 'Englebert', 'Enoch', 'Enrico', 'Enrique', 'Ephraim', 'Ephram', 'Ephrayim', 'Ephrem', 'Er', 'Erasmus', 'Erastus', 'Erek', 'Erhard', 'Erhart', 'Eric', 'Erich', 'Erick', 'Erik', 'Erin', 'Erl', 'Ernest', 'Ernesto', 'Ernie', 'Ernst', 'Erny', 'Errol', 'Ervin', 'Erwin', 'Esau', 'Esme', 'Esteban', 'Ethan', 'Ethelbert', 'Ethelred', 'Etienne', 'Euclid', 'Eugen', 'Eugene', 'Eustace', 'Ev', 'Evan', 'Evelyn', 'Everard', 'Everett', 'Ewan', 'Ewart', 'Ez', 'Ezechiel', 'Ezekiel', 'Ezra', 'Fabian', 'Fabio', 'Fairfax', 'Farley', 'Fazeel', 'Federico', 'Felice', 'Felicio', 'Felipe', 'Felix', 'Ferd', 'Ferdie', 'Ferdinand', 'Ferdy', 'Fergus', 'Ferguson', 'Ferinand', 'Fernando', 'Fidel', 'Filbert', 'Filip', 'Filipe', 'Filmore', 'Finley', 'Finn', 'Fitz', 'Fitzgerald', 'Flem', 'Fleming', 'Flemming', 'Fletch', 'Fletcher', 'Flin', 'Flinn', 'Flint', 'Flipper', 'Florian', 'Floyd', 'Flynn', 'Fons', 'Fonsie', 'Fonz', 'Fonzie', 'Forbes', 'Ford', 'Forest', 'Forester', 'Forrest', 'Forrester', 'Forster', 'Foster', 'Fowler', 'Fox', 'Fran', 'Francesco', 'Francis', 'Francisco', 'Francois', 'Frank', 'Frankie', 'Franklin', 'Franklyn', 'Franky', 'Frans', 'Franz', 'Fraser', 'Frazier', 'Fred', 'Freddie', 'Freddy', 'Frederic', 'Frederich', 'Frederick', 'Frederico', 'Frederik', 'Fredric', 'Fredrick', 'Freeman', 'Freemon', 'Fremont', 'French', 'Friedric', 'Friedrich', 'Friedrick', 'Fritz', 'Fulton', 'Fyodor', 'Gabe', 'Gabriel', 'Gabriele', 'Gabriell', 'Gabriello', 'Gail', 'Gale', 'Galen', 'Gallagher', 'Gamaliel', 'Garcia', 'Garcon', 'Gardener', 'Gardiner', 'Gardner', 'Garey', 'Garfield', 'Garfinkel', 'Garold', 'Garp', 'Garret', 'Garrett', 'Garrot', 'Garrott', 'Garry', 'Garth', 'Garv', 'Garvey', 'Garvin', 'Garvy', 'Garwin', 'Garwood', 'Gary', 'Gaspar', 'Gasper', 'Gaston', 'Gav', 'Gaven', 'Gavin', 'Gavriel', 'Gay', 'Gayle', 'Gearard', 'Gene', 'Geo', 'Geof', 'Geoff', 'Geoffrey', 'Geoffry', 'Georg', 'George', 'Georges', 'Georgia', 'Georgie', 'Georgy', 'Gerald', 'Geraldo', 'Gerard', 'Gere', 'Gerhard', 'Gerhardt', 'Geri', 'Germaine', 'Gerold', 'Gerome', 'Gerrard', 'Gerri', 'Gerrit', 'Gerry', 'Gershom', 'Gershon', 'Giacomo', 'Gian', 'Giancarlo', 'Giavani', 'Gibb', 'Gideon', 'Giff', 'Giffard', 'Giffer', 'Giffie', 'Gifford', 'Giffy', 'Gil', 'Gilbert', 'Gilberto', 'Gilburt', 'Giles', 'Gill', 'Gilles', 'Ginger', 'Gino', 'Giordano', 'Giorgi', 'Giorgio', 'Giovanne', 'Giovanni', 'Giraldo', 'Giraud', 'Giuseppe', 'Glen', 'Glenn', 'Glynn', 'Godard', 'Godart', 'Goddard', 'Goddart', 'Godfree', 'Godfrey', 'Godfry', 'Godwin', 'Gomer', 'Gonzales', 'Gonzalo', 'Goober', 'Goose', 'Gordan', 'Gordie', 'Gordon', 'Grace', 'Grady', 'Graehme', 'Graeme', 'Graham', 'Graig', 'Grant', 'Granville', 'Greg', 'Gregg', 'Greggory', 'Gregor', 'Gregorio', 'Gregory', 'Gretchen', 'Griff', 'Griffin', 'Griffith', 'Griswold', 'Grove', 'Grover', 'Guido', 'Guillaume', 'Guillermo', 'Gunner', 'Gunter', 'Gunther', 'Gus', 'Gustaf', 'Gustav', 'Gustave', 'Gustavo', 'Gustavus', 'Guthrey', 'Guthrie', 'Guthry', 'Guy', 'Hadleigh', 'Hadley', 'Hadrian', 'Hagan', 'Hagen', 'Hailey', 'Hakeem', 'Hakim', 'Hal', 'Hale', 'Haleigh', 'Haley', 'Hall', 'Hallam', 'Halvard', 'Ham', 'Hamel', 'Hamid', 'Hamil', 'Hamilton', 'Hamish', 'Hamlen', 'Hamlet', 'Hamlin', 'Hammad', 'Hamnet', 'Han', 'Hanan', 'Hanford', 'Hank', 'Hannibal', 'Hans', 'Hans-Peter', 'Hansel', 'Hanson', 'Harald', 'Harcourt', 'Hari', 'Harlan', 'Harland', 'Harley', 'Harlin', 'Harman', 'Harmon', 'Harold', 'Harris', 'Harrison', 'Harrold', 'Harry', 'Hart', 'Hartley', 'Hartwell', 'Harv', 'Harvard', 'Harvey', 'Harvie', 'Harwell', 'Hasheem', 'Hashim', 'Haskel', 'Haskell', 'Hassan', 'Hastings', 'Hasty', 'Haven', 'Hayden', 'Haydon', 'Hayes', 'Hayward', 'Haywood', 'Hazel', 'Heath', 'Heathcliff', 'Hebert', 'Hector', 'Heinrich', 'Heinz', 'Helmuth', 'Henderson', 'Hendrick', 'Hendrik', 'Henri', 'Henrie', 'Henrik', 'Henrique', 'Henry', 'Herb', 'Herbert', 'Herbie', 'Herby', 'Hercule', 'Hercules', 'Herculie', 'Herman', 'Hermann', 'Hermon', 'Hermy', 'Hernando', 'Herold', 'Herrick', 'Herrmann', 'Hersch', 'Herschel', 'Hersh', 'Hershel', 'Herve', 'Hervey', 'Hew', 'Hewe', 'Hewet', 'Hewett', 'Hewie', 'Hewitt', 'Heywood', 'Hezekiah', 'Higgins', 'Hilary', 'Hilbert', 'Hill', 'Hillard', 'Hillary', 'Hillel', 'Hillery', 'Hilliard', 'Hilton', 'Hiralal', 'Hiram', 'Hiro', 'Hirsch', 'Hobart', 'Hodge', 'Hogan', 'Hollis', 'Holly', 'Homer', 'Horace', 'Horacio', 'Horatio', 'Horatius', 'Horst', 'Howard', 'Howie', 'Hoyt', 'Hubert', 'Hudson', 'Huey', 'Hugh', 'Hugo', 'Humbert', 'Humphrey', 'Hunt', 'Hunter', 'Huntington', 'Huntlee', 'Huntley', 'Hurley', 'Husain', 'Husein', 'Hussein', 'Hy', 'Hyatt', 'Hyman', 'Hymie', 'Iago', 'Iain', 'Ian', 'Ibrahim', 'Ichabod', 'Iggie', 'Iggy', 'Ignace', 'Ignacio', 'Ignacius', 'Ignatius', 'Ignaz', 'Ignazio', 'Igor', 'Ike', 'Ikey', 'Immanuel', 'Ingamar', 'Ingelbert', 'Ingemar', 'Inglebert', 'Ingmar', 'Ingram', 'Inigo', 'Ira', 'Irvin', 'Irvine', 'Irving', 'Irwin', 'Isa', 'Isaac', 'Isaak', 'Isador', 'Isadore', 'Isaiah', 'Ishmael', 'Isidore', 'Ismail', 'Israel', 'Istvan', 'Ivan', 'Ivor', 'Izaak', 'Izak', 'Izzy', 'Jabez', 'Jack', 'Jackie', 'Jackson', 'Jacob', 'Jacques', 'Jae', 'Jaime', 'Jake', 'Jakob', 'James', 'Jameson', 'Jamey', 'Jamie', 'Jan', 'Janos', 'Janus', 'Jared', 'Jarrett', 'Jarvis', 'Jason', 'Jasper', 'Javier', 'Jay', 'Jean', 'Jean-Christophe', 'Jean-Francois', 'Jean-Lou', 'Jean-Luc', 'Jean-Marc', 'Jean-Paul', 'Jean-Pierre', 'Jeb', 'Jed', 'Jedediah', 'Jef', 'Jeff', 'Jefferey', 'Jefferson', 'Jeffery', 'Jeffie', 'Jeffrey', 'Jeffry', 'Jefry', 'Jehu', 'Jennings', 'Jens', 'Jephthah', 'Jerald', 'Jeramie', 'Jere', 'Jereme', 'Jeremiah', 'Jeremias', 'Jeremie', 'Jeremy', 'Jermain', 'Jermaine', 'Jermayne', 'Jerold', 'Jerome', 'Jeromy', 'Jerri', 'Jerrie', 'Jerrold', 'Jerrome', 'Jerry', 'Jervis', 'Jerzy', 'Jess', 'Jesse', 'Jessee', 'Jessey', 'Jessie', 'Jesus', 'Jeth', 'Jethro', 'Jim', 'Jimbo', 'Jimmie', 'Jimmy', 'Jo', 'Joab', 'Joachim', 'Joao', 'Joaquin', 'Job', 'Jock', 'Jodi', 'Jodie', 'Jody', 'Joe', 'Joel', 'Joey', 'Johan', 'Johann', 'Johannes', 'John', 'John-David', 'John-Patrick', 'Johnathan', 'Johnathon', 'Johnnie', 'Johnny', 'Johny', 'Jon', 'Jonah', 'Jonas', 'Jonathan', 'Jonathon', 'Jonny', 'Jordan', 'Jordon', 'Jordy', 'Jorge', 'Jory', 'Jose', 'Josef', 'Joseph', 'Josephus', 'Josh', 'Joshua', 'Joshuah', 'Josiah', 'Jotham', 'Juan', 'Juanita', 'Jud', 'Judah', 'Judas', 'Judd', 'Jude', 'Judith', 'Judson', 'Judy', 'Juergen', 'Jule', 'Jules', 'Julian', 'Julie', 'Julio', 'Julius', 'Justin', 'Justis', 'Kaiser', 'Kaleb', 'Kalil', 'Kalle', 'Kalman', 'Kalvin', 'Kam', 'Kane', 'Kareem', 'Karel', 'Karim', 'Karl', 'Karsten', 'Kaspar', 'Keefe', 'Keenan', 'Keene', 'Keil', 'Keith', 'Kellen', 'Kelley', 'Kelly', 'Kelsey', 'Kelvin', 'Kelwin', 'Ken', 'Kendal', 'Kendall', 'Kendrick', 'Kenn', 'Kennedy', 'Kenneth', 'Kenny', 'Kent', 'Kenton', 'Kenyon', 'Kermie', 'Kermit', 'Kerry', 'Kevan', 'Kevin', 'Kim', 'Kimball', 'Kimmo', 'Kin', 'Kincaid', 'King', 'Kingsley', 'Kingsly', 'Kingston', 'Kip', 'Kirby', 'Kirk', 'Kit', 'Klaus', 'Klee', 'Knox', 'Konrad', 'Konstantin', 'Kory', 'Kostas', 'Kraig', 'Kris', 'Krishna', 'Kristian', 'Kristopher', 'Kristos', 'Kurt', 'Kurtis', 'Kyle', 'Laird', 'Lamar', 'Lambert', 'Lamont', 'Lance', 'Lancelot', 'Lane', 'Langston', 'Lanny', 'Larry', 'Lars', 'Laurance', 'Lauren', 'Laurence', 'Laurens', 'Laurent', 'Laurie', 'Lawerence', 'Lawrence', 'Lawson', 'Lawton', 'Lay', 'Layton', 'Lazar', 'Lazare', 'Lazaro', 'Lazarus', 'Lazlo', 'Lee', 'Lefty', 'Leif', 'Leigh', 'Leighton', 'Leland', 'Lem', 'Lemar', 'Lemmie', 'Lemmy', 'Lemuel', 'Len', 'Lenard', 'Lennie', 'Lenny', 'Leo', 'Leon', 'Leonard', 'Leonardo', 'Leonerd', 'Leonhard', 'Leonid', 'Leonidas', 'Leopold', 'Leroy', 'Les', 'Lesley', 'Leslie', 'Lester', 'Lev', 'Levi', 'Levin', 'Levon', 'Levy', 'Lew', 'Lewis', 'Lex', 'Liam', 'Lin', 'Lincoln', 'Lind', 'Lindsay', 'Lindsey', 'Lindy', 'Linoel', 'Linus', 'Lion', 'Lionel', 'Lionello', 'Llewellyn', 'Lloyd', 'Locke', 'Lockwood', 'Logan', 'Lon', 'Lonnie', 'Lonny', 'Loren', 'Lorenzo', 'Lorne', 'Lorrie', 'Lothar', 'Lou', 'Louie', 'Louis', 'Lovell', 'Lowell', 'Lucas', 'Luce', 'Lucian', 'Luciano', 'Lucien', 'Lucio', 'Lucius', 'Ludvig', 'Ludwig', 'Luigi', 'Luis', 'Lukas', 'Luke', 'Luther', 'Lyle', 'Lyn', 'Lyndon', 'Lynn', 'Mac', 'Mace', 'Mack', 'Mackenzie', 'Maddie', 'Maddy', 'Madison', 'Magnum', 'Magnus', 'Mahesh', 'Mahmoud', 'Mahmud', 'Maison', 'Major', 'Malcolm', 'Manfred', 'Manish', 'Manny', 'Manuel', 'Marc', 'Marcel', 'Marcello', 'Marcellus', 'Marcelo', 'Marchall', 'Marcio', 'Marco', 'Marcos', 'Marcus', 'Marietta', 'Marilu', 'Mario', 'Marion', 'Marius', 'Mark', 'Marko', 'Markos', 'Markus', 'Marlin', 'Marlo', 'Marlon', 'Marlow', 'Marlowe', 'Marmaduke', 'Marsh', 'Marshal', 'Marshall', 'Mart', 'Martainn', 'Marten', 'Martie', 'Martin', 'Martino', 'Marty', 'Martyn', 'Marv', 'Marve', 'Marven', 'Marvin', 'Marwin', 'Mason', 'Mateo', 'Mathew', 'Mathias', 'Matias', 'Matt', 'Matteo', 'Matthaeus', 'Mattheus', 'Matthew', 'Matthias', 'Matthieu', 'Matthiew', 'Matthus', 'Mattias', 'Mattie', 'Matty', 'Maurice', 'Mauricio', 'Maurie', 'Maurise', 'Maurits', 'Mauritz', 'Maury', 'Max', 'Maxfield', 'Maxie', 'Maxim', 'Maximilian', 'Maximilien', 'Maxwell', 'Mayer', 'Maynard', 'Maynord', 'Mayor', 'Mead', 'Meade', 'Meier', 'Meir', 'Mel', 'Melvin', 'Melvyn', 'Menard', 'Mendel', 'Mendie', 'Meredeth', 'Meredith', 'Merell', 'Merill', 'Merle', 'Merlin', 'Merrel', 'Merrick', 'Merril', 'Merrill', 'Merry', 'Merv', 'Mervin', 'Merwin', 'Meryl', 'Meyer', 'Mic', 'Micah', 'Michael', 'Michail', 'Michal', 'Michale', 'Micheal', 'Micheil', 'Michel', 'Michele', 'Mick', 'Mickey', 'Mickie', 'Micky', 'Miguel', 'Mika', 'Mikael', 'Mike', 'Mikel', 'Mikey', 'Mikhail', 'Miles', 'Millicent', 'Milo', 'Milt', 'Milton', 'Mischa', 'Mitch', 'Mitchael', 'Mitchel', 'Mitchell', 'Moe', 'Mohamad', 'Mohamed', 'Mohammad', 'Mohammed', 'Mohan', 'Moise', 'Moises', 'Moishe', 'Monroe', 'Montague', 'Monte', 'Montgomery', 'Monty', 'Moore', 'Mordecai', 'Morgan', 'Morlee', 'Morley', 'Morly', 'Morrie', 'Morris', 'Morry', 'Morse', 'Mort', 'Morten', 'Mortie', 'Mortimer', 'Morton', 'Morty', 'Mose', 'Moses', 'Moshe', 'Moss', 'Muffin', 'Mugsy', 'Muhammad', 'Munmro', 'Munroe', 'Murdoch', 'Murdock', 'Murphy', 'Murray', 'Mustafa', 'Myke', 'Myles', 'Mylo', 'Myron', 'Nahum', 'Napoleon', 'Nat', 'Natale', 'Nate', 'Nathan', 'Nathanael', 'Nathanial', 'Nathaniel', 'Nathanil', 'Neal', 'Neale', 'Neall', 'Nealon', 'Nealson', 'Nealy', 'Ned', 'Neddie', 'Neddy', 'Neel', 'Neil', 'Nels', 'Nelsen', 'Nelson', 'Nero', 'Neron', 'Nester', 'Nestor', 'Nev', 'Nevil', 'Nevile', 'Neville', 'Nevin', 'Nevins', 'Newton', 'Niall', 'Niccolo', 'Nicholas', 'Nichole', 'Nichols', 'Nick', 'Nickey', 'Nickie', 'Nickolas', 'Nicky', 'Nico', 'Nicolas', 'Niels', 'Nigel', 'Niki', 'Nikita', 'Nikki', 'Nikolai', 'Nikos', 'Niles', 'Nils', 'Nilson', 'Niven', 'Noach', 'Noah', 'Noam', 'Noble', 'Noe', 'Noel', 'Nolan', 'Noland', 'Norbert', 'Norm', 'Norman', 'Normand', 'Normie', 'Norris', 'Northrop', 'Northrup', 'Norton', 'Norwood', 'Nunzio', 'Obadiah', 'Obadias', 'Oberon', 'Obie', 'Octavius', 'Odell', 'Odie', 'Odin', 'Odysseus', 'Olaf', 'Olag', 'Ole', 'Oleg', 'Olin', 'Oliver', 'Olivier', 'Olle', 'Ollie', 'Omar', 'Oral', 'Oran', 'Orazio', 'Orbadiah', 'Oren', 'Orin', 'Orion', 'Orlando', 'Orren', 'Orrin', 'Orson', 'Orton', 'Orville', 'Osbert', 'Osborn', 'Osborne', 'Osbourn', 'Osbourne', 'Oscar', 'Osgood', 'Osmond', 'Osmund', 'Ossie', 'Oswald', 'Oswell', 'Otes', 'Othello', 'Otho', 'Otis', 'Otto', 'Owen', 'Ozzie', 'Ozzy', 'Pablo', 'Pace', 'Paco', 'Paddie', 'Paddy', 'Padraig', 'Page', 'Paige', 'Pail', 'Palmer', 'Paolo', 'Park', 'Parke', 'Parker', 'Parnell', 'Parrnell', 'Parry', 'Parsifal', 'Partha', 'Pascal', 'Pascale', 'Pasquale', 'Pat', 'Pate', 'Patel', 'Paten', 'Patin', 'Paton', 'Patric', 'Patrice', 'Patricio', 'Patrick', 'Patrik', 'Patsy', 'Pattie', 'Patty', 'Paul', 'Paulo', 'Pavel', 'Pearce', 'Pedro', 'Peirce', 'Pembroke', 'Pen', 'Penn', 'Pennie', 'Penny', 'Penrod', 'Pepe', 'Pepillo', 'Pepito', 'Perceval', 'Percival', 'Percy', 'Perry', 'Pete', 'Peter', 'Petey', 'Petr', 'Peyter', 'Peyton', 'Phil', 'Philbert', 'Philip', 'Phillip', 'Phillipe', 'Phillipp', 'Phineas', 'Phip', 'Pierce', 'Pierre', 'Pierson', 'Piet', 'Pieter', 'Pietro', 'Piggy', 'Pincas', 'Pinchas', 'Pincus', 'Piotr', 'Pip', 'Plato', 'Pooh', 'Porter', 'Poul', 'Powell', 'Praneetf', 'Prasad', 'Prasun', 'Prent', 'Prentice', 'Prentiss', 'Prescott', 'Preston', 'Price', 'Prince', 'Pryce', 'Puff', 'Purcell', 'Putnam', 'Pyotr', 'Quent', 'Quentin', 'Quiggly', 'Quigly', 'Quigman', 'Quill', 'Quillan', 'Quincey', 'Quincy', 'Quinlan', 'Quinn', 'Quint', 'Quintin', 'Quinton', 'Quintus', 'Rab', 'Rabbi', 'Rabi', 'Rad', 'Radcliffe', 'Rafael', 'Rafe', 'Ragnar', 'Raimund', 'Rainer', 'Raj', 'Rajeev', 'Raleigh', 'Ralf', 'Ralph', 'Ram', 'Ramesh', 'Ramon', 'Ramsay', 'Ramsey', 'Rand', 'Randal', 'Randall', 'Randell', 'Randi', 'Randie', 'Randolf', 'Randolph', 'Randy', 'Ransell', 'Ransom', 'Raoul', 'Raphael', 'Raul', 'Ravi', 'Ravil', 'Rawley', 'Ray', 'Raymond', 'Raymund', 'Raymundo', 'Raynard', 'Rayner', 'Raynor', 'Reagan', 'Red', 'Redford', 'Redmond', 'Reece', 'Reed', 'Rees', 'Reese', 'Reg', 'Regan', 'Regen', 'Reggie', 'Reggis', 'Reggy', 'Reginald', 'Reginauld', 'Reid', 'Reilly', 'Reinhard', 'Reinhold', 'Rem', 'Remington', 'Remus', 'Renado', 'Renaldo', 'Renard', 'Renato', 'Renaud', 'Renault', 'Rene', 'Reube', 'Reuben', 'Reuven', 'Rex', 'Rey', 'Reynard', 'Reynold', 'Reynolds', 'Reza', 'Rhett', 'Ric', 'Ricard', 'Ricardo', 'Riccardo', 'Rice', 'Rich', 'Richard', 'Richardo', 'Richie', 'Richmond', 'Richy', 'Rick', 'Rickard', 'Rickey', 'Ricki', 'Rickie', 'Ricky', 'Rik', 'Rikki', 'Riley', 'Rinaldo', 'Ripley', 'Ritch', 'Ritchie', 'Roarke', 'Rob', 'Robb', 'Robbert', 'Robbie', 'Robert', 'Roberto', 'Robin', 'Robinson', 'Rochester', 'Rock', 'Rockwell', 'Rocky', 'Rod', 'Rodd', 'Roddie', 'Roddy', 'Roderic', 'Roderich', 'Roderick', 'Roderigo', 'Rodge', 'Rodger', 'Rodney', 'Rodolfo', 'Rodolph', 'Rodolphe', 'Rodrick', 'Rodrigo', 'Rodrique', 'Rog', 'Roger', 'Rogers', 'Roice', 'Roland', 'Rolando', 'Rolf', 'Rolfe', 'Rolland', 'Rollin', 'Rollins', 'Rollo', 'Rolph', 'Romain', 'Roman', 'Romeo', 'Ron', 'Ronald', 'Ronen', 'Roni', 'Ronnie', 'Ronny', 'Roosevelt', 'Rory', 'Roscoe', 'Ross', 'Roth', 'Rourke', 'Rowland', 'Roy', 'Royal', 'Royce', 'Rube', 'Ruben', 'Rubin', 'Ruby', 'Rudd', 'Ruddie', 'Ruddy', 'Rudie', 'Rudiger', 'Rudolf', 'Rudolfo', 'Rudolph', 'Rudy', 'Rudyard', 'Rufe', 'Rufus', 'Rupert', 'Ruperto', 'Russ', 'Russel', 'Russell', 'Rustie', 'Rustin', 'Rusty', 'Rutger', 'Rutherford', 'Rutledge', 'Rutter', 'Ryan', 'Sal', 'Salem', 'Salim', 'Salman', 'Salmon', 'Salomo', 'Salomon', 'Salomone', 'Salvador', 'Salvatore', 'Salvidor', 'Sam', 'Sammie', 'Sammy', 'Sampson', 'Samson', 'Samuel', 'Samuele', 'Sancho', 'Sander', 'Sanders', 'Sanderson', 'Sandor', 'Sandro', 'Sandy', 'Sanford', 'Sanson', 'Sansone', 'Sarge', 'Sargent', 'Sascha', 'Sasha', 'Saul', 'Sauncho', 'Saunder', 'Saunders', 'Saunderson', 'Saundra', 'Saw', 'Sawyer', 'Sawyere', 'Sax', 'Saxe', 'Saxon', 'Say', 'Sayer', 'Sayers', 'Sayre', 'Sayres', 'Scarface', 'Schroeder', 'Schuyler', 'Scot', 'Scott', 'Scotti', 'Scottie', 'Scotty', 'Seamus', 'Sean', 'Sebastian', 'Sebastiano', 'Sebastien', 'See', 'Selby', 'Selig', 'Serge', 'Sergeant', 'Sergei', 'Sergent', 'Sergio', 'Seth', 'Seymour', 'Shadow', 'Shaine', 'Shalom', 'Shamus', 'Shanan', 'Shane', 'Shannan', 'Shannon', 'Shaughn', 'Shaun', 'Shaw', 'Shawn', 'Shay', 'Shayne', 'Shea', 'Sheff', 'Sheffie', 'Sheffield', 'Sheffy', 'Shelby', 'Shelden', 'Sheldon', 'Shell', 'Shelley', 'Shelton', 'Shem', 'Shep', 'Shepard', 'Shepherd', 'Sheppard', 'Shepperd', 'Sheridan', 'Sherlock', 'Sherlocke', 'Sherman', 'Sherwin', 'Sherwood', 'Sherwynd', 'Shimon', 'Shlomo', 'Sholom', 'Shorty', 'Shurlock', 'Shurlocke', 'Shurwood', 'Si', 'Sibyl', 'Sid', 'Siddhartha', 'Sidnee', 'Sidney', 'Siegfried', 'Siffre', 'Sig', 'Sigfrid', 'Sigfried', 'Sigmund', 'Silas', 'Silvain', 'Silvan', 'Silvano', 'Silvanus', 'Silvester', 'Silvio', 'Sim', 'Simeon', 'Simmonds', 'Simon', 'Simone', 'Sinclair', 'Sinclare', 'Sivert', 'Siward', 'Skell', 'Skelly', 'Skip', 'Skipp', 'Skipper', 'Skippie', 'Skippy', 'Skipton', 'Sky', 'Skye', 'Skylar', 'Skyler', 'Slade', 'Slim', 'Sloan', 'Sloane', 'Sly', 'Smith', 'Smitty', 'Socrates', 'Sol', 'Sollie', 'Solly', 'Solomon', 'Somerset', 'Son', 'Sonnie', 'Sonny', 'Sparky', 'Spence', 'Spencer', 'Spense', 'Spenser', 'Spike', 'Spiro', 'Spiros', 'Spud', 'Srinivas', 'Stacy', 'Staffard', 'Stafford', 'Staford', 'Stan', 'Standford', 'Stanfield', 'Stanford', 'Stanislaw', 'Stanleigh', 'Stanley', 'Stanly', 'Stanton', 'Stanwood', 'Stavros', 'Stearn', 'Stearne', 'Stefan', 'Stefano', 'Steffen', 'Stephan', 'Stephanus', 'Stephen', 'Sterling', 'Stern', 'Sterne', 'Steve', 'Steven', 'Stevie', 'Stevy', 'Stew', 'Steward', 'Stewart', 'Stig', 'Stillman', 'Stillmann', 'Sting', 'Stinky', 'Stirling', 'Stu', 'Stuart', 'Sturgis', 'Sullivan', 'Sully', 'Sumner', 'Sunny', 'Sutherland', 'Sutton', 'Sven', 'Swen', 'Syd', 'Sydney', 'Sylvan', 'Sylvester', 'Tab', 'Tabb', 'Tabbie', 'Tabby', 'Taber', 'Tabor', 'Tad', 'Tadd', 'Taddeo', 'Taddeus', 'Tadeas', 'Tailor', 'Tait', 'Taite', 'Talbert', 'Talbot', 'Tallie', 'Tally', 'Tam', 'Tamas', 'Tammie', 'Tammy', 'Tan', 'Tann', 'Tanner', 'Tanney', 'Tannie', 'Tanny', 'Tarrance', 'Tarrant', 'Tarzan', 'Tate', 'Taylor', 'Teador', 'Ted', 'Tedd', 'Teddie', 'Teddy', 'Tedie', 'Tedman', 'Tedmund', 'Tedrick', 'Temp', 'Temple', 'Templeton', 'Teodoor', 'Teodor', 'Teodorico', 'Teodoro', 'Terence', 'Terencio', 'Terrance', 'Terrel', 'Terrell', 'Terrence', 'Terri', 'Terrill', 'Terry', 'Thacher', 'Thad', 'Thaddeus', 'Thaddius', 'Thaddus', 'Thadeus', 'Thain', 'Thaine', 'Thane', 'Tharen', 'Thatch', 'Thatcher', 'Thaxter', 'Thayne', 'Thebault', 'Thedric', 'Thedrick', 'Theo', 'Theobald', 'Theodor', 'Theodore', 'Theodoric', 'Theophyllus', 'Thibaud', 'Thibaut', 'Thom', 'Thomas', 'Thor', 'Thorn', 'Thorndike', 'Thornie', 'Thornton', 'Thorny', 'Thorpe', 'Thorstein', 'Thorsten', 'Thorvald', 'Thurstan', 'Thurston', 'Tibold', 'Tiebold', 'Tiebout', 'Tiler', 'Tim', 'Timmie', 'Timmy', 'Timothee', 'Timotheus', 'Timothy', 'Tirrell', 'Tito', 'Titos', 'Titus', 'Tobe', 'Tobiah', 'Tobias', 'Tobie', 'Tobin', 'Tobit', 'Toby', 'Tod', 'Todd', 'Toddie', 'Toddy', 'Tom', 'Tomas', 'Tome', 'Tomkin', 'Tomlin', 'Tommie', 'Tommy', 'Tonnie', 'Tony', 'Tore', 'Torey', 'Torin', 'Torr', 'Torrance', 'Torre', 'Torrence', 'Torrey', 'Torrin', 'Torry', 'Town', 'Towney', 'Townie', 'Townsend', 'Towny', 'Trace', 'Tracey', 'Tracie', 'Tracy', 'Traver', 'Travers', 'Travis', 'Tray', 'Tre', 'Tremain', 'Tremaine', 'Tremayne', 'Trent', 'Trenton', 'Trev', 'Trevar', 'Trever', 'Trevor', 'Trey', 'Trip', 'Tristan', 'Troy', 'Truman', 'Tuck', 'Tucker', 'Tuckie', 'Tucky', 'Tudor', 'Tull', 'Tulley', 'Tully', 'Turner', 'Ty', 'Tybalt', 'Tye', 'Tyler', 'Tymon', 'Tymothy', 'Tynan', 'Tyrone', 'Tyrus', 'Tyson', 'Udale', 'Udall', 'Udell', 'Ugo', 'Ulberto', 'Uli', 'Ulick', 'Ulises', 'Ulric', 'Ulrich', 'Ulrick', 'Ulysses', 'Umberto', 'Upton', 'Urbain', 'Urban', 'Urbano', 'Urbanus', 'Uri', 'Uriah', 'Uriel', 'Urson', 'Vachel', 'Vaclav', 'Vail', 'Val', 'Valdemar', 'Vale', 'Valentin', 'Valentine', 'Van', 'Vance', 'Vasili', 'Vasilis', 'Vasily', 'Vassili', 'Vassily', 'Vaughan', 'Vaughn', 'Venkat', 'Verge', 'Vergil', 'Vern', 'Verne', 'Vernen', 'Verney', 'Vernon', 'Vernor', 'Vic', 'Vick', 'Victor', 'Vijay', 'Vilhelm', 'Vin', 'Vince', 'Vincent', 'Vincents', 'Vinnie', 'Vinny', 'Vinod', 'Virge', 'Virgie', 'Virgil', 'Virgilio', 'Vite', 'Vito', 'Vlad', 'Vladamir', 'Vladimir', 'Voltaire', 'Von', 'Wade', 'Wadsworth', 'Wain', 'Waine', 'Wainwright', 'Wait', 'Waite', 'Waiter', 'Wake', 'Wakefield', 'Wald', 'Waldemar', 'Walden', 'Waldo', 'Waldon', 'Waleed', 'Walker', 'Wallace', 'Wallache', 'Wallas', 'Wallie', 'Wallis', 'Wally', 'Walsh', 'Walt', 'Walter', 'Walther', 'Walton', 'Wang', 'Ward', 'Warde', 'Warden', 'Ware', 'Waring', 'Warner', 'Warren', 'Wash', 'Washington', 'Wat', 'Waverley', 'Waverly', 'Way', 'Waylan', 'Wayland', 'Waylen', 'Waylin', 'Waylon', 'Wayne', 'Web', 'Webb', 'Weber', 'Webster', 'Weidar', 'Weider', 'Welbie', 'Welby', 'Welch', 'Wells', 'Welsh', 'Wendall', 'Wendel', 'Wendell', 'Werner', 'Wes', 'Wesley', 'Weslie', 'West', 'Westbrook', 'Westbrooke', 'Westleigh', 'Westley', 'Weston', 'Weylin', 'Wheeler', 'Whit', 'Whitaker', 'Whitby', 'Whitman', 'Whitney', 'Whittaker', 'Wiatt', 'Wilber', 'Wilbert', 'Wilbur', 'Wilburn', 'Wilburt', 'Wilden', 'Wildon', 'Wilek', 'Wiley', 'Wilfred', 'Wilfrid', 'Wilhelm', 'Will', 'Willard', 'Willdon', 'Willem', 'Willey', 'Willi', 'William', 'Willie', 'Willis', 'Willmott', 'Willy', 'Wilmar', 'Wilmer', 'Wilson', 'Wilt', 'Wilton', 'Win', 'Windham', 'Winfield', 'Winford', 'Winfred', 'Winifield', 'Winn', 'Winnie', 'Winny', 'Winslow', 'Winston', 'Winthrop', 'Winton', 'Wit', 'Witold', 'Wittie', 'Witty', 'Wojciech', 'Wolf', 'Wolfgang', 'Wolfie', 'Wolfram', 'Wolfy', 'Woochang', 'Wood', 'Woodie', 'Woodman', 'Woodrow', 'Woody', 'Worden', 'Worth', 'Worthington', 'Worthy', 'Wright', 'Wyatan', 'Wyatt', 'Wye', 'Wylie', 'Wyn', 'Wyndham', 'Wynn', 'Wynton', 'Xavier', 'Xenos', 'Xerxes', 'Xever', 'Ximenes', 'Ximenez', 'Xymenes', 'Yaakov', 'Yacov', 'Yale', 'Yanaton', 'Yance', 'Yancey', 'Yancy', 'Yank', 'Yankee', 'Yard', 'Yardley', 'Yehudi', 'Yigal', 'Yule', 'Yuri', 'Yves', 'Zach', 'Zacharia', 'Zachariah', 'Zacharias', 'Zacharie', 'Zachary', 'Zacherie', 'Zachery', 'Zack', 'Zackariah', 'Zak', 'Zalman', 'Zane', 'Zared', 'Zary', 'Zeb', 'Zebadiah', 'Zebedee', 'Zebulen', 'Zebulon', 'Zechariah', 'Zed', 'Zedekiah', 'Zeke', 'Zelig', 'Zerk', 'Zeus', 'Zippy', 'Zollie', 'Zolly', 'Zorro', 'Rahul', 'Shumeet', 'Vibhu', '']\n"
     ]
    }
   ],
   "source": [
    "# male_names_list\n",
    "all_attribute = open(\"attrribute_names_lists/male_names.txt\", \"r\") \n",
    "data = all_attribute.read()\n",
    "male_names_list = data.split(\"\\n\")\n",
    "print((male_names_list))\n",
    "all_attribute.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_attributes_ids(all_attribute_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project_ghent/bias_mitigation_in_text_classification/bias_in_bios_k_fold/job_data_unbalanced_original_and_flipped.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  female_bios_df[\"job_cat\"] = \"female_job\"\n",
      "/project_ghent/bias_mitigation_in_text_classification/bias_in_bios_k_fold/job_data_unbalanced_original_and_flipped.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  female_bios_df[\"job_cat_id\"] = int(0)\n",
      "/project_ghent/bias_mitigation_in_text_classification/bias_in_bios_k_fold/job_data_unbalanced_original_and_flipped.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  male_bios_df[\"job_cat\"] = \"male_job\"\n",
      "/project_ghent/bias_mitigation_in_text_classification/bias_in_bios_k_fold/job_data_unbalanced_original_and_flipped.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  male_bios_df[\"job_cat_id\"] = int(1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title gender  label  \\\n",
       "31289          architect      M      1   \n",
       "61990  software engineer      M     24   \n",
       "29313           comedian      M      4   \n",
       "61302       psychologist      M     22   \n",
       "60333          architect      M      1   \n",
       "...                  ...    ...    ...   \n",
       "5098                  DJ      M      8   \n",
       "11063            Surgeon      M     25   \n",
       "49107       psychologist      F     22   \n",
       "8028           Dietitian      F      7   \n",
       "45876          Architect      M      1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  \n",
       "31289    male_job           1  \n",
       "61990    male_job           1  \n",
       "29313    male_job           1  \n",
       "61302  female_job           0  \n",
       "60333    male_job           1  \n",
       "...           ...         ...  \n",
       "5098     male_job           1  \n",
       "11063    male_job           1  \n",
       "49107  female_job           0  \n",
       "8028   female_job           0  \n",
       "45876    male_job           1  \n",
       "\n",
       "[21499 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import job_data_unbalanced_original_and_flipped\n",
    "# import job_data_unbalanced_test\n",
    "df = job_data_unbalanced_original_and_flipped.final_bios_df\n",
    "# test_df = job_data_unbalanced_test.test_final_bios_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title gender  old_label  \\\n",
       "31289          architect      M          1   \n",
       "61990  software engineer      M         24   \n",
       "29313           comedian      M          4   \n",
       "61302       psychologist      M         22   \n",
       "60333          architect      M          1   \n",
       "...                  ...    ...        ...   \n",
       "5098                  DJ      M          8   \n",
       "11063            Surgeon      M         25   \n",
       "49107       psychologist      F         22   \n",
       "8028           Dietitian      F          7   \n",
       "45876          Architect      M          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  \n",
       "31289    male_job           1  \n",
       "61990    male_job           1  \n",
       "29313    male_job           1  \n",
       "61302  female_job           0  \n",
       "60333    male_job           1  \n",
       "...           ...         ...  \n",
       "5098     male_job           1  \n",
       "11063    male_job           1  \n",
       "49107  female_job           0  \n",
       "8028   female_job           0  \n",
       "45876    male_job           1  \n",
       "\n",
       "[21499 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'label':'old_label'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = 0\n",
    "# for k,i in enumerate(df.old_label.unique()):\n",
    "#     df['label'] = np.where(df['old_label']== i, k, df['label'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = pd.Series(df.label.values,index=df.prof).to_dict()\n",
    "# label_dict\n",
    "label_dict = {\n",
    "    'yoga_teacher': 0,\n",
    " 'dietitian': 1,\n",
    " 'comedian': 2,\n",
    " 'composer': 3,\n",
    " 'surgeon': 4,\n",
    " 'nurse': 5,\n",
    " 'rapper': 6,\n",
    " 'dj': 7,\n",
    " 'psychologist': 8,\n",
    " 'model': 9,\n",
    " 'interior_designer': 10,\n",
    " 'software_engineer': 11,\n",
    " 'paralegal': 12,\n",
    " 'architect': 13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title gender  old_label  \\\n",
       "31289          architect      M          1   \n",
       "61990  software engineer      M         24   \n",
       "29313           comedian      M          4   \n",
       "61302       psychologist      M         22   \n",
       "60333          architect      M          1   \n",
       "...                  ...    ...        ...   \n",
       "5098                  DJ      M          8   \n",
       "11063            Surgeon      M         25   \n",
       "49107       psychologist      F         22   \n",
       "8028           Dietitian      F          7   \n",
       "45876          Architect      M          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  label  \n",
       "31289    male_job           1     13  \n",
       "61990    male_job           1     11  \n",
       "29313    male_job           1      2  \n",
       "61302  female_job           0      8  \n",
       "60333    male_job           1     13  \n",
       "...           ...         ...    ...  \n",
       "5098     male_job           1      7  \n",
       "11063    male_job           1      4  \n",
       "49107  female_job           0      8  \n",
       "8028   female_job           0      1  \n",
       "45876    male_job           1     13  \n",
       "\n",
       "[21499 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'label':'old_label'}, inplace=True)\n",
    "df['label'] = df['prof'].map(label_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 4151,\n",
       " 13: 2796,\n",
       " 5: 2788,\n",
       " 4: 2736,\n",
       " 11: 1990,\n",
       " 3: 1750,\n",
       " 9: 1549,\n",
       " 1: 1006,\n",
       " 2: 813,\n",
       " 12: 412,\n",
       " 0: 406,\n",
       " 10: 393,\n",
       " 6: 362,\n",
       " 7: 347}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'label':'old_label'}, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = 0\n",
    "# for k,i in enumerate(df.old_label.unique()):\n",
    "#     df['label'] = np.where(df['old_label']== i, k, df['label'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title  gender  old_label  \\\n",
       "31289          architect       1          1   \n",
       "61990  software engineer       1         24   \n",
       "29313           comedian       1          4   \n",
       "61302       psychologist       1         22   \n",
       "60333          architect       1          1   \n",
       "...                  ...     ...        ...   \n",
       "5098                  DJ       1          8   \n",
       "11063            Surgeon       1         25   \n",
       "49107       psychologist       0         22   \n",
       "8028           Dietitian       0          7   \n",
       "45876          Architect       1          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  label  \n",
       "31289    male_job           1     13  \n",
       "61990    male_job           1     11  \n",
       "29313    male_job           1      2  \n",
       "61302  female_job           0      8  \n",
       "60333    male_job           1     13  \n",
       "...           ...         ...    ...  \n",
       "5098     male_job           1      7  \n",
       "11063    male_job           1      4  \n",
       "49107  female_job           0      8  \n",
       "8028   female_job           0      1  \n",
       "45876    male_job           1     13  \n",
       "\n",
       "[21499 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = {'M': 1,'F': 0}\n",
    "df.gender = [gender[item] for item in df.gender]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/etokpoua/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_scrubbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, focuses, on, cloud, security, ,, identity,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[_, is, the, creator, of, Statoshi, ,, a, fork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[_, children, 's, books, include, ``, Pouch, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, also, has, a, therapy, practice, ,, throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, exhibition, explores, concrete, construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[_, ’, s, toured, the, UK, ,, Europe, and, Can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[Dr., _, graduated, from, Andhra, Medical, Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, has, a, longstanding, interest, in, youth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[_, provides, one-on-one, dietary, counseling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, has, over, fourteen, years, of, experience...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title  gender  old_label  \\\n",
       "31289          architect       1          1   \n",
       "61990  software engineer       1         24   \n",
       "29313           comedian       1          4   \n",
       "61302       psychologist       1         22   \n",
       "60333          architect       1          1   \n",
       "...                  ...     ...        ...   \n",
       "5098                  DJ       1          8   \n",
       "11063            Surgeon       1         25   \n",
       "49107       psychologist       0         22   \n",
       "8028           Dietitian       0          7   \n",
       "45876          Architect       1          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  label  \\\n",
       "31289    male_job           1     13   \n",
       "61990    male_job           1     11   \n",
       "29313    male_job           1      2   \n",
       "61302  female_job           0      8   \n",
       "60333    male_job           1     13   \n",
       "...           ...         ...    ...   \n",
       "5098     male_job           1      7   \n",
       "11063    male_job           1      4   \n",
       "49107  female_job           0      8   \n",
       "8028   female_job           0      1   \n",
       "45876    male_job           1     13   \n",
       "\n",
       "                                      tokenized_scrubbed  \n",
       "31289  [_, focuses, on, cloud, security, ,, identity,...  \n",
       "61990  [_, is, the, creator, of, Statoshi, ,, a, fork...  \n",
       "29313  [_, children, 's, books, include, ``, Pouch, P...  \n",
       "61302  [_, also, has, a, therapy, practice, ,, throug...  \n",
       "60333  [The, exhibition, explores, concrete, construc...  \n",
       "...                                                  ...  \n",
       "5098   [_, ’, s, toured, the, UK, ,, Europe, and, Can...  \n",
       "11063  [Dr., _, graduated, from, Andhra, Medical, Col...  \n",
       "49107  [_, has, a, longstanding, interest, in, youth,...  \n",
       "8028   [_, provides, one-on-one, dietary, counseling,...  \n",
       "45876  [_, has, over, fourteen, years, of, experience...  \n",
       "\n",
       "[21499 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['tokenized_scrubbed'] = df.apply(lambda row: nltk.word_tokenize(row['scrubbed']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = male_names_list + female_names_list\n",
    "# all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countrywoman',\n",
       " 'sororal',\n",
       " 'witches',\n",
       " 'maidservant',\n",
       " 'mothers',\n",
       " 'diva',\n",
       " 'actress',\n",
       " 'spinster',\n",
       " 'mama',\n",
       " 'duchesses',\n",
       " 'barwoman',\n",
       " 'countrywomen',\n",
       " 'dowry',\n",
       " 'hostesses',\n",
       " 'airwomen',\n",
       " 'menopause',\n",
       " 'clitoris',\n",
       " 'princess',\n",
       " 'governesses',\n",
       " 'abbess',\n",
       " 'women',\n",
       " 'widow',\n",
       " 'ladies',\n",
       " 'sorceresses',\n",
       " 'madam',\n",
       " 'brides',\n",
       " 'baroness',\n",
       " 'housewives',\n",
       " 'godesses',\n",
       " 'niece',\n",
       " 'widows',\n",
       " 'lady',\n",
       " 'sister',\n",
       " 'brides',\n",
       " 'nun',\n",
       " 'adultresses',\n",
       " 'obstetrics',\n",
       " 'bellgirls',\n",
       " 'her',\n",
       " 'marchioness',\n",
       " 'princesses',\n",
       " 'empresses',\n",
       " 'mare',\n",
       " 'chairwoman',\n",
       " 'convent',\n",
       " 'priestesses',\n",
       " 'girlhood',\n",
       " 'ladies',\n",
       " 'queen',\n",
       " 'gals',\n",
       " 'mommies',\n",
       " 'maid',\n",
       " 'female_ejaculation',\n",
       " 'spokeswoman',\n",
       " 'seamstress',\n",
       " 'cowgirls',\n",
       " 'chick',\n",
       " 'spinsters',\n",
       " 'hair_salon',\n",
       " 'empress',\n",
       " 'mommy',\n",
       " 'feminism',\n",
       " 'gals',\n",
       " 'enchantress',\n",
       " 'gal',\n",
       " 'motherhood',\n",
       " 'estrogen',\n",
       " 'camerawomen',\n",
       " 'godmother',\n",
       " 'strongwoman',\n",
       " 'goddess',\n",
       " 'matriarch',\n",
       " 'aunt',\n",
       " 'chairwomen',\n",
       " \"ma'am\",\n",
       " 'sisterhood',\n",
       " 'hostess',\n",
       " 'estradiol',\n",
       " 'wife',\n",
       " 'mom',\n",
       " 'stewardess',\n",
       " 'females',\n",
       " 'viagra',\n",
       " 'spokeswomen',\n",
       " 'ma',\n",
       " 'belle',\n",
       " 'minx',\n",
       " 'maiden',\n",
       " 'witch',\n",
       " 'miss',\n",
       " 'nieces',\n",
       " 'mothered',\n",
       " 'cow',\n",
       " 'belles',\n",
       " 'councilwomen',\n",
       " 'landladies',\n",
       " 'granddaughter',\n",
       " 'fiancees',\n",
       " 'stepmothers',\n",
       " 'horsewomen',\n",
       " 'grandmothers',\n",
       " 'adultress',\n",
       " 'schoolgirl',\n",
       " 'hen',\n",
       " 'granddaughters',\n",
       " 'bachelorette',\n",
       " 'camerawoman',\n",
       " 'moms',\n",
       " 'her',\n",
       " 'mistress',\n",
       " 'lass',\n",
       " 'policewoman',\n",
       " 'nun',\n",
       " 'actresses',\n",
       " 'saleswomen',\n",
       " 'girlfriend',\n",
       " 'councilwoman',\n",
       " 'lady',\n",
       " 'stateswoman',\n",
       " 'maternal',\n",
       " 'lass',\n",
       " 'landlady',\n",
       " 'sistren',\n",
       " 'ladies',\n",
       " 'wenches',\n",
       " 'sorority',\n",
       " 'bellgirl',\n",
       " 'duchess',\n",
       " 'ballerina',\n",
       " 'chicks',\n",
       " 'fiancee',\n",
       " 'fillies',\n",
       " 'wives',\n",
       " 'suitress',\n",
       " 'maternity',\n",
       " 'she',\n",
       " 'businesswoman',\n",
       " 'masseuses',\n",
       " 'heroine',\n",
       " 'doe',\n",
       " 'busgirls',\n",
       " 'girlfriends',\n",
       " 'queens',\n",
       " 'sisters',\n",
       " 'mistresses',\n",
       " 'stepmother',\n",
       " 'brides',\n",
       " 'daughter',\n",
       " 'minxes',\n",
       " 'cowgirl',\n",
       " 'lady',\n",
       " 'daughters',\n",
       " 'mezzo',\n",
       " 'saleswoman',\n",
       " 'mistress',\n",
       " 'hostess',\n",
       " 'nuns',\n",
       " 'maids',\n",
       " 'mrs.',\n",
       " 'headmistresses',\n",
       " 'lasses',\n",
       " 'congresswoman',\n",
       " 'airwoman',\n",
       " 'housewife',\n",
       " 'priestess',\n",
       " 'barwomen',\n",
       " 'barnoesses',\n",
       " 'abbesses',\n",
       " 'handywoman',\n",
       " 'toque',\n",
       " 'sororities',\n",
       " 'stewardesses',\n",
       " 'filly',\n",
       " 'czarina',\n",
       " 'stepdaughters',\n",
       " 'herself',\n",
       " 'girls',\n",
       " 'lionesses',\n",
       " 'lady',\n",
       " 'vagina',\n",
       " 'hers',\n",
       " 'masseuse',\n",
       " 'cows',\n",
       " 'aunts',\n",
       " 'wench',\n",
       " 'toques',\n",
       " 'wife',\n",
       " 'lioness',\n",
       " 'sorceress',\n",
       " 'effeminate',\n",
       " 'mother',\n",
       " 'lesbians',\n",
       " 'female',\n",
       " 'waitresses',\n",
       " 'ovum',\n",
       " 'skene_gland',\n",
       " 'stepdaughter',\n",
       " 'womb',\n",
       " 'businesswomen',\n",
       " 'heiress',\n",
       " 'waitress',\n",
       " 'headmistress',\n",
       " 'woman',\n",
       " 'governess',\n",
       " 'godess',\n",
       " 'bride',\n",
       " 'grandma',\n",
       " 'bride',\n",
       " 'gal',\n",
       " 'lesbian',\n",
       " 'ladies',\n",
       " 'girl',\n",
       " 'grandmother',\n",
       " 'mare',\n",
       " 'maternity',\n",
       " 'hens',\n",
       " 'uterus',\n",
       " 'nuns',\n",
       " 'maidservants',\n",
       " \"seamstress'\",\n",
       " 'busgirl',\n",
       " 'heroines',\n",
       " 'countryman',\n",
       " 'fraternal',\n",
       " 'wizards',\n",
       " 'manservant',\n",
       " 'fathers',\n",
       " 'divo',\n",
       " 'actor',\n",
       " 'bachelor',\n",
       " 'papa',\n",
       " 'dukes',\n",
       " 'barman',\n",
       " 'countrymen',\n",
       " 'brideprice',\n",
       " 'hosts',\n",
       " 'airmen',\n",
       " 'andropause',\n",
       " 'penis',\n",
       " 'prince',\n",
       " 'governors',\n",
       " 'abbot',\n",
       " 'men',\n",
       " 'widower',\n",
       " 'gentlemen',\n",
       " 'sorcerers',\n",
       " 'sir',\n",
       " 'bridegrooms',\n",
       " 'baron',\n",
       " 'househusbands',\n",
       " 'gods',\n",
       " 'nephew',\n",
       " 'widowers',\n",
       " 'lord',\n",
       " 'brother',\n",
       " 'grooms',\n",
       " 'priest',\n",
       " 'adultors',\n",
       " 'andrology',\n",
       " 'bellboys',\n",
       " 'his',\n",
       " 'marquis',\n",
       " 'princes',\n",
       " 'emperors',\n",
       " 'stallion',\n",
       " 'chairman',\n",
       " 'monastery',\n",
       " 'priests',\n",
       " 'boyhood',\n",
       " 'fellas',\n",
       " 'king',\n",
       " 'dudes',\n",
       " 'daddies',\n",
       " 'manservant',\n",
       " 'semen',\n",
       " 'spokesman',\n",
       " 'tailor',\n",
       " 'cowboys',\n",
       " 'dude',\n",
       " 'bachelors',\n",
       " 'barbershop',\n",
       " 'emperor',\n",
       " 'daddy',\n",
       " 'masculism',\n",
       " 'guys',\n",
       " 'enchanter',\n",
       " 'guy',\n",
       " 'fatherhood',\n",
       " 'androgen',\n",
       " 'cameramen',\n",
       " 'godfather',\n",
       " 'strongman',\n",
       " 'god',\n",
       " 'patriarch',\n",
       " 'uncle',\n",
       " 'chairmen',\n",
       " 'sir',\n",
       " 'brotherhood',\n",
       " 'host',\n",
       " 'testosterone',\n",
       " 'husband',\n",
       " 'dad',\n",
       " 'steward',\n",
       " 'males',\n",
       " 'cialis',\n",
       " 'spokesmen',\n",
       " 'pa',\n",
       " 'beau',\n",
       " 'stud',\n",
       " 'bachelor',\n",
       " 'wizard',\n",
       " 'sir',\n",
       " 'nephews',\n",
       " 'fathered',\n",
       " 'bull',\n",
       " 'beaus',\n",
       " 'councilmen',\n",
       " 'landlords',\n",
       " 'grandson',\n",
       " 'fiances',\n",
       " 'stepfathers',\n",
       " 'horsemen',\n",
       " 'grandfathers',\n",
       " 'adultor',\n",
       " 'schoolboy',\n",
       " 'rooster',\n",
       " 'grandsons',\n",
       " 'bachelor',\n",
       " 'cameraman',\n",
       " 'dads',\n",
       " 'him',\n",
       " 'master',\n",
       " 'lad',\n",
       " 'policeman',\n",
       " 'monk',\n",
       " 'actors',\n",
       " 'salesmen',\n",
       " 'boyfriend',\n",
       " 'councilman',\n",
       " 'fella',\n",
       " 'statesman',\n",
       " 'paternal',\n",
       " 'chap',\n",
       " 'landlord',\n",
       " 'brethren',\n",
       " 'lords',\n",
       " 'blokes',\n",
       " 'fraternity',\n",
       " 'bellboy',\n",
       " 'duke',\n",
       " 'ballet_dancer',\n",
       " 'dudes',\n",
       " 'fiance',\n",
       " 'colts',\n",
       " 'husbands',\n",
       " 'suitor',\n",
       " 'paternity',\n",
       " 'he',\n",
       " 'businessman',\n",
       " 'masseurs',\n",
       " 'hero',\n",
       " 'deer',\n",
       " 'busboys',\n",
       " 'boyfriends',\n",
       " 'kings',\n",
       " 'brothers',\n",
       " 'masters',\n",
       " 'stepfather',\n",
       " 'grooms',\n",
       " 'son',\n",
       " 'studs',\n",
       " 'cowboy',\n",
       " 'mentleman',\n",
       " 'sons',\n",
       " 'baritone',\n",
       " 'salesman',\n",
       " 'paramour',\n",
       " 'male_host',\n",
       " 'monks',\n",
       " 'menservants',\n",
       " 'mr.',\n",
       " 'headmasters',\n",
       " 'lads',\n",
       " 'congressman',\n",
       " 'airman',\n",
       " 'househusband',\n",
       " 'priest',\n",
       " 'barmen',\n",
       " 'barons',\n",
       " 'abbots',\n",
       " 'handyman',\n",
       " 'beard',\n",
       " 'fraternities',\n",
       " 'stewards',\n",
       " 'colt',\n",
       " 'czar',\n",
       " 'stepsons',\n",
       " 'himself',\n",
       " 'boys',\n",
       " 'lions',\n",
       " 'gentleman',\n",
       " 'penis',\n",
       " 'his',\n",
       " 'masseur',\n",
       " 'bulls',\n",
       " 'uncles',\n",
       " 'bloke',\n",
       " 'beards',\n",
       " 'hubby',\n",
       " 'lion',\n",
       " 'sorcerer',\n",
       " 'macho',\n",
       " 'father',\n",
       " 'gays',\n",
       " 'male',\n",
       " 'waiters',\n",
       " 'sperm',\n",
       " 'prostate',\n",
       " 'stepson',\n",
       " 'prostatic_utricle',\n",
       " 'businessmen',\n",
       " 'heir',\n",
       " 'waiter',\n",
       " 'headmaster',\n",
       " 'man',\n",
       " 'governor',\n",
       " 'god',\n",
       " 'bridegroom',\n",
       " 'grandpa',\n",
       " 'groom',\n",
       " 'dude',\n",
       " 'gay',\n",
       " 'gents',\n",
       " 'boy',\n",
       " 'grandfather',\n",
       " 'gelding',\n",
       " 'paternity',\n",
       " 'roosters',\n",
       " 'prostatic_utricle',\n",
       " 'priests',\n",
       " 'manservants',\n",
       " 'stailor',\n",
       " 'busboy',\n",
       " 'heros',\n",
       " '']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_all_attribute_list = [i.lower() for i in all_attribute_list]\n",
    "all_attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tokens(wordlist):\n",
    "    lower_wordlist = [i.lower() for i in wordlist]\n",
    "    for i in range(len(wordlist)):\n",
    "        if lower_wordlist[i] in all_attribute_list:\n",
    "            wordlist[i] = \"_\"\n",
    "        if wordlist[i] in all_names:\n",
    "            wordlist[i] = \"_\"\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_scrubbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, focuses, on, cloud, security, ,, identity,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[_, is, the, creator, of, Statoshi, ,, a, fork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[_, children, 's, books, include, ``, Pouch, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, also, has, a, therapy, practice, ,, throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, exhibition, explores, concrete, construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[_, ’, s, toured, the, UK, ,, Europe, and, _, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[Dr., _, graduated, from, Andhra, Medical, Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, has, a, longstanding, interest, in, youth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[_, provides, one-on-one, dietary, counseling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, has, over, fourteen, years, of, experience...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title  gender  old_label  \\\n",
       "31289          architect       1          1   \n",
       "61990  software engineer       1         24   \n",
       "29313           comedian       1          4   \n",
       "61302       psychologist       1         22   \n",
       "60333          architect       1          1   \n",
       "...                  ...     ...        ...   \n",
       "5098                  DJ       1          8   \n",
       "11063            Surgeon       1         25   \n",
       "49107       psychologist       0         22   \n",
       "8028           Dietitian       0          7   \n",
       "45876          Architect       1          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  label  \\\n",
       "31289    male_job           1     13   \n",
       "61990    male_job           1     11   \n",
       "29313    male_job           1      2   \n",
       "61302  female_job           0      8   \n",
       "60333    male_job           1     13   \n",
       "...           ...         ...    ...   \n",
       "5098     male_job           1      7   \n",
       "11063    male_job           1      4   \n",
       "49107  female_job           0      8   \n",
       "8028   female_job           0      1   \n",
       "45876    male_job           1     13   \n",
       "\n",
       "                                      tokenized_scrubbed  \n",
       "31289  [_, focuses, on, cloud, security, ,, identity,...  \n",
       "61990  [_, is, the, creator, of, Statoshi, ,, a, fork...  \n",
       "29313  [_, children, 's, books, include, ``, Pouch, P...  \n",
       "61302  [_, also, has, a, therapy, practice, ,, throug...  \n",
       "60333  [The, exhibition, explores, concrete, construc...  \n",
       "...                                                  ...  \n",
       "5098   [_, ’, s, toured, the, UK, ,, Europe, and, _, ...  \n",
       "11063  [Dr., _, graduated, from, Andhra, Medical, Col...  \n",
       "49107  [_, has, a, longstanding, interest, in, youth,...  \n",
       "8028   [_, provides, one-on-one, dietary, counseling,...  \n",
       "45876  [_, has, over, fourteen, years, of, experience...  \n",
       "\n",
       "[21499 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_scrubbed'] = df.apply(lambda row: replace_tokens(row['tokenized_scrubbed']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>old_label</th>\n",
       "      <th>scrubbed</th>\n",
       "      <th>bio</th>\n",
       "      <th>flipped_bio</th>\n",
       "      <th>swapped</th>\n",
       "      <th>prof</th>\n",
       "      <th>job_cat</th>\n",
       "      <th>job_cat_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_scrubbed</th>\n",
       "      <th>scrubbed2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31289</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ focuses on cloud security, identity and acce...</td>\n",
       "      <td>He focuses on cloud security, identity and acc...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>She focuses on cloud security, identity and ac...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, focuses, on, cloud, security, ,, identity,...</td>\n",
       "      <td>_ focuses on cloud security , identity and acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61990</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>_ is the creator of Statoshi, a fork of Bitcoi...</td>\n",
       "      <td>He is the creator of Statoshi, a fork of Bitco...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>She is the creator of Statoshi, a fork of Bitc...</td>\n",
       "      <td>software_engineer</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[_, is, the, creator, of, Statoshi, ,, a, fork...</td>\n",
       "      <td>_ is the creator of Statoshi , a fork of Bitco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>comedian</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>_ children's books include \"Pouch Potato, Char...</td>\n",
       "      <td>His children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Sh...</td>\n",
       "      <td>Her children's books include \"Pouch Potato, Ch...</td>\n",
       "      <td>comedian</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[_, children, 's, books, include, ``, Pouch, P...</td>\n",
       "      <td>_ children 's books include `` Pouch Potato , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>_ also has a therapy practice, through which _...</td>\n",
       "      <td>He also has a therapy practice, through which ...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>She also has a therapy practice, through which...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, also, has, a, therapy, practice, ,, throug...</td>\n",
       "      <td>_ also has a therapy practice , through which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60333</th>\n",
       "      <td>architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, exhibition, explores, concrete, construc...</td>\n",
       "      <td>The exhibition explores concrete construction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>DJ</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>_’s toured the UK, Europe and Canada as well a...</td>\n",
       "      <td>He’s toured the UK, Europe and Canada as well ...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>She’s toured the UK, Europe and Canada as well...</td>\n",
       "      <td>dj</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[_, ’, s, toured, the, UK, ,, Europe, and, _, ...</td>\n",
       "      <td>_ ’ s toured the UK , Europe and _ as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College, A...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>Dr. Chacko graduated from Andhra Medical Colle...</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[Dr., _, graduated, from, Andhra, Medical, Col...</td>\n",
       "      <td>Dr. _ graduated from Andhra Medical College , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49107</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "      <td>She has a longstanding interest in youth menta...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>He has a longstanding interest in youth mental...</td>\n",
       "      <td>psychologist</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[_, has, a, longstanding, interest, in, youth,...</td>\n",
       "      <td>_ has a longstanding interest in youth mental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>Dietitian</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "      <td>She provides one-on-one dietary counseling on ...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>He provides one-on-one dietary counseling on w...</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>female_job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[_, provides, one-on-one, dietary, counseling,...</td>\n",
       "      <td>_ provides one-on-one dietary counseling on we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>Architect</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "      <td>He has over fourteen years of experience devel...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>She has over fourteen years of experience deve...</td>\n",
       "      <td>architect</td>\n",
       "      <td>male_job</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, has, over, fourteen, years, of, experience...</td>\n",
       "      <td>_ has over fourteen years of experience develo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21499 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raw_title  gender  old_label  \\\n",
       "31289          architect       1          1   \n",
       "61990  software engineer       1         24   \n",
       "29313           comedian       1          4   \n",
       "61302       psychologist       1         22   \n",
       "60333          architect       1          1   \n",
       "...                  ...     ...        ...   \n",
       "5098                  DJ       1          8   \n",
       "11063            Surgeon       1         25   \n",
       "49107       psychologist       0         22   \n",
       "8028           Dietitian       0          7   \n",
       "45876          Architect       1          1   \n",
       "\n",
       "                                                scrubbed  \\\n",
       "31289  _ focuses on cloud security, identity and acce...   \n",
       "61990  _ is the creator of Statoshi, a fork of Bitcoi...   \n",
       "29313  _ children's books include \"Pouch Potato, Char...   \n",
       "61302  _ also has a therapy practice, through which _...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   _’s toured the UK, Europe and Canada as well a...   \n",
       "11063  Dr. _ graduated from Andhra Medical College, A...   \n",
       "49107  _ has a longstanding interest in youth mental ...   \n",
       "8028   _ provides one-on-one dietary counseling on we...   \n",
       "45876  _ has over fourteen years of experience develo...   \n",
       "\n",
       "                                                     bio  \\\n",
       "31289  He focuses on cloud security, identity and acc...   \n",
       "61990  He is the creator of Statoshi, a fork of Bitco...   \n",
       "29313  His children's books include \"Pouch Potato, Ch...   \n",
       "61302  He also has a therapy practice, through which ...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   He’s toured the UK, Europe and Canada as well ...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  She has a longstanding interest in youth menta...   \n",
       "8028   She provides one-on-one dietary counseling on ...   \n",
       "45876  He has over fourteen years of experience devel...   \n",
       "\n",
       "                                             flipped_bio  \\\n",
       "31289  She focuses on cloud security, identity and ac...   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...   \n",
       "29313  Her children's books include \"Pouch Potato, Sh...   \n",
       "61302  She also has a therapy practice, through which...   \n",
       "60333  The exhibition explores concrete construction ...   \n",
       "...                                                  ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...   \n",
       "49107  He has a longstanding interest in youth mental...   \n",
       "8028   He provides one-on-one dietary counseling on w...   \n",
       "45876  She has over fourteen years of experience deve...   \n",
       "\n",
       "                                                 swapped               prof  \\\n",
       "31289  She focuses on cloud security, identity and ac...          architect   \n",
       "61990  She is the creator of Statoshi, a fork of Bitc...  software_engineer   \n",
       "29313  Her children's books include \"Pouch Potato, Ch...           comedian   \n",
       "61302  She also has a therapy practice, through which...       psychologist   \n",
       "60333  The exhibition explores concrete construction ...          architect   \n",
       "...                                                  ...                ...   \n",
       "5098   She’s toured the UK, Europe and Canada as well...                 dj   \n",
       "11063  Dr. Chacko graduated from Andhra Medical Colle...            surgeon   \n",
       "49107  He has a longstanding interest in youth mental...       psychologist   \n",
       "8028   He provides one-on-one dietary counseling on w...          dietitian   \n",
       "45876  She has over fourteen years of experience deve...          architect   \n",
       "\n",
       "          job_cat  job_cat_id  label  \\\n",
       "31289    male_job           1     13   \n",
       "61990    male_job           1     11   \n",
       "29313    male_job           1      2   \n",
       "61302  female_job           0      8   \n",
       "60333    male_job           1     13   \n",
       "...           ...         ...    ...   \n",
       "5098     male_job           1      7   \n",
       "11063    male_job           1      4   \n",
       "49107  female_job           0      8   \n",
       "8028   female_job           0      1   \n",
       "45876    male_job           1     13   \n",
       "\n",
       "                                      tokenized_scrubbed  \\\n",
       "31289  [_, focuses, on, cloud, security, ,, identity,...   \n",
       "61990  [_, is, the, creator, of, Statoshi, ,, a, fork...   \n",
       "29313  [_, children, 's, books, include, ``, Pouch, P...   \n",
       "61302  [_, also, has, a, therapy, practice, ,, throug...   \n",
       "60333  [The, exhibition, explores, concrete, construc...   \n",
       "...                                                  ...   \n",
       "5098   [_, ’, s, toured, the, UK, ,, Europe, and, _, ...   \n",
       "11063  [Dr., _, graduated, from, Andhra, Medical, Col...   \n",
       "49107  [_, has, a, longstanding, interest, in, youth,...   \n",
       "8028   [_, provides, one-on-one, dietary, counseling,...   \n",
       "45876  [_, has, over, fourteen, years, of, experience...   \n",
       "\n",
       "                                               scrubbed2  \n",
       "31289  _ focuses on cloud security , identity and acc...  \n",
       "61990  _ is the creator of Statoshi , a fork of Bitco...  \n",
       "29313  _ children 's books include `` Pouch Potato , ...  \n",
       "61302  _ also has a therapy practice , through which ...  \n",
       "60333  The exhibition explores concrete construction ...  \n",
       "...                                                  ...  \n",
       "5098   _ ’ s toured the UK , Europe and _ as well as ...  \n",
       "11063  Dr. _ graduated from Andhra Medical College , ...  \n",
       "49107  _ has a longstanding interest in youth mental ...  \n",
       "8028   _ provides one-on-one dietary counseling on we...  \n",
       "45876  _ has over fourteen years of experience develo...  \n",
       "\n",
       "[21499 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scrubbed2'] = df.apply(lambda row: \" \".join(row['tokenized_scrubbed']), axis=1)\n",
    "# joined = \" \".joi(list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_df = np.array_split(df, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################### tokenize dataset ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b574d52793147cf8ff06cad810f0ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/742k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f2534873814de599d231dde2c81c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, AdamW, BertConfig, BertForPreTraining\n",
    "\n",
    "from transformers import AlbertTokenizer\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2', do_lower_case=True)\n",
    "seq_len = 100\n",
    "vocab_length = 30522\n",
    "def tokenize(data, y, g):\n",
    "    \n",
    "\n",
    "    # Load the BERT tokenizer.\n",
    "    print('Loading BERT tokenizer...')\n",
    "\n",
    "    # Training Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for k, sent in enumerate(data):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            str(sent),                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = seq_len,           # Pad & truncate all sentences.\n",
    "                            truncation=True,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "        \n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "        \n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    class_labels = torch.tensor(y)\n",
    "    gender_labels = torch.tensor(g)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#     print(y)\n",
    "#     print(y_onehot)\n",
    "\n",
    "    return input_ids, class_labels, attention_masks, gender_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################### save dataset ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He focuses on cloud security, identity and access management, mobility security, and security for Microsoft platforms and solutions. Jan is based in Belgium.\n",
      "Token IDs: tensor([    2,    24,  7155,    27,  4005,  1221,    15,  3270,    17,  1381,\n",
      "         1097,    15, 14806,  1221,    15,    17,  1221,    26,  7099,  6843,\n",
      "           17,  6776,     9,  2262,    25,   432,    19,  4692,     9,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(13)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_0\n",
      "Loading BERT tokenizer...\n",
      "Original:  Born in England he now resides in Berlin. Educated at Dartington College of Arts he graduated with a BA and MA in contemporary music composition and arts theory and continues his work in his solo projects and as a member of the krautrock band Curious Egg.\n",
      "Token IDs: tensor([    2,   386,    19,   648,    24,   130, 12631,    19,  2296,     9,\n",
      "         3977,    35, 25680,   444,   314,    16,  1008,    24,  2158,    29,\n",
      "           21,  2683,    17,  1216,    19,  2152,   232,  4046,    17,  1008,\n",
      "         1639,    17,  2622,    33,   170,    19,    33,  2046,  2314,    17,\n",
      "           28,    21,   322,    16,    14,  5179,  1982,  4651,   323,  7686,\n",
      "         6387,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_1\n",
      "Loading BERT tokenizer...\n",
      "Original:  In his works, references to the musical past are often embedded within folk materials of his native country, Argentina. Disks and scores with his music are available on the independent label Contrapunctus, on FJH Publications, Editions Billaudot, and on Ricordi.\n",
      "Token IDs: tensor([    2,    19,    33,   693,    15,  7231,    20,    14,  1457,   640,\n",
      "           50,   478, 12138,   363,  3267,  2895,    16,    33,  1275,   475,\n",
      "           15,  4491,     9,  8582,    18,    17,  7369,    29,    33,   232,\n",
      "           50,   904,    27,    14,  1124,  1899, 11805, 17359,   267,    15,\n",
      "           27,   398,   728,   252,  4411,    15,  6179,  1071,  1346, 12527,\n",
      "           15,    17,    27,  5738,   897,    49,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_2\n",
      "Loading BERT tokenizer...\n",
      "Original:  She has been with the ITEE eResearch group since 2006 as a Web Developer / Senior Research Assistant working on the HarvANA project as well as annotation tools for 3D models of museum artefacts and protein crystallography structures.\n",
      "Token IDs: tensor([    2,    39,    63,    74,    29,    14,    32,  2851,    13,    62,\n",
      "        26619,   214,   179,   592,    28,    21,  2741, 10058,    13,   118,\n",
      "         1101,   527,  1482,   638,    27,    14,  2431, 18026,   669,    28,\n",
      "          134,    28,    40,  1270,   857,  4672,    26,   203,    43,  2761,\n",
      "           16,   774, 27284,    17,  4008,  4282,   255, 10112,  3815,     9,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_3\n",
      "Loading BERT tokenizer...\n",
      "Original:  She began blogging in 2012, with her posts evolving from an initial empty nest focus (“NestAche” as Dr. Margaret termed it) to posts describing her work in mental health. Her writing can be found on her own website http://drmargaretrutherford.com, as well as The Huffington Post, Midlife Boulevard, Boomeon, BetterAfter50, WeWantMore and now at The Good Men Project.\n",
      "Token IDs: tensor([    2,    39,   260,   334, 13919,    19,   563,    15,    29,    36,\n",
      "         9868, 22363,    37,    40,  2104,  2424,  5618,  1776,    13,     5,\n",
      "            1,  2696,    38,  9616,     1,    28,   744,     9,  4072, 13776,\n",
      "           32,     6,    20,  9868,  7153,    36,   170,    19,  3584,   853,\n",
      "            9,    36,  1174,    92,    44,   216,    27,    36,   258,  2271,\n",
      "         7775,  6903,  3807,  1615,  1136,    99, 23266,   106,  1426,     9,\n",
      "          960,    15,    28,   134,    28,    14, 26910,   678,    15,   907,\n",
      "         4102,  7717,    15,  6403, 11572,    15,   574,  5162,  2290,    15,\n",
      "           95, 14876,  1995,    17,   130,    35,    14,   254,   304,   669,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_4\n",
      "Loading BERT tokenizer...\n",
      "Original:  She graduated with honors in 1999. Having more than 19 years of diverse experiences, especially in CLINICAL PSYCHOLOGIST, Dr. Mary Elizabeth Hickcox affiliates with no hospital, and cooperates with other doctors and specialists without joining any medical groups. Call Dr. Mary Elizabeth Hickcox on phone number (330) 650-5338 for more information and advice or to book an appointment.\n",
      "Token IDs: tensor([    2,    39,  2158,    29,  7811,    19,  1247,     9,   452,    91,\n",
      "          119,   732,   122,    16,  6951,  5513,    15,  1118,    19,  5611,\n",
      "        13729,    15,   744,     9,  1044,  2076,    13, 15477,   716,   396,\n",
      "         6772,    18,    29,    90,   980,    15,    17, 15180,    18,    29,\n",
      "           89,  6995,    17, 19546,   366,  3765,   186,  1088,  1170,     9,\n",
      "          645,   744,     9,  1044,  2076,    13, 15477,   716,   396,    27,\n",
      "         1132,   234,    13,     5, 13509,     6,    13, 13798,     8,  4022,\n",
      "         3665,    26,    91,   676,    17,  4978,    54,    20,   360,    40,\n",
      "         4905,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_5\n",
      "Loading BERT tokenizer...\n",
      "Original:  Having been a therapist for forty years, she has observed how people approach life dilemmas and the diverse voices they use to express their unique experiences. Playwriting as an...\n",
      "Token IDs: tensor([    2,   452,    74,    21, 18000,    26,  4671,   122,    15,    39,\n",
      "           63,  3634,   184,   148,  2141,   201, 23314,    18,    17,    14,\n",
      "         6951,  5333,    59,   275,    20,  2999,    66,  2619,  5513,     9,\n",
      "          418, 12646,    28,    40,     9,     9,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_6\n",
      "Loading BERT tokenizer...\n",
      "Original:  At same time, He is also doing study and research in Software Management at Carnegie Mellon University. Prior to Google, he worked at Cisco Systems, Nortel Networks, Sun Microsystems, AT&T Bell Lab. He has 15+ years experiences in system and business software development, network equipment development, and project and product managements. He also has 8+ years experiences in teaching in Computer Science, Networking and Internet Application Developments.\n",
      "Token IDs: tensor([    2,    35,   205,    85,    15,    24,    25,    67,   845,   949,\n",
      "           17,   527,    19,  2306,  1097,    35, 12234, 23771,   155,     9,\n",
      "         1313,    20,  8144,    15,    24,   577,    35, 28184,  1242,    15,\n",
      "         2127,  3454,  5540,    15,   939,  2899, 10724,    18,    15,    35,\n",
      "         1569,    38,  1988,  4343,     9,    24,    63,   357,  2430,   122,\n",
      "         5513,    19,   329,    17,   508,  2306,   522,    15,   982,  2181,\n",
      "          522,    15,    17,   669,    17,  2374,  1097,    18,     9,    24,\n",
      "           67,    63,   469,  2430,   122,  5513,    19,  2540,    19,  1428,\n",
      "          762,    15, 16230,    17,  2620,  3010, 11884,     9,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_7\n",
      "Loading BERT tokenizer...\n",
      "Original:  He studies what's called targeted violence. That includes mass shootings. And he has little doubt that what happened here in Las Vegas will eventually inspire copycats.\n",
      "Token IDs: tensor([    2,    24,  1011,    98,    22,    18,   227,  9536,  3300,     9,\n",
      "           30,  1103,  1619,  3511,    18,     9,    17,    24,    63,   265,\n",
      "         3063,    30,    98,  1190,   235,    19,  3695,  6432,   129,   878,\n",
      "        19146,  4344, 14626,     9,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "bio_classification_train_dataset_8\n",
      "Loading BERT tokenizer...\n",
      "Original:  Hamasaki Rio is a lovely Asian model who is well known ... Model: Natsuki Iijima This hot Asian teen has a nice set ... : Mao Mao is a cute Asian teen who hangs around the ... but she is kind of shy and backs out last minute ...\n",
      "Token IDs: tensor([    2, 21594,  4713,  4017,    25,    21,  8601,  2282,  1061,    72,\n",
      "           25,   134,   167,    13,     9,     9,     9,  1061,    45,  1775,\n",
      "        21898,   595, 17316,    48,  1047,  2282,  9503,    63,    21,  2210,\n",
      "          309,    13,     9,     9,     9,    13,    45, 15107, 15107,    25,\n",
      "           21, 10901,  2282,  9503,    72,  4546,    18,   140,    14,    13,\n",
      "            9,     9,     9,    47,    39,    25,   825,    16,  8327,    17,\n",
      "           97,    18,    70,   236,  2038,    13,     9,     9,     9,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(9)\n",
      "2,149 training samples\n",
      "bio_classification_train_dataset_9\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(k_fold_df):\n",
    "    sentences = i.bio.values\n",
    "    gender = i.gender.values\n",
    "    labels = i.label.values\n",
    "    train_input_ids, train_class_labels, train_attention_masks, train_gender_labels = tokenize(sentences, labels, gender)\n",
    "    # test_input_ids, test_class_labels, test_attention_masks, test_gender_labels = tokenize(X_test, y_test, gen_test)\n",
    "#     val_input_ids, val_class_labels, val_attention_masks, val_gender_labels = tokenize(X_val, y_val, gen_val)\n",
    "\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', train_input_ids[0])\n",
    "    print('Token IDs:', train_class_labels[0])\n",
    "    \n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    train_dataset = TensorDataset(train_input_ids, train_class_labels, train_attention_masks, train_gender_labels)\n",
    "\n",
    "    print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "\n",
    "    name = \"bio_classification_train_dataset_\" + str(ind)\n",
    "    torch.save(train_dataset, 'unbalanced_datasets/'+name+'.pt')\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  _ focuses on cloud security , identity and access management , mobility security , and security for Microsoft platforms and solutions . _ is based in Belgium .\n",
      "Token IDs: tensor([    2,    13,     1,  7155,    27,  4005,  1221,    13,    15,  3270,\n",
      "           17,  1381,  1097,    13,    15, 14806,  1221,    13,    15,    17,\n",
      "         1221,    26,  7099,  6843,    17,  6776,    13,     9,    13,     1,\n",
      "           25,   432,    19,  4692,    13,     9,     3,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(13)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_0\n",
      "Loading BERT tokenizer...\n",
      "Original:  Born in England _ now resides in Berlin . Educated at Dartington College of Arts _ graduated with a BA and _ in contemporary music composition and arts theory and continues _ work in _ solo projects and as a member of the krautrock band Curious Egg .\n",
      "Token IDs: tensor([    2,   386,    19,   648,    13,     1,   130, 12631,    19,  2296,\n",
      "           13,     9,  3977,    35, 25680,   444,   314,    16,  1008,    13,\n",
      "            1,  2158,    29,    21,  2683,    17,    13,     1,    19,  2152,\n",
      "          232,  4046,    17,  1008,  1639,    17,  2622,    13,     1,   170,\n",
      "           19,    13,     1,  2046,  2314,    17,    28,    21,   322,    16,\n",
      "           14,  5179,  1982,  4651,   323,  7686,  6387,    13,     9,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_1\n",
      "Loading BERT tokenizer...\n",
      "Original:  In _ works , references to the musical past are often embedded within folk materials of _ native country , Argentina . Disks and scores with _ music are available on the independent label Contrapunctus , on FJH Publications , Editions Billaudot , and on Ricordi .\n",
      "Token IDs: tensor([    2,    19,    13,     1,   693,    13,    15,  7231,    20,    14,\n",
      "         1457,   640,    50,   478, 12138,   363,  3267,  2895,    16,    13,\n",
      "            1,  1275,   475,    13,    15,  4491,    13,     9,  8582,    18,\n",
      "           17,  7369,    29,    13,     1,   232,    50,   904,    27,    14,\n",
      "         1124,  1899, 11805, 17359,   267,    13,    15,    27,   398,   728,\n",
      "          252,  4411,    13,    15,  6179,  1071,  1346, 12527,    13,    15,\n",
      "           17,    27,  5738,   897,    49,    13,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_2\n",
      "Loading BERT tokenizer...\n",
      "Original:  _ has been with the ITEE eResearch group since 2006 as a _ Developer / Senior Research Assistant working on the HarvANA project as well as annotation tools for 3D models of museum artefacts and protein crystallography structures .\n",
      "Token IDs: tensor([    2,    13,     1,    63,    74,    29,    14,    32,  2851,    13,\n",
      "           62, 26619,   214,   179,   592,    28,    21,    13,     1, 10058,\n",
      "           13,   118,  1101,   527,  1482,   638,    27,    14,  2431, 18026,\n",
      "          669,    28,   134,    28,    40,  1270,   857,  4672,    26,   203,\n",
      "           43,  2761,    16,   774, 27284,    17,  4008,  4282,   255, 10112,\n",
      "         3815,    13,     9,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_3\n",
      "Loading BERT tokenizer...\n",
      "Original:  _ began blogging in 2012 , with _ posts evolving from an initial empty nest focus ( “ NestAche ” as Dr. _ termed it ) to posts describing _ work in mental health . _ writing can be found on _ own website http : //drmargaretrutherford.com , as well as The Huffington Post , Midlife Boulevard , Boomeon , BetterAfter50 , WeWantMore and now at The Good _ Project .\n",
      "Token IDs: tensor([    2,    13,     1,   260,   334, 13919,    19,   563,    13,    15,\n",
      "           29,    13,     1,  9868, 22363,    37,    40,  2104,  2424,  5618,\n",
      "         1776,    13,     5,    13,     1,  5618,  9616,    13,     1,    28,\n",
      "          744,     9,    13,     1, 13776,    32,    13,     6,    20,  9868,\n",
      "         7153,    13,     1,   170,    19,  3584,   853,    13,     9,    13,\n",
      "            1,  1174,    92,    44,   216,    27,    13,     1,   258,  2271,\n",
      "         7775,    13,    45, 12894,  3807,  1615,  1136,    99, 23266,   106,\n",
      "         1426,     9,   960,    13,    15,    28,   134,    28,    14, 26910,\n",
      "          678,    13,    15,   907,  4102,  7717,    13,    15,  6403, 11572,\n",
      "           13,    15,   574,  5162,  2290,    13,    15,    95, 14876,     3])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_4\n",
      "Loading BERT tokenizer...\n",
      "Original:  _ graduated with honors in 1999 . Having more than 19 years of diverse experiences , especially in CLINICAL PSYCHOLOGIST , Dr. _ _ _ affiliates with no hospital , and cooperates with other doctors and specialists without joining any medical groups . Call Dr. _ _ _ on phone number ( 330 ) 650-5338 for more information and advice or to book an appointment .\n",
      "Token IDs: tensor([    2,    13,     1,  2158,    29,  7811,    19,  1247,    13,     9,\n",
      "          452,    91,   119,   732,   122,    16,  6951,  5513,    13,    15,\n",
      "         1118,    19,  5611, 13729,    13,    15,   744,     9,    13,     1,\n",
      "           13,     1,    13,     1,  6772,    18,    29,    90,   980,    13,\n",
      "           15,    17, 15180,    18,    29,    89,  6995,    17, 19546,   366,\n",
      "         3765,   186,  1088,  1170,    13,     9,   645,   744,     9,    13,\n",
      "            1,    13,     1,    13,     1,    27,  1132,   234,    13,     5,\n",
      "           13, 13509,    13,     6,    13, 13798,     8,  4022,  3665,    26,\n",
      "           91,   676,    17,  4978,    54,    20,   360,    40,  4905,    13,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_5\n",
      "Loading BERT tokenizer...\n",
      "Original:  Having been a therapist for forty years , _ has observed how people approach life dilemmas and the diverse voices they use to express their unique experiences . Playwriting as an ...\n",
      "Token IDs: tensor([    2,   452,    74,    21, 18000,    26,  4671,   122,    13,    15,\n",
      "           13,     1,    63,  3634,   184,   148,  2141,   201, 23314,    18,\n",
      "           17,    14,  6951,  5333,    59,   275,    20,  2999,    66,  2619,\n",
      "         5513,    13,     9,   418, 12646,    28,    40,    13,     9,     9,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_6\n",
      "Loading BERT tokenizer...\n",
      "Original:  At same time , _ is also doing study and research in Software Management at Carnegie Mellon University . Prior to Google , _ worked at Cisco Systems , Nortel Networks , Sun Microsystems , AT & T _ Lab . _ has 15+ years experiences in system and business software development , network equipment development , and project and product managements . _ also has 8+ years experiences in teaching in Computer Science , Networking and Internet Application Developments .\n",
      "Token IDs: tensor([    2,    35,   205,    85,    13,    15,    13,     1,    25,    67,\n",
      "          845,   949,    17,   527,    19,  2306,  1097,    35, 12234, 23771,\n",
      "          155,    13,     9,  1313,    20,  8144,    13,    15,    13,     1,\n",
      "          577,    35, 28184,  1242,    13,    15,  2127,  3454,  5540,    13,\n",
      "           15,   939,  2899, 10724,    18,    13,    15,    35,   279,    13,\n",
      "           38,    13,     1,  4343,    13,     9,    13,     1,    63,   357,\n",
      "         2430,   122,  5513,    19,   329,    17,   508,  2306,   522,    13,\n",
      "           15,   982,  2181,   522,    13,    15,    17,   669,    17,  2374,\n",
      "         1097,    18,    13,     9,    13,     1,    67,    63,   469,  2430,\n",
      "          122,  5513,    19,  2540,    19,  1428,   762,    13,    15,     3])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_7\n",
      "Loading BERT tokenizer...\n",
      "Original:  _ studies what 's called targeted violence . That includes mass shootings . And _ has little doubt that what happened here in Las Vegas will eventually inspire copycats .\n",
      "Token IDs: tensor([    2,    13,     1,  1011,    98,    13,    22,    18,   227,  9536,\n",
      "         3300,    13,     9,    30,  1103,  1619,  3511,    18,    13,     9,\n",
      "           17,    13,     1,    63,   265,  3063,    30,    98,  1190,   235,\n",
      "           19,  3695,  6432,   129,   878, 19146,  4344, 14626,    13,     9,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "scrubbed_classification_train_dataset_8\n",
      "Loading BERT tokenizer...\n",
      "Original:  Hamasaki _ is a lovely Asian model who is well known ... Model : Natsuki Iijima This hot Asian teen has a nice set ... : Mao Mao is a cute Asian teen who hangs around the ... but _ is kind of shy and backs out last minute ...\n",
      "Token IDs: tensor([    2, 21594,  4713,    13,     1,    25,    21,  8601,  2282,  1061,\n",
      "           72,    25,   134,   167,    13,     9,     9,     9,  1061,    13,\n",
      "           45,  1775, 21898,   595, 17316,    48,  1047,  2282,  9503,    63,\n",
      "           21,  2210,   309,    13,     9,     9,     9,    13,    45, 15107,\n",
      "        15107,    25,    21, 10901,  2282,  9503,    72,  4546,    18,   140,\n",
      "           14,    13,     9,     9,     9,    47,    13,     1,    25,   825,\n",
      "           16,  8327,    17,    97,    18,    70,   236,  2038,    13,     9,\n",
      "            9,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(9)\n",
      "2,149 training samples\n",
      "scrubbed_classification_train_dataset_9\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(k_fold_df):\n",
    "    sentences = i.scrubbed2.values\n",
    "    gender = i.gender.values\n",
    "    labels = i.label.values\n",
    "    train_input_ids, train_class_labels, train_attention_masks, train_gender_labels = tokenize(sentences, labels, gender)\n",
    "    # test_input_ids, test_class_labels, test_attention_masks, test_gender_labels = tokenize(X_test, y_test, gen_test)\n",
    "#     val_input_ids, val_class_labels, val_attention_masks, val_gender_labels = tokenize(X_val, y_val, gen_val)\n",
    "\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', train_input_ids[0])\n",
    "    print('Token IDs:', train_class_labels[0])\n",
    "    \n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    train_dataset = TensorDataset(train_input_ids, train_class_labels, train_attention_masks, train_gender_labels)\n",
    "\n",
    "    print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "\n",
    "    name = \"scrubbed_classification_train_dataset_\" + str(ind)\n",
    "    torch.save(train_dataset, 'unbalanced_datasets/'+name+'.pt')\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  She focuses on cloud security, identity and access management, mobility security, and security for Microsoft platforms and solutions. Jan is based in Belgium.\n",
      "Token IDs: tensor([    2,    39,  7155,    27,  4005,  1221,    15,  3270,    17,  1381,\n",
      "         1097,    15, 14806,  1221,    15,    17,  1221,    26,  7099,  6843,\n",
      "           17,  6776,     9,  2262,    25,   432,    19,  4692,     9,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(13)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_0\n",
      "Loading BERT tokenizer...\n",
      "Original:  Born in England she now resides in Berlin. Educated at Dartington College of Arts she graduated with a BA and MA in contemporary music composition and arts theory and continues her work in her solo projects and as a member of the krautrock band Curious Egg.\n",
      "Token IDs: tensor([    2,   386,    19,   648,    39,   130, 12631,    19,  2296,     9,\n",
      "         3977,    35, 25680,   444,   314,    16,  1008,    39,  2158,    29,\n",
      "           21,  2683,    17,  1216,    19,  2152,   232,  4046,    17,  1008,\n",
      "         1639,    17,  2622,    36,   170,    19,    36,  2046,  2314,    17,\n",
      "           28,    21,   322,    16,    14,  5179,  1982,  4651,   323,  7686,\n",
      "         6387,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_1\n",
      "Loading BERT tokenizer...\n",
      "Original:  In her works, references to the musical past are often embedded within folk materials of her native country, Argentina. Disks and scores with her music are available on the independent label Contrapunctus, on FJH Publications, Editions Billaudot, and on Ricordi.\n",
      "Token IDs: tensor([    2,    19,    36,   693,    15,  7231,    20,    14,  1457,   640,\n",
      "           50,   478, 12138,   363,  3267,  2895,    16,    36,  1275,   475,\n",
      "           15,  4491,     9,  8582,    18,    17,  7369,    29,    36,   232,\n",
      "           50,   904,    27,    14,  1124,  1899, 11805, 17359,   267,    15,\n",
      "           27,   398,   728,   252,  4411,    15,  6179,  1071,  1346, 12527,\n",
      "           15,    17,    27,  5738,   897,    49,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_2\n",
      "Loading BERT tokenizer...\n",
      "Original:  He has been with the ITEE eResearch group since 2006 as a Web Developer / Senior Research Assistant working on the HarvANA project as well as annotation tools for 3D models of museum artefacts and protein crystallography structures.\n",
      "Token IDs: tensor([    2,    24,    63,    74,    29,    14,    32,  2851,    13,    62,\n",
      "        26619,   214,   179,   592,    28,    21,  2741, 10058,    13,   118,\n",
      "         1101,   527,  1482,   638,    27,    14,  2431, 18026,   669,    28,\n",
      "          134,    28,    40,  1270,   857,  4672,    26,   203,    43,  2761,\n",
      "           16,   774, 27284,    17,  4008,  4282,   255, 10112,  3815,     9,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_3\n",
      "Loading BERT tokenizer...\n",
      "Original:  He began blogging in 2012, with his posts evolving from an initial empty nest focus (“NestAche” as Dr. Joseph termed it) to posts describing his work in mental health. His writing can be found on his own website http://drmargaretrutherford.com, as well as The Huffington Post, Midlife Boulevard, Boomeon, BetterAfter50, WeWantMore and now at The Good Women Project.\n",
      "Token IDs: tensor([    2,    24,   260,   334, 13919,    19,   563,    15,    29,    33,\n",
      "         9868, 22363,    37,    40,  2104,  2424,  5618,  1776,    13,     5,\n",
      "            1,  2696,    38,  9616,     1,    28,   744,     9,  1540, 13776,\n",
      "           32,     6,    20,  9868,  7153,    33,   170,    19,  3584,   853,\n",
      "            9,    33,  1174,    92,    44,   216,    27,    33,   258,  2271,\n",
      "         7775,  6903,  3807,  1615,  1136,    99, 23266,   106,  1426,     9,\n",
      "          960,    15,    28,   134,    28,    14, 26910,   678,    15,   907,\n",
      "         4102,  7717,    15,  6403, 11572,    15,   574,  5162,  2290,    15,\n",
      "           95, 14876,  1995,    17,   130,    35,    14,   254,   364,   669,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_4\n",
      "Loading BERT tokenizer...\n",
      "Original:  He graduated with honors in 1999. Having more than 19 years of diverse experiences, especially in CLINICAL PSYCHOLOGIST, Dr. John William Hickcox affiliates with no hospital, and cooperates with other doctors and specialists without joining any medical groups. Call Dr. John William Hickcox on phone number (330) 650-5338 for more information and advice or to book an appointment.\n",
      "Token IDs: tensor([    2,    24,  2158,    29,  7811,    19,  1247,     9,   452,    91,\n",
      "          119,   732,   122,    16,  6951,  5513,    15,  1118,    19,  5611,\n",
      "        13729,    15,   744,     9,   239,   605,    13, 15477,   716,   396,\n",
      "         6772,    18,    29,    90,   980,    15,    17, 15180,    18,    29,\n",
      "           89,  6995,    17, 19546,   366,  3765,   186,  1088,  1170,     9,\n",
      "          645,   744,     9,   239,   605,    13, 15477,   716,   396,    27,\n",
      "         1132,   234,    13,     5, 13509,     6,    13, 13798,     8,  4022,\n",
      "         3665,    26,    91,   676,    17,  4978,    54,    20,   360,    40,\n",
      "         4905,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_5\n",
      "Loading BERT tokenizer...\n",
      "Original:  Having been a therapist for forty years, he has observed how people approach life dilemmas and the diverse voices they use to express their unique experiences. Playwriting as an...\n",
      "Token IDs: tensor([    2,   452,    74,    21, 18000,    26,  4671,   122,    15,    24,\n",
      "           63,  3634,   184,   148,  2141,   201, 23314,    18,    17,    14,\n",
      "         6951,  5333,    59,   275,    20,  2999,    66,  2619,  5513,     9,\n",
      "          418, 12646,    28,    40,     9,     9,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_6\n",
      "Loading BERT tokenizer...\n",
      "Original:  At same time, She is also doing study and research in Software Management at Carnegie Mellon University. Prior to Google, she worked at Cisco Systems, Nortel Networks, Sun Microsystems, AT&T Bell Lab. She has 15+ years experiences in system and business software development, network equipment development, and project and product managements. She also has 8+ years experiences in teaching in Computer Science, Networking and Internet Application Developments.\n",
      "Token IDs: tensor([    2,    35,   205,    85,    15,    39,    25,    67,   845,   949,\n",
      "           17,   527,    19,  2306,  1097,    35, 12234, 23771,   155,     9,\n",
      "         1313,    20,  8144,    15,    39,   577,    35, 28184,  1242,    15,\n",
      "         2127,  3454,  5540,    15,   939,  2899, 10724,    18,    15,    35,\n",
      "         1569,    38,  1988,  4343,     9,    39,    63,   357,  2430,   122,\n",
      "         5513,    19,   329,    17,   508,  2306,   522,    15,   982,  2181,\n",
      "          522,    15,    17,   669,    17,  2374,  1097,    18,     9,    39,\n",
      "           67,    63,   469,  2430,   122,  5513,    19,  2540,    19,  1428,\n",
      "          762,    15, 16230,    17,  2620,  3010, 11884,     9,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_7\n",
      "Loading BERT tokenizer...\n",
      "Original:  She studies what's called targeted violence. That includes mass shootings. And she has little doubt that what happened here in Las Vegas will eventually inspire copycats.\n",
      "Token IDs: tensor([    2,    39,  1011,    98,    22,    18,   227,  9536,  3300,     9,\n",
      "           30,  1103,  1619,  3511,    18,     9,    17,    39,    63,   265,\n",
      "         3063,    30,    98,  1190,   235,    19,  3695,  6432,   129,   878,\n",
      "        19146,  4344, 14626,     9,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(8)\n",
      "2,150 training samples\n",
      "flipped_classification_train_dataset_8\n",
      "Loading BERT tokenizer...\n",
      "Original:  Hamasaki Rio is a lovely Asian model who is well known ... Model: Natsuki Iijima This hot Asian teen has a nice set ... : Mao Mao is a cute Asian teen who hangs around the ... but he is kind of shy and backs out last minute ...\n",
      "Token IDs: tensor([    2, 21594,  4713,  4017,    25,    21,  8601,  2282,  1061,    72,\n",
      "           25,   134,   167,    13,     9,     9,     9,  1061,    45,  1775,\n",
      "        21898,   595, 17316,    48,  1047,  2282,  9503,    63,    21,  2210,\n",
      "          309,    13,     9,     9,     9,    13,    45, 15107, 15107,    25,\n",
      "           21, 10901,  2282,  9503,    72,  4546,    18,   140,    14,    13,\n",
      "            9,     9,     9,    47,    24,    25,   825,    16,  8327,    17,\n",
      "           97,    18,    70,   236,  2038,    13,     9,     9,     9,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(9)\n",
      "2,149 training samples\n",
      "flipped_classification_train_dataset_9\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(k_fold_df):\n",
    "    sentences = i.flipped_bio.values\n",
    "    gender = i.gender.values\n",
    "    labels = i.label.values\n",
    "    train_input_ids, train_class_labels, train_attention_masks, train_gender_labels = tokenize(sentences, labels, gender)\n",
    "    # test_input_ids, test_class_labels, test_attention_masks, test_gender_labels = tokenize(X_test, y_test, gen_test)\n",
    "#     val_input_ids, val_class_labels, val_attention_masks, val_gender_labels = tokenize(X_val, y_val, gen_val)\n",
    "\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', train_input_ids[0])\n",
    "    print('Token IDs:', train_class_labels[0])\n",
    "    \n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    train_dataset = TensorDataset(train_input_ids, train_class_labels, train_attention_masks, train_gender_labels)\n",
    "\n",
    "    print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "\n",
    "    name = \"flipped_classification_train_dataset_\" + str(ind)\n",
    "    torch.save(train_dataset, 'unbalanced_datasets/'+name+'.pt')\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  She completed an AS at Mercer County Community College, a BA in Psychology at The College of New Jersey, and an MA in Applied Clinical Psychology at William Paterson University. She is currently pursing her BSN at Walden University.\n",
      "Token IDs: tensor([    2,    39,  1066,    40,    28,    35, 14035,   271,   514,   314,\n",
      "           15,    21,  2683,    19,  6182,    35,    14,   314,    16,    78,\n",
      "         2134,    15,    17,    40,  1216,    19,  2435,  5611,  6182,    35,\n",
      "          605, 22228,   155,     9,    39,    25,   871,  6771,    18,    68,\n",
      "           36,   334,    18,   103,    35, 25043,   155,     9,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(5)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_0\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He studied architecture in Thessaloniki, Greece and he holds an MSc from Columbia University and a PhD from TU Delft. His thesis investigated the recent history of planning in Athens and the link between conflict, urban management and architectural form. His research interests explore architecture in relation to the politics of labour, law and social reform. Prior to the RCA, he taught at the Berlage Institute/Rotterdam and since 2012 at the MArch Urban Design at the Bartlett.\n",
      "Token IDs: tensor([    2,    24,  1449,  2607,    19, 25201,    15,  4309,    17,    24,\n",
      "         2763,    40,  4235,   150,    37,  2368,   155,    17,    21,  7739,\n",
      "           37,  2289,  1506,  3072,     9,    33, 10452, 11790,    14,  1764,\n",
      "          447,    16,  2334,    19,  7300,    17,    14,  3508,   128,  2930,\n",
      "           15,  1980,  1097,    17,  5350,   505,     9,    33,   527,  4408,\n",
      "         8594,  2607,    19,  5827,    20,    14,  2634,    16,  2668,    15,\n",
      "          451,    17,   668,  3202,     9,  1313,    20,    14, 15445,    15,\n",
      "           24,  2359,    35,    14,  5914, 24436,   934,   118, 19879,   106,\n",
      "         9578,    17,   179,   563,    35,    14,   285,  1980,   704,    35,\n",
      "           14, 23097,     9,     3,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(13)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_1\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Hanna was previously a research assistant at Middleberg Nutrition since 2013. In addition. Hanna has provided nutrition education lessons and performed healthy cooking demonstrations to teens and families in New York City as part of Food Bank for NYC, empowering them to enjoy food while making smarter choices.\n",
      "Token IDs: tensor([    2, 10413,    23,  1343,    21,   527,  1482,    35,   772,  1731,\n",
      "        16124,   179,   616,     9,    19,   848,     9, 10413,    63,  1173,\n",
      "        16124,   565,  7870,    17,   986,  7714,  8233, 15705,    20, 15823,\n",
      "           17,  1250,    19,    78,   305,   136,    28,   141,    16,   950,\n",
      "          965,    26, 17615,    15, 23985,    68,   105,    20,  4696,   950,\n",
      "          133,   544,  3978,   106, 10978,     9,     3,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(1)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_2\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He's taken on projects ranging from mediocre (the Austin Powers series) to terrible (The Cat In The Hat, and apparently The Love Guru) over the last several years.\n",
      "Token IDs: tensor([    2,    24,    22,    18,   658,    27,  2314,  7657,    37,    55,\n",
      "         6921,  6037,    13,     5,   124,  4665,  2737,   231,     6,    20,\n",
      "         5803,    13,     5,   124,  2008,    19,    14,  2970,    15,    17,\n",
      "         3083,    14,   339, 10334,     6,    84,    14,   236,   238,   122,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(2)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_3\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  She is also a writer and publishes the award-winning Blooming Rock blog which focuses on urbanism, sustainability and architecture. Taz writes for other publications as well, including Modern Phoenix, the Firefly Living blog, Arizona Community Contractor magazine, Java Magazine and the Atlantic Cities. She serves on Phoenix's Historic Preservation Commission, is co-chair of the Phoenix Post-War Architecture Task Force, co-chair of the American Institute of Architect's Advocacy Committee and also serves on the Phoenix General Plan Update Task Force. Along with being involved in a variety of community-building projects, she partners with Women Design Arizona to curate and organize the Sustainable Communities Lecture Series that brings together experts and the community to talk about how to make Phoenix a more sustainable city.\n",
      "Token IDs: tensor([    2,    39,    25,    67,    21,  1462,    17, 13829,    14,   450,\n",
      "            8,  6088,  8064,    68,   629,  8146,    56,  7155,    27,  1980,\n",
      "          756,    15, 17491,    17,  2607,     9, 28624,  6215,    26,    89,\n",
      "         4411,    28,   134,    15,   215,   773,  6014,    15,    14,   535,\n",
      "         9700,   634,  8146,    15,  4045,   514, 15136,  1039,    15,  8247,\n",
      "         1039,    17,    14,  3040,  1920,     9,    39,  2589,    27,  6014,\n",
      "           22,    18,  1310,  8121,  1312,    15,    25,   326,     8, 14045,\n",
      "           16,    14,  6014,   678,     8,  1885,  2607,  3005,   558,    15,\n",
      "          326,     8, 14045,    16,    14,   189,   934,    16,  3338,    22,\n",
      "           18, 13812,   940,    17,    67,  2589,    27,    14,  6014,     3])\n",
      "Token IDs: tensor(13)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_4\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He completed a residency at St Lukes Roosevelt Hospital. He currently practices at Bay Area Cosmetic Surgical Center and is affiliated with Fawcett Memorial Hospital, Tampa Community Hospital and Florida Hospital Tampa. Dr. Hirschfeld accepts multiple insurance plans including Aetna, Medicare and Humana. Dr. Hirschfeld also practices at Riverchase Dermatology in Sun City Center, FL. In addition to English, Dr. Hirschfeld's practice supports this language: Spanish.\n",
      "Token IDs: tensor([    2,    24,  1066,    21, 16298,    35,   354,  3881,    18,  8440,\n",
      "          980,     9,    24,   871,  5242,    35,   899,   217, 18872, 12569,\n",
      "          459,    17,    25,  6751,    29,  1399, 12354,  3317,  2148,   980,\n",
      "           15, 10385,   514,   980,    17,  1750,   980, 10385,     9,   744,\n",
      "            9, 20680,  5450, 16548,  1886,  4225,  1753,   215,    21,  1198,\n",
      "          325,    15, 28736,    17,   585,    58,     9,   744,     9, 20680,\n",
      "         5450,    67,  5242,    35,   341,  1651,   870,  2223,   540, 17810,\n",
      "           19,   939,   136,   459,    15,  8631,     9,    19,   848,    20,\n",
      "          486,    15,   744,     9, 20680,  5450,    22,    18,  1345,  6747,\n",
      "           48,   816,    45,  1273,     9,     3,     0,     0,     0,     0])\n",
      "Token IDs: tensor(4)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_5\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  His music has received numerous international performances and broadcasts; including BBC Radio 3, SEAMUS (Miami & Iowa), Sonorities (Belfast), EMMF (Kansas & Chicago), Huddersfield Contemporary Music Festival, Expo (Manchester and Scarborough), ACMC (Wellington and Brisbane), Futura (France), Weimar, Sonus and TES (Canada), NYCEMF (New York in 2011/13/16/17) and at ICMC conferences (NYC, Barcelona, New Orleans, Ljubljana, Belfast); and he has written for dance, theatre and education. In the 1993 ALEA III competition Ironwork for piano and tape was a prizewinner; Break was a finalist of 2004 Musica Nova, and Shelter received an honourable mention at Bourge, IMEB, 2006. In 2010, Can won the medal of the Senato della Repubblica Italiana Music Contest “Città di Udine”.\n",
      "Token IDs: tensor([    2,    33,   232,    63,   420,  1548,   294,  3200,    17,  9461,\n",
      "           73,   215,  2313,   603,   203,    15, 27614,    13,     5,  1435,\n",
      "         5448,   279,  4985,     6,    15,   433,   248,  3808,    13,     5,\n",
      "         3512, 13088,     6,    15, 22909,   410,    13,     5,  2825,    18,\n",
      "          472,   279,  1360,     6,    15, 23050,  2152,   232,   874,    15,\n",
      "        13443,    13,     5,   177, 18129,    17, 21945,     6,    15,    21,\n",
      "          150,  4829,    13,     5,   854,  4926,    17,  7273,     6,    15,\n",
      "         2916, 18274,    13,     5, 10696,     6,    15, 24789,    15,   433,\n",
      "          267,    17,    13,  3231,    13,     5, 18006,     6,    15, 17615,\n",
      "         1503,   410,    13,     5,  2681,   305,    19,   542, 11698,     3])\n",
      "Token IDs: tensor(3)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_6\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  His bad luck evaporates when meeting talented singing Chipmunks Alvin, Simon and Theodore. Soon they became a true musical sensation. Sweet animals do not fail to occur wild side of nature, so Dave is forced to use all their ingenuity to smooth out the problems and return his family before it's too late.\n",
      "Token IDs: tensor([    2,    33,   896,  5419, 25098,    18,    76,  1235, 11847,  3385,\n",
      "         7525,  5619,  4020, 19768,    15,  2214,    17, 10358,     9,   651,\n",
      "           59,   178,    21,  1151,  1457,  7126,     9,  2092,  2522,   107,\n",
      "           52,  7476,    20,  3744,  1808,   270,    16,  1444,    15,    86,\n",
      "         3498,    25,  1292,    20,   275,    65,    66,    13, 10180,   291,\n",
      "          856,    20,  3905,    70,    14,  1716,    17,   788,    33,   190,\n",
      "          115,    32,    22,    18,   266,   456,     9,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(3)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_7\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  She received her Bachelor of Science Degree in Nursing from Murray State University and her Masters of Science Degree in Nursing from the University of Kentucky. She brings with her over twenty-five years of experience in Family Medicine. In her spare time, Ms. Hunter enjoys spending time with her husband and two daughters.\n",
      "Token IDs: tensor([    2,    39,   420,    36,  3427,    16,   762,  1168,    19,  8181,\n",
      "           37,  5169,   146,   155,    17,    36,  5001,    16,   762,  1168,\n",
      "           19,  8181,    37,    14,   155,    16,  4425,     9,    39,  7620,\n",
      "           29,    36,    84,  1309,     8,  4709,   122,    16,  1496,    19,\n",
      "          190,  2333,     9,    19,    36,  8001,    85,    15,  4235,     9,\n",
      "         2944, 18431,  4837,    85,    29,    36,  1253,    17,    81,  4909,\n",
      "            9,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(5)\n",
      "4,300 training samples\n",
      "bio_and_flipped_classification_train_dataset_8\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42992/1204574785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He's also tnd member of the core Activiti development team. He's also the coauthor of Manning's \"Open Source ESBs in Action.\" he coauthor of Manning's \"Open Source ESBs in Action.\" See less\n",
      "Token IDs: tensor([    2,    24,    22,    18,    67,    13,    38,   706,   322,    16,\n",
      "           14,  2884,    13, 19516,  8793,   522,   173,     9,    24,    22,\n",
      "           18,    67,    14,   326, 10007,    16, 12481,    22,    18,    13,\n",
      "            7, 10157,  1267,    13,   160,  4562,    19,  1028,     9,     7,\n",
      "           24,   326, 10007,    16, 12481,    22,    18,    13,     7, 10157,\n",
      "         1267,    13,   160,  4562,    19,  1028,     9,     7,   196,   787,\n",
      "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Token IDs: tensor(11)\n",
      "4,298 training samples\n",
      "bio_and_flipped_classification_train_dataset_9\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(k_fold_df):\n",
    "    from sklearn.utils import shuffle\n",
    "    df_1 =  i[[\"gender\", \"label\", \"bio\"]]\n",
    "    df_2 =  i[[\"gender\", \"label\", \"flipped_bio\"]]\n",
    "    df_2.rename(columns={'flipped_bio':'bio'}, inplace=True)\n",
    "    dff = pd.concat([df_1, df_2])\n",
    "    dff = shuffle(dff, random_state=42)\n",
    "    sentences = dff.bio.values\n",
    "    gender = dff.gender.values\n",
    "    labels = dff.label.values\n",
    "    train_input_ids, train_class_labels, train_attention_masks, train_gender_labels = tokenize(sentences, labels, gender)\n",
    "    # test_input_ids, test_class_labels, test_attention_masks, test_gender_labels = tokenize(X_test, y_test, gen_test)\n",
    "#     val_input_ids, val_class_labels, val_attention_masks, val_gender_labels = tokenize(X_val, y_val, gen_val)\n",
    "\n",
    "    print('Original: ', sentences[0])\n",
    "    print('Token IDs:', train_input_ids[0])\n",
    "    print('Token IDs:', train_class_labels[0])\n",
    "    \n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    train_dataset = TensorDataset(train_input_ids, train_class_labels, train_attention_masks, train_gender_labels)\n",
    "\n",
    "    print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "\n",
    "    name = \"bio_and_flipped_classification_train_dataset_\" + str(ind)\n",
    "    torch.save(train_dataset, 'unbalanced_datasets/'+name+'.pt')\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
